<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-05-07T20:51:11-06:00</updated><id>http://localhost:4000/</id><title type="html">Eggink Blog</title><subtitle>Jake W. Knigge's blah, blah, blog... a place to discuss statistics, math, and  whatever else comes to mind.
</subtitle><entry><title type="html">Statistical learning theory - complexity example</title><link href="http://localhost:4000/jekyll/update/2018/05/07/slt-example.html" rel="alternate" type="text/html" title="Statistical learning theory - complexity example" /><published>2018-05-07T22:00:00-06:00</published><updated>2018-05-07T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/07/slt-example</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/07/slt-example.html">&lt;p&gt;This post illustrates how we use Rademacher complexities in statistical learning theory.
To that end, we’ll assume that we’re working with our toolbox developed in
&lt;a href=&quot;/jekyll/update/2018/05/06/learning-theory-1.html&quot;&gt;last post&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-quick-recap&quot;&gt;A quick recap&lt;/h3&gt;

&lt;p&gt;Last post, our main result was that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right] \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right],&lt;/script&gt;

&lt;p&gt;which allowed us to bound the statistical risk as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right] +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right),&lt;/script&gt;

&lt;p&gt;with at least probability &lt;script type=&quot;math/tex&quot;&gt;1-\delta&lt;/script&gt;. In other words, Rademacher complexity helps
us measure the tendency of a model class to overfit a sample.&lt;/p&gt;

&lt;h3 id=&quot;warm-up&quot;&gt;Warm up&lt;/h3&gt;

&lt;p&gt;Let’s Rademacherize our minds with a straightforward application of last post’s bound.
We’ll assume that our loss functions are &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-Lipschitz. With this and this alone, we
can show that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
	\sum_{i=1}^n \sigma_i l_f(z_i) \right] \le
	L \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
		\sum_{i=1}^n \sigma_i f(x_i) \right].&lt;/script&gt;

&lt;p&gt;This is cool for at least two reasons. The first is that the righthand side doesn’t
depend on &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; anymore—only &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. The second is that the expectation no longer
depends on &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;, but only on &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;linear-regression-with-squared-loss&quot;&gt;Linear regression with squared loss&lt;/h3&gt;

&lt;p&gt;To make these ideas concrete, we’ll look at one of the most commone models arising in
statistics / machine learning: ordinary linear regression. Here’s our set up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Our class of functions is &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F} = \{\theta \mid x \mapsto \theta^T x\}&lt;/script&gt; where
&lt;script type=&quot;math/tex&quot;&gt;\|\theta\| \le B_\theta&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\|x\| \le B_x&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;By assumption on &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;, we have &lt;script type=&quot;math/tex&quot;&gt;\|y\| \le B_\theta B_x&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Our loss function &lt;script type=&quot;math/tex&quot;&gt;l(\theta^T x, y) = (\theta^T x - y)^2&lt;/script&gt;, with &lt;script type=&quot;math/tex&quot;&gt;L = 4B_\theta B_x&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’re interested in the Rademacher complexity of our function class on &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples
&lt;script type=&quot;math/tex&quot;&gt;S = \{(x_1,y_1),\dots,(x_n,y_n)\}&lt;/script&gt;, &lt;em&gt;i.e.&lt;/em&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathcal{R}(\mathcal{F}, S) &amp;= \E_\sigma \left[ \sup_{\theta: \theta \le B_\theta}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \theta^T x_i \right] \\
	&amp;= \frac{1}{n} \E_\sigma \left[ \sup_\theta \theta^T \left(
		\sum_{i=1}^n \sigma_i x_i \right) \right]
		&amp;&amp; {\small \textsf{(linearity)}} \\
	&amp;= \frac{1}{n} \E_\sigma \left[ B_\theta \left\|
		\sum_{i=1}^n \sigma_i x_i \right\| \right]
		&amp;&amp; {\small \textsf{(bound on $\theta$)}} \\
	&amp;= \frac{B_\theta}{n} \E_\sigma \sqrt{ \left\|
		\sum_{i=1}^n \sigma_i x_i \right\|^2 }
		&amp;&amp; {\small \textsf{(square-square root trick)}} \\
	&amp;\le \frac{B_\theta}{n} \sqrt{\E_\sigma \left\|
		\sum_{i=1}^n \sigma_i x_i \right\|^2}
		&amp;&amp; {\small \textsf{(Jensen for concave functions)}} \\
	&amp;\le \frac{B_\theta}{n} \sqrt{n B_x^2}
		&amp;&amp; {\small \textsf{(independence of $\sigma_i$ and $\|\sigma_i\|=1$)}}\\
	&amp;= \frac{B_\theta B_x}{\sqrt{n}} \\
	&amp;= \frac{\textsf{size of model class}}{\textsf{convergence rate}}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The trickiest step is the one that exploits the independence of the Rademacher
random variables and the bound on their norm. It’s easy to see if we write out
the double sum&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_k \sum_j \sigma_k \sigma_j x_k^T x_j = \sum_k \sigma_k^2 x_k^T x_k +
	\sum_{j \neq k} \sigma_j \sigma_k x_j^T x_k = \sum_k x_k^T x_k,&lt;/script&gt;

&lt;p&gt;because the &lt;script type=&quot;math/tex&quot;&gt;\sigma_j&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\sigma_k&lt;/script&gt; are independent.&lt;/p&gt;

&lt;h3 id=&quot;putting-it-all-together&quot;&gt;Putting it all together&lt;/h3&gt;

&lt;p&gt;From last post and the above calculation, we conclude that with probability at least
&lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) &amp;\le
	\frac{8(B_\theta B_x)^2}{\sqrt{n}} +
	\mathcal{O}\left( \sqrt{\frac{1}{m} \ln \frac{1}{\delta}} \right) \\
	&amp;=\mathcal{R}(\mathcal{F}, S) L +
	\mathcal{O}\left( \sqrt{\frac{1}{m} \ln \frac{1}{\delta}} \right),
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;for empirical risk minimization. Hot diggity!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… the online learning perspective!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicolò Cesa-Bianchi’s lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">This post illustrates how we use Rademacher complexities in statistical learning theory. To that end, we’ll assume that we’re working with our toolbox developed in last post.</summary></entry><entry><title type="html">Learning theory - statistical learning</title><link href="http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1.html" rel="alternate" type="text/html" title="Learning theory - statistical learning" /><published>2018-05-06T11:30:00-06:00</published><updated>2018-05-06T11:30:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1.html">&lt;p&gt;Today’s post is the first in a set of three that will discuss two theories of learning.
In particular, today’s post will cover (a very narrow aspect of)
&lt;strong&gt;statistical learning theory&lt;/strong&gt;. The next post will present a game-theoretic
view of learning, using &lt;strong&gt;online learning&lt;/strong&gt; as its primary analytical framework. The
final post will connect the two perspectives.&lt;/p&gt;

&lt;h3 id=&quot;a-bit-of-background&quot;&gt;A bit of background&lt;/h3&gt;

&lt;p&gt;Learning problems, specifically machine learning problems can be analyzed from at
least two perspectives. In either case, our goal is to have a toolbox from which
we can analyze how well a learning system works. For example, we want to be able to
say when learning occurs, when it doesn’t, and how quickly it occurs or doesn’t. To
make this problem tractable, we’ll require&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a model for the data;&lt;/li&gt;
  &lt;li&gt;assumptions on the source of that data;&lt;/li&gt;
  &lt;li&gt;functions to generate predictions;&lt;/li&gt;
  &lt;li&gt;loss functions to assess the quality of our predictions; and&lt;/li&gt;
  &lt;li&gt;learning algorithms to help us improve our predictions by understanding our losses.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-set-up&quot;&gt;The set-up&lt;/h3&gt;

&lt;p&gt;We assume that our data consists of &lt;script type=&quot;math/tex&quot;&gt;(x, y)&lt;/script&gt; feature-output pairs with
&lt;script type=&quot;math/tex&quot;&gt;x \in \reals^d&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y \in \reals&lt;/script&gt;. The data comes from some &lt;strong&gt;fixed but unknown&lt;/strong&gt;
source that could be &lt;strong&gt;stochastic&lt;/strong&gt; (as in the statistical learning framework) or
&lt;strong&gt;nonstochastic&lt;/strong&gt; (as in online learning framework).&lt;/p&gt;

&lt;p&gt;We a function &lt;script type=&quot;math/tex&quot;&gt;f: \reals^d \to \reals&lt;/script&gt; that maps data to
estimates/forecasts/predictions. So, &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; gives us a mechanism to
generate our own &lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;’s that we can compare against the true &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;’s; we assess
our estimates via a loss function &lt;script type=&quot;math/tex&quot;&gt;l: \reals^n \times \reals \to \reals&lt;/script&gt;. You probably
have many loss functions that you know and love…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;squared-error loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \|y - \hat{y}\|^2_2&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;absolute-error: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \|y - \hat{y} \|_1&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Kullback–Leibler: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = y \log \frac{y}{\hat{y}}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;hinge loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \max \{0, 1 - y \cdot \hat{y} \}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;logistic loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \ln \frac{\hat{y}}{1 - \hat{y}}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The final ingredient is a &lt;strong&gt;learning algorithm&lt;/strong&gt;, which we can think of as a map from data
to models. This is way that V. Vapnik and A. Chervonenkis conceptualized learning
algorithms and we think that it’s a useful mental model.&lt;/p&gt;

&lt;p&gt;Before diving into either framework let’s give ourselves a learning goal: our algorithms
should output good models with respect to the data source.&lt;/p&gt;

&lt;h3 id=&quot;statistical-learning-theory&quot;&gt;Statistical learning theory&lt;/h3&gt;

&lt;p&gt;In the statistical learning setting, we assume that our data is generated by a probability
(&lt;em&gt;i.e.&lt;/em&gt;, stochastic) model with distribution
&lt;script type=&quot;math/tex&quot;&gt;\mathcal{D} \subseteq \reals^d \times \reals&lt;/script&gt;. In particular, we’ll assume&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(x, y) \stackrel{\textsf{i.i.d.}}{\sim} \mathcal{D}.&lt;/script&gt;

&lt;p&gt;We are interested in learning by controlling the &lt;strong&gt;statistical risk&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f) = \E \left[ l\big(f(X), Y\big) \right],&lt;/script&gt;

&lt;p&gt;where the expectation is over the randomness in the data &lt;script type=&quot;math/tex&quot;&gt;(X,Y)&lt;/script&gt; and the model &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;
belongs to some class of models &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;. The class of models is a design
parameter that we specify. For example, we could choose a set of linear predictors&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{F} = \left\{\theta \in \reals^d \mid x \mapsto \theta^T x\right\}.&lt;/script&gt;

&lt;p&gt;Since we’re restricting our models to the class &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;, we’re really interested
in controlling our risk over that class. So we want a model&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f^\star \in \argmin_{f \in \mathcal{F}} R_{\mathcal{D}}(f).&lt;/script&gt;

&lt;p&gt;But this is statistics, so we don’t have access to &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; at the population
level. Instead, we have knowledge of &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; through &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples
&lt;script type=&quot;math/tex&quot;&gt;(x_1,y_1),\dots,(x_n,y_n)&lt;/script&gt;. Hmmm…&lt;/p&gt;

&lt;h3 id=&quot;empirical-risk-minimization&quot;&gt;Empirical risk minimization&lt;/h3&gt;

&lt;p&gt;As statistically-minded individuals, we’ll use the &lt;strong&gt;empirical risk&lt;/strong&gt; as a surrogate
for the population risk and pick our model as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_n^\star \in \argmin_{f \in \mathcal{F}} R_n(f)
	= \argmin_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n l\big(f(x_i), y_i\big).&lt;/script&gt;

&lt;p&gt;We want the empirical risk to a be a good proxy for the statistical risk. More
specifically, we want it to be uniformly close to the statistical risk. By &lt;em&gt;uniformly
close&lt;/em&gt;, we mean that we’re close over all models within our class and all data.&lt;/p&gt;

&lt;p&gt;This might seem a bit extreme, but it prevents us from being lulled into believing we have
a “good” model by getting easy training data or having an overly complex model
class—think interpolating the data.&lt;/p&gt;

&lt;h3 id=&quot;rademacher-complexity&quot;&gt;Rademacher complexity&lt;/h3&gt;

&lt;p&gt;To help us assess our algorithms and models, we turn to &lt;strong&gt;Rademacher averages&lt;/strong&gt;, which
is a Vapnik–Chervonenkis type notion of complexity that (also) has its origins in the
Russian school of statistics (~1970s). We defined the empirical Rademacher average&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{R}_n(\mathcal{F}, S) = \E_\sigma \left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i f(x_i) \right],&lt;/script&gt;

&lt;p&gt;for a class of functions &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples &lt;script type=&quot;math/tex&quot;&gt;S = \{x_1,\dots,x_n\}&lt;/script&gt;.
Before moving on, note that the empirical Rademacher average does not depend on
&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;, but only on the data. This will prove useful in the sequel.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aside:&lt;/strong&gt; see the &lt;a href=&quot;/jekyll/update/2018/03/04/rademacher.html&quot;&gt;Rademachers are rad - part I&lt;/a&gt; and
&lt;a href=&quot;/jekyll/update/2018/03/06/rademacher_2.html&quot;&gt;Rademachers are rad - part II&lt;/a&gt; post for Rademacher fun in the spirit of
Rademacher complexity.&lt;/p&gt;

&lt;h3 id=&quot;assessing-empirical-risk&quot;&gt;Assessing empirical risk&lt;/h3&gt;

&lt;p&gt;Okay, now we’re going ready to assess how well empirical risk minimization works by
studying the difference&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f) - R_{\mathcal{D}}(f^\star),&lt;/script&gt;

&lt;p&gt;which is the difference between a suboptimal model and the optimal model—note that we
don’t have an empirical risk term… yet.&lt;/p&gt;

&lt;p&gt;Nonetheless, here goes. We can add and subtract the empirical risk getting&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) &amp;=
	R_{\mathcal{D}}(f_n^\star) - R_n(f_n^\star) +
		R_n(f_n^\star) - R_{\mathcal{D}}(f^\star) \\
	&amp;\le \sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\} +
		R_n(f^\star) - R_{\mathcal{D}}(f^\star).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The &lt;script type=&quot;math/tex&quot;&gt;\sup&lt;/script&gt; term is a comparison of the selected model on the whole distribution versus
the sample. The second term is the error of using the “best” model on the training sample
versus the whole distribution. The inequality follows from the &lt;script type=&quot;math/tex&quot;&gt;\sup&lt;/script&gt; and the fact that
&lt;script type=&quot;math/tex&quot;&gt;R_n(f_n^\star) \le R_n(f^\star)&lt;/script&gt; by definition of &lt;script type=&quot;math/tex&quot;&gt;f_n^\star&lt;/script&gt;. Also, we can interpret
the first term as a measurement of how much the model overfits the data. And, in some
sense, this is what we want to understand!&lt;/p&gt;

&lt;h3 id=&quot;high-probability-bounds&quot;&gt;High probability bounds&lt;/h3&gt;

&lt;p&gt;Both terms on the righthand side are random variables because they depend on the
training data. So via Chernoff bounds (which we’re excluding from the current discussion),
we can say that with probability &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\} &amp;\le
	\E \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right]+
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right) \\
R_n(f^\star) - R_{\mathcal{D}}(f^\star) &amp;\le
	\E \bigg[ R_n(f^\star) - R_{\mathcal{D}}(f^\star) \bigg]+
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The expected value of the second term is 0 because the expected value of the empirical
risk, by our i.i.d. assumption, is the statistical risk. You can think of this term as
a bias-like term. The first term is more interesting; it may have caused your
Rademacher neurons to fire, but it’s not quite a Rademacher average… yet.&lt;/p&gt;

&lt;h3 id=&quot;the-ghost-sample&quot;&gt;The ghost sample&lt;/h3&gt;

&lt;p&gt;Now, we’re going to use one of “modern” statistics favorite tricks: the &lt;strong&gt;ghost sample&lt;/strong&gt;.
The ghost sample allows us to replace a (population) quantity by the sample quantity by
pretending that we have access to a second, made-up sample from the distribution—it’s
like we have a second training set. By the ghost sample trick (first equality) and
Jensen’s inequality, our term is bounded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right]
	&amp;= \E_S \left[\sup_{f \in \mathcal{F}}
		\bigg\{\E_{\tilde{S}} R_{\tilde{n}}(f) - R_n(f)\bigg\}\right]\\
	&amp;\le \E_S \E_{\tilde{S}}
		\left[\sup_{f \in \mathcal{F}}\big\{R_{\tilde{n}}(f) - R_n(f)\big\}\right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Okay, cool. The righthand side is the difference between two empirical risk quantities,
one for the original training sample and the other for the ghost sample. We’re getting
closer to bounding the overfitting term…&lt;/p&gt;

&lt;h3 id=&quot;rademacher-magic&quot;&gt;Rademacher magic&lt;/h3&gt;

&lt;p&gt;Now, we introduce Rademacher random variables &lt;script type=&quot;math/tex&quot;&gt;\sigma_i \sim \mathsf{Rademacher}&lt;/script&gt; into
the problem which will allow us to bound the overfitting. Think of the Rademachers as
randomly permuting an example from the training set with an example from the ghost sample.
We want to control how much the risk changes when we exchange examples and do so via the
empirical Rademacher average&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_\sigma \left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \big( l_f(\tilde{z}_i) - l_f(z_i) \big) \right],&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;z_i = (x_i, y_i)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_f(z_i)&lt;/script&gt; is the loss function for &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; evaluated on
example &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt;. Now let’s manipulate this quantity, first distributing terms
and then exchanging the supremum with a sum to get an inequality:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E_\sigma &amp;\left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \big( l_f(\tilde{z}_i) - l_f(z_i) \big) \right]\\
	&amp;= \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) +
	   	\frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right] \\
	&amp;\le \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) + \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right] \\
	&amp;= \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	      \frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) \right] +
		\E_\sigma \left[ \sup_{f \in \mathcal{F}}
	      \frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So, this last calculation, the fact that &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; has the same distribution as
&lt;script type=&quot;math/tex&quot;&gt;-\sigma&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;z \sim \tilde{z}&lt;/script&gt;, imply that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right] \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right].&lt;/script&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… a short-and-sweet example of the material from this post and then the online learning
perspective!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicolò Cesa-Bianchi’s lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today’s post is the first in a set of three that will discuss two theories of learning. In particular, today’s post will cover (a very narrow aspect of) statistical learning theory. The next post will present a game-theoretic view of learning, using online learning as its primary analytical framework. The final post will connect the two perspectives.</summary></entry><entry><title type="html">The entropy method</title><link href="http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro.html" rel="alternate" type="text/html" title="The entropy method" /><published>2018-04-29T22:00:00-06:00</published><updated>2018-04-29T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro.html">&lt;p&gt;Welcome back! This post is going to start us down the path of the &lt;strong&gt;entropy method&lt;/strong&gt;
for obtaining concentration inequalities. The idea is pretty straightforward. We
take a (relevant) modified logarithmic Sobolev inequality and, via a Herbst-type
argument, derive exponential concentration inequalities.&lt;/p&gt;

&lt;p&gt;In a deviation from previous posts, we’re going to take as given the concentration
behavior (&lt;em&gt;i.e.&lt;/em&gt;, we’re doing an example instead of a proof) and look at a neat
application that puts it to work.&lt;/p&gt;

&lt;h3 id=&quot;an-eigenvalue-bound&quot;&gt;An eigenvalue bound&lt;/h3&gt;

&lt;p&gt;The largest eigenvalue of a random symmetric matrix is a quantity that naturally
arises in many “modern” statistical problems—&lt;em&gt;e.g.&lt;/em&gt;, in random correlation matrices.
We can describe the behavior of the variance of this eigenvalue using the Efron–Stein
inequality; however, we can obtain concentration convergence rates using the entropy
method. In particular, we’ll use bounded differences-inspired condition to evoke
a fast concentration inequality.&lt;/p&gt;

&lt;p&gt;Assume we have independent random &lt;script type=&quot;math/tex&quot;&gt;X_{ij}, 1 \le i \le j \le n&lt;/script&gt; that are bounded
by 1 in absolute value. The symmetric matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; has entries &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt;. Our
object of interest is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Z = \lambda_{\max} = \sup_{\|u\| = 1} u^T A u = v^T A v,&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; is the eigenvector associated with &lt;script type=&quot;math/tex&quot;&gt;\lambda_{\max}&lt;/script&gt;. Assume that
&lt;script type=&quot;math/tex&quot;&gt;\tilde{X}_{ij}&lt;/script&gt; is an independent copy of &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}_{ij}&lt;/script&gt;
is the matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; with entropy &lt;script type=&quot;math/tex&quot;&gt;(i,j)&lt;/script&gt; replaced by the independent copy.
Similarly, let &lt;script type=&quot;math/tex&quot;&gt;\tilde{Z}_{ij}&lt;/script&gt; be the maximum eigenvalue of &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}_{ij}&lt;/script&gt;.
Here’s where it starts to get good.&lt;/p&gt;

&lt;p&gt;In the spirit of bounded differences, we can calculate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\big(Z - \tilde{Z}_{ij}\big)_+ &amp;\le
	(v^TAv - v^T\tilde{A}_{ij}v) \ind{} \{Z &gt; \tilde{Z}_{ij}\} \\
	&amp;= \big( v^T(A-\tilde{A}_{ij})v \big) \ind{} \{Z &gt; \tilde{Z}_{ij}\} \\
	&amp;\le 2 \left( v_i v_j \left( X_{ij} - \tilde{X}_{ij} \right) \right)_+ \\
	&amp;\le 4 |v_i v_j|.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The first line results from the assumption on &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; and the use of the indicator variable.
The third line follows from a rewriting of the matrix multiplication and the observation
that all but two entries of the sum cancel each other.&lt;/p&gt;

&lt;p&gt;If we throw this guy into the Efron–Stein inequality, we get that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Var(Z) \le 16.&lt;/script&gt;

&lt;p&gt;Now, we can use the logarithmic Sobolev machinery to get the exponential
concentration inequality&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob(Z - \E Z &gt; t) \le e^{-t^2 / (2c)} = e^{-t^2 / (32)},&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; is a constant that bounds &lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^n (Z - \tilde{Z}_{ij})^2&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;linear-algebra-aside&quot;&gt;Linear algebra aside&lt;/h3&gt;

&lt;p&gt;A theorem from linear algebra tells us that the maximum eigenvalue of a symmetric
matrix is upper-bounded by the largest row sum and lower-bounded the smallest row
sum. So, the above ideas become interesting and useful when have big matrices…
precisely the kind arising in &lt;em&gt;modern&lt;/em&gt; applications!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… honestly, I’m not sure! I’m thinking we could start to unpack the machinery
that supported our blind use of the entropy method. Or it could be about bandits,
prediction with expert advice, Markov chains, something from convex optimization…&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapters 3 and 6 of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Welcome back! This post is going to start us down the path of the entropy method for obtaining concentration inequalities. The idea is pretty straightforward. We take a (relevant) modified logarithmic Sobolev inequality and, via a Herbst-type argument, derive exponential concentration inequalities.</summary></entry><entry><title type="html">Rademachers are rad - part III</title><link href="http://localhost:4000/jekyll/update/2018/04/25/rademacher_3.html" rel="alternate" type="text/html" title="Rademachers are rad - part III" /><published>2018-04-25T17:00:00-06:00</published><updated>2018-04-25T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/25/rademacher_3</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/25/rademacher_3.html">&lt;p&gt;After some ambivalence, I decided that we’ll pay homage to our Rademacher friends
once again. We’re going to prove a minimax lower bound for an expert prediction
problem. As we’ll see, Rademacher random variables will come to our rescue 
(twice, in fact).&lt;/p&gt;

&lt;h3 id=&quot;prediction-with-experts&quot;&gt;Prediction with experts&lt;/h3&gt;

&lt;p&gt;Let’s say that we disagree with statistical learning theory on philosophical grounds,
&lt;em&gt;i.e.&lt;/em&gt;, we don’t believe that our data are generated via a stochastic model that
assumes independence (or exchangeability). Can we predict in the absence of a
statistical assumptions? If so, how would we do it?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Can we predict in the absence of a statistical assumptions?&lt;/em&gt; &lt;strong&gt;Yes!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;If so, how could we do it?&lt;/em&gt; &lt;strong&gt;Using the advice of experts!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;prediction with expert advice&lt;/strong&gt; framework has the following set up:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a decision space &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;an outcome space &lt;script type=&quot;math/tex&quot;&gt;\mathcal{Y}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;a loss function &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;; and&lt;/li&gt;
  &lt;li&gt;a set of expert indices &lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}&lt;/script&gt;;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t = 1, 2, \dots&lt;/script&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;the environment chooses the next outcome &lt;script type=&quot;math/tex&quot;&gt;y_t&lt;/script&gt; and the experts choose
 &lt;script type=&quot;math/tex&quot;&gt;\left\{ f_{E,t} \in \mathcal{D} \mid E \in \mathcal{E} \right\}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the expert advice is provided to the forecaster;&lt;/li&gt;
  &lt;li&gt;the forecast chooses a prediction &lt;script type=&quot;math/tex&quot;&gt;\widehat{p}_t \in \mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the environment reveals the next outcome &lt;script type=&quot;math/tex&quot;&gt;y_t \in \mathcal{Y}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the forecaster incurs a loss &lt;script type=&quot;math/tex&quot;&gt;l(\widehat{p}_t, y_t)&lt;/script&gt; and each expert &lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt; incurs
 a loss &lt;script type=&quot;math/tex&quot;&gt;l(f_{E,t}, y_t)&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;minimax-lower-bound&quot;&gt;Minimax lower bound&lt;/h3&gt;

&lt;p&gt;We want to show that if &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is the absolute loss, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sup_{n,N} \frac{\mathfrak{M}(n,N,l)}{\sqrt{(n/2) \ln N}} \ge 1&lt;/script&gt;

&lt;p&gt;where the minimax regret &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n,N,l) = \inf_P \sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } 
	\sup_{y^n \in \mathcal{Y}^n} \max_{i=1,\dots,N}
	\left\{ \sum_{i=1}^n l(\hat{p}_t, y_t) - l \left( f_{i,t}, y_t \right) \right\},&lt;/script&gt;

&lt;p&gt;with &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt; is a set of &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; static experts, &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; is a forecasting strategy, 
&lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is a &lt;script type=&quot;math/tex&quot;&gt;[0,1]&lt;/script&gt;-valued convex loss function, and &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is the number of rounds.
(A static expert is one with constant-valued predictions, &lt;em&gt;i.e.&lt;/em&gt;, they only depend on the 
current round.)&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;We’re going to lower bound a lower bound on &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}(n,N,l)&lt;/script&gt;, which may seem
odd, but is a fairly common technique. (So keep it in your back pocket the next time
you have to bound something.) In particular, we’re going to use the fact that a fixed
class of static experts lower bounds the minimax regret as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n,N,l) \ge 
	\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l)&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l) = \inf_P \sup_{y^n \in \{0,1\}} \sup_{f \in \mathcal{F}}
	\left\{ \sum_{t=1}^n |\hat{p}_t - y_t| -  |f_t - y_t| \right\}.&lt;/script&gt;

&lt;p&gt;Then we’ll lower bound &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l)&lt;/script&gt;, which implies the minimax
regret bound.&lt;/p&gt;

&lt;p&gt;First, we use the &lt;em&gt;average-is-less-than-the-max&lt;/em&gt; trick to get&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l) \ge \inf_P \E \left[ \sup_{f \in \mathcal{F}}
	\left\{ \sum_{t=1}^n |\hat{p}_t - Y_t| -  |f_t - Y_t| \right\} \right],&lt;/script&gt;

&lt;p&gt;where the expectation is over the randomness in &lt;script type=&quot;math/tex&quot;&gt;Y_t&lt;/script&gt;. By the definitions of the 
infimum and supremum, we can rewrite this guy as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\inf_P \E \left[ \sum_{t=1}^n |\hat{p}_t - Y_t| \right] -  
 \E \left[ \inf_{f \in \mathcal{F}} \sum_{t=1}^n |f_t - Y_t| \right].&lt;/script&gt;

&lt;p&gt;Okay, cool. Now we’re going to use the fact that 
&lt;script type=&quot;math/tex&quot;&gt;\E \sum_{t=1}^n |\hat{p}_t - Y_t| = n/2&lt;/script&gt; for all
forecasting strategies because of the randomness of the &lt;script type=&quot;math/tex&quot;&gt;Y_t&lt;/script&gt;. (To see this, split the
absolute value into two parts, enjoy some nice cancellations and sum it all up.)
We’ll use this fact and then introduce some Rademacher random variables defined as 
&lt;script type=&quot;math/tex&quot;&gt;W_t = 1 - 2Y_t&lt;/script&gt; to write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathfrak{M}(n, \mathcal{F}, l) &amp;\ge 
\frac{n}{2} - \E \left[ \inf_{f \in \mathcal{F}} \sum_{t=1}^n |f_t - Y_t| \right] \\
	&amp;= \E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n \frac{1}{2} - |f_t - Y_t| \right]\\
	&amp;= \E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n 
		\left( \frac{1}{2} - f_t \right)  W_t \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now, let’s take supremums of both sides, do another Rademacher trick, and then 
exploit the symmetry of Rademachers:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l) 
	&amp;\ge \sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } 
		\E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n \left( \frac{1}{2} - f_t \right) 
		 W_t \right] \\
	&amp;\ge \frac{1}{2} \E \left[ \max_{i=1,...,N} \sum_{t=1}^n Z_{i,t} W_t \right] \\
	&amp;= \frac{1}{2} \E \left[ \max_{i=1,...,N} \sum_{t=1}^n Z_{i,t} \right],
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where we used that &lt;script type=&quot;math/tex&quot;&gt;(1/2)(1 - 2f_t) = (1/2)Z_{i,t}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Z_{i,t}W_t \sim Z_{i,t}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The final step is an appeal to &lt;em&gt;ye-old&lt;/em&gt; central limit theorem and a maximal inequality
for (sub-)Gaussian random variables. The CLT says that for each &lt;script type=&quot;math/tex&quot;&gt;i = 1,\dots,N&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{\sqrt{n}} \sum_{t=1}^n Z_{i,t} \sim N(0,1) \implies
\lim_{n \to \infty} \E \left[ \frac{1}{\sqrt{n}} \max_{i=1,...,N} 
								\sum_{t=1}^n Z_{i,t} \right] =
	\E \left[ \max_{i=1,...,N} X_i \right].&lt;/script&gt;

&lt;p&gt;for standard normals &lt;script type=&quot;math/tex&quot;&gt;X_1,\dots,X_n&lt;/script&gt;. The maximal inequality gives&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E \left[ \max_{i=1,...,N} X_i \right] \le \sqrt{2 \ln N}.&lt;/script&gt;

&lt;p&gt;Now, we stitch everything back together and conclude the proof with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathfrak{M}(n,N,l) &amp;\ge 
	\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l) \\
	&amp;\ge \frac{\E \left[ \max_{i=1,...,N} X_i \right]}{\sqrt{2 \ln N}} \\
	&amp;\ge 1.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Rademacher’s to the rescue once again.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… modified logarithmic Sobolev inequalities &lt;strong&gt;or&lt;/strong&gt; bandits!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapters 2 and 3 of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Prediction, Learning, and Games&lt;/em&gt; by N. Cesa-Bianchi and G. Lugosi.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">After some ambivalence, I decided that we’ll pay homage to our Rademacher friends once again. We’re going to prove a minimax lower bound for an expert prediction problem. As we’ll see, Rademacher random variables will come to our rescue (twice, in fact).</summary></entry><entry><title type="html">A neat inequality</title><link href="http://localhost:4000/jekyll/update/2018/04/21/ineq.html" rel="alternate" type="text/html" title="A neat inequality" /><published>2018-04-21T17:00:00-06:00</published><updated>2018-04-21T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/21/ineq</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/21/ineq.html">&lt;p&gt;As promised, this post will be about the useful inequality from 
&lt;a href=&quot;/jekyll/update/2018/04/07/lsi.html&quot;&gt;logarithmic Sobolev inequality post&lt;/a&gt;. Without further ado…&lt;/p&gt;

&lt;h3 id=&quot;starting-simple&quot;&gt;Starting simple&lt;/h3&gt;

&lt;p&gt;We are going to prove the inequality&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left( e^{z/2} - e^{y/2} \right)^2 \le \frac{(z-y)^2}{8}(e^{z} + e^{y})&lt;/script&gt;

&lt;p&gt;for real numbers &lt;script type=&quot;math/tex&quot;&gt;z \ge y&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;We can rewrite the inequality as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left( e^{(z-y)/2} - 1 \right)^2 \le \frac{(z-y)^2}{8}(e^{z-y} + 1).&lt;/script&gt;

&lt;p&gt;Now, let’s define &lt;script type=&quot;math/tex&quot;&gt;x = z - y&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;x \ge 0&lt;/script&gt; because &lt;script type=&quot;math/tex&quot;&gt;z \ge y&lt;/script&gt;. Let’s
move everything to the righthand side and open up the square, which gives&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0 \le \frac{x^2}{8} (e^x + 1) - \left( e^x - 2e^{x/2} + 1 \right).&lt;/script&gt;

&lt;p&gt;Now, let’s collect like terms&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0 \le e^x \left( \frac{x^2}{8} - 1 \right) + \frac{x^2}{8} + 2e^{x/2} - 1 = f(x).&lt;/script&gt;

&lt;p&gt;When &lt;script type=&quot;math/tex&quot;&gt;x = 0&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;f(x)&lt;/script&gt;, &lt;em&gt;i.e.&lt;/em&gt;, the righthand side, is also 0. Let’s look at the
derivative of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; to see whether the function is increasing or decreasing:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{df(x)}{dx} = \frac{1}{8} e^x (x^2 + 2x - 8) + \frac{x}{4} + e^{x/2}.&lt;/script&gt;

&lt;p&gt;Unfortunately, that pesky &lt;script type=&quot;math/tex&quot;&gt;-e^x&lt;/script&gt; means we still have some work to do. Let’s 
keep taking derivatives and see if we can’t get rid of that negative:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac{d^2f(x)}{dx^2} &amp;= 
	\frac{1}{8} \left( e^x \left( x^2 + 4x - 6 \right) + 4e^{x/2} + 2 \right) \\
\frac{d^3f(x)}{dx^3} &amp;= 
	\frac{1}{8} \left( e^x \left( x^2 + 6x - 2 \right) + 2e^{x/2} \right) \\
\frac{d^4f(x)}{dx^4} &amp;= 
	\frac{1}{8} \left( e^x \left( x^2 + 8x + 4 \right) + e^{x/2} \right).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Cool! The righthand side of &lt;script type=&quot;math/tex&quot;&gt;\frac{d^4f(x)}{dx^4} &gt; 0&lt;/script&gt; since &lt;script type=&quot;math/tex&quot;&gt;x \ge 0&lt;/script&gt;. 
Also, we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{df(0)}{dx} = \frac{d^2f(0)}{dx^2} = \frac{d^3f(0)}{dx^3} = 0,&lt;/script&gt;

&lt;p&gt;which means we’re in good shape (because the fourth derivative being positive). 
In particular, we integrate the fourth derivative four times and conclude that 
our original function that is always greater than or equal to zero&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
0 \le
\int \frac{d^4f(x)}{dx^4} \, d^4x &amp;= \frac{e^x (x^2 - 8)}{8} + 2 e^{(x/2)}
	+ \frac{c_1 x^3}{6} + \frac{c_2 x^2}{2} + c_3 x + c_4 \\
		&amp;= e^x \left( \frac{x^2}{8} - 1 \right) + \frac{x^2}{8} + 2e^{x/2} - 1,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;c_4 = -1&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;c_3 = 0&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;c_2 = 1/4&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;c_1 = 0&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;remarks&quot;&gt;Remarks&lt;/h4&gt;

&lt;p&gt;This inequality is neat because you can approach it a few different ways. If
we didn’t use &lt;script type=&quot;math/tex&quot;&gt;x = z - y&lt;/script&gt;, and worked directly with the function of &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;
and &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;, we could’ve gotten away with taking two derivatives instead of 
four. I find the “&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;-consolidated”, “fourth derivative” approach easier 
as it requires less bookkeeping for &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;And the best for last: the easiest way to solve this problem is to plot it. 😏&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… more Rademacher rad-ness, modified logarithmic Sobolev inequalities &lt;strong&gt;or&lt;/strong&gt; 
bandits!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapter 5 of (my new favorite book):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by 
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">As promised, this post will be about the useful inequality from logarithmic Sobolev inequality post. Without further ado…</summary></entry><entry><title type="html">Upper confidence bounds</title><link href="http://localhost:4000/jekyll/update/2018/04/18/ucb.html" rel="alternate" type="text/html" title="Upper confidence bounds" /><published>2018-04-18T21:00:00-06:00</published><updated>2018-04-18T21:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/18/ucb</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/18/ucb.html">&lt;p&gt;Today we’re going to prove the upper bound that results from the upper
confidence bound (UCB) strategy. The UCB strategy allowed us to bound
the pseudo-regret by a term which is logarithmic in the number of
rounds played. Generally speaking, “good” regret bounds for bandit problems
are sublinear in the number of rounds played.&lt;/p&gt;

&lt;h3 id=&quot;stochastic-bandit-problems&quot;&gt;Stochastic bandit problems&lt;/h3&gt;

&lt;p&gt;As a quick review, here’s the set-up for the stochastic multi-armed bandit
problem.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are &lt;script type=&quot;math/tex&quot;&gt;\{1,\dots,K\}&lt;/script&gt; arms.&lt;/li&gt;
  &lt;li&gt;Each arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; corresponds to an unknown probability distribution &lt;script type=&quot;math/tex&quot;&gt;p_i&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, the player selects an arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; (independently of 
previous choices) and receives a reward &lt;script type=&quot;math/tex&quot;&gt;X_{I_t,t} \sim p_{I_t}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;We assess a player’s performance by her &lt;strong&gt;regret&lt;/strong&gt;, which
compares her performance to (something like) the best-possible performance.&lt;/li&gt;
  &lt;li&gt;After the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds of the game, the player’s regret is&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_n = \max_{i=1,\dots,K} \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t},&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;where &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; is the number of bandit arms, &lt;script type=&quot;math/tex&quot;&gt;X_{i,t}&lt;/script&gt; is the reward of arm 
&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; is the player’s (possibly randomly) chosen arm.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll denote the mean of distribution &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;\mu_i&lt;/script&gt; and define&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu^\star = \max_{i=1,\dots,K} \mu_i \quad \textsf{and} \quad
	i^\star = \argmax_{i=1,\dots,K} \mu_i&lt;/script&gt;

&lt;p&gt;as optimal parameters. Instead of using the regret to assess our player’s performance,
we’ll use the &lt;strong&gt;pseudo-regret&lt;/strong&gt;, which is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\bar{R}_n &amp;= \max_{i=1,\dots,K} \E 
	\left[ \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t} \right] \\
	&amp;= n \mu^\star - \E \sum_{t=1}^n \mu_{I_t}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;We know that &lt;script type=&quot;math/tex&quot;&gt;\bar{R}_n \le \E R_n&lt;/script&gt; because of Jensen’s inequality for convex 
functions. For our purposes, a more informative form of the pseudo-regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n = \sum_{i=1}^K \Delta_i \E T_i(n),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\Delta_i = \mu^\star - \mu_i&lt;/script&gt; is the suboptimality of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and the
random variable &lt;script type=&quot;math/tex&quot;&gt;T_i(n) = \sum_{i=1}^n \ind{}\{I_t = i\}&lt;/script&gt; is the number of times 
arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is selected in the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds.&lt;/p&gt;

&lt;h3 id=&quot;upper-confidence-bounds&quot;&gt;Upper confidence bounds&lt;/h3&gt;

&lt;p&gt;One approach for simultaneously performing &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;exploitation&lt;/strong&gt; is 
to use &lt;strong&gt;upper confidence bound&lt;/strong&gt; (UCB) strategies. UCB strategies produce upper
bounds (based on a confidence level) on the current estimate for each arm’s mean 
reward. The player selects the arm that is the best using the UCB-modified estimate.&lt;/p&gt;

&lt;p&gt;In the spirit of brevity, we’re going to gloss over a few important details 
(&lt;em&gt;e.g.&lt;/em&gt;, Legendre–Fenchel duals and Hoeffding’s lemma) but here’s the gist of 
the UCB set-up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define &lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,n} = \frac{1}{n} \sum_{j=1}^n X_{i,j}&lt;/script&gt; as the sample
mean of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; after being played &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; times.&lt;/li&gt;
  &lt;li&gt;For a convex function &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; with convex conjugate &lt;script type=&quot;math/tex&quot;&gt;\psi^*&lt;/script&gt; and parameter 
&lt;script type=&quot;math/tex&quot;&gt;\lambda &gt; 0&lt;/script&gt;, the cumulant generating function of &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; is bounded by &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln \E e^{\lambda(X - \E X)} \le \psi(\lambda) \quad \textsf{and} \quad
\ln \E e^{\lambda(\E X - X)} \le \psi(\lambda).&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;By Markov’s inequality and the Cramér–Chernoff technique&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left( \mu_i - \widehat{\mu}_{i,n} \ge \varepsilon \right) \le
	e^{-n \psi^*(\varepsilon)}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Markov’s inequality means that, with probability &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;, we have an 
upper bound on the estimate of the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th arm:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mu_i &lt; \widehat{\mu}_{i,n} + (\psi^*)^{-1} 
	\left(\frac{1}{n} \ln \frac{1}{\delta} \right). %]]&gt;&lt;/script&gt;

&lt;p&gt;The &lt;strong&gt;UCB strategy&lt;/strong&gt; is (very) simple; at each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, select the arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_t \in \argmax_{i=1,\dots,K} \left\{ \widehat{\mu}_{i,T_i(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) \right\}.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;The tradeoff.&lt;/strong&gt;
Let’s pick apart this term and see how it encourages exploration and exploitation.
We’re going to use &lt;script type=&quot;math/tex&quot;&gt;\psi(x) = x^2/8&lt;/script&gt; with convex conjugate 
&lt;script type=&quot;math/tex&quot;&gt;\psi^*(z) = 2z^2&lt;/script&gt;, so that &lt;script type=&quot;math/tex&quot;&gt;(\psi^*)^{-1}(z) = (x/2)^{1/2}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;When arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; has not been played many times before time $t$, &lt;em&gt;i.e.&lt;/em&gt;, when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; is small numerator of &lt;script type=&quot;math/tex&quot;&gt;\frac{\alpha \ln t}{T_i(t-1)}&lt;/script&gt; dominates 
and the UCB-adjusted estimate of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is likely to relatively high, which
encourages arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; to be chosen. In other words, it encourages exploration.&lt;/p&gt;

&lt;p&gt;As arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is chosen more, &lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; increases and the estimate
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; improves. If arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is the optimal arm, then the 
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; term dominates the estimates for other arms and the
UCB-adjustment further encourages selection of this arm. This means that the 
algorithm exploits high-yielding arms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Upper bound on pseudo-regret.&lt;/strong&gt;
If our player follows the UCB scheme specified above, then for &lt;script type=&quot;math/tex&quot;&gt;\alpha &gt; 2&lt;/script&gt;
her pseudo-regret is upperbounded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n \le \sum_{i: \Delta_i &gt; 0} \left( 
\frac{\alpha \Delta_i}{\psi^*(\Delta_i / 2)} \ln n + \frac{\alpha}{\alpha - 2} 
\right).&lt;/script&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;Okay, here goes. We incur regret when we don’t pick the optimal arm, &lt;em&gt;i.e.&lt;/em&gt;,
when &lt;script type=&quot;math/tex&quot;&gt;I_t \neq i^\star&lt;/script&gt;. So, we need to analyze the conditions that lead
us to choose a suboptimal arm.&lt;/p&gt;

&lt;p&gt;Assume we’ve played arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; a total of &lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; times and arm &lt;script type=&quot;math/tex&quot;&gt;i^\star&lt;/script&gt; 
a total of &lt;script type=&quot;math/tex&quot;&gt;T_{i^\star}(t-1)&lt;/script&gt; times. By the set up of our bandit scenario, 
if &lt;script type=&quot;math/tex&quot;&gt;I_t = i&lt;/script&gt;, &lt;em&gt;i.e.&lt;/em&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_t = i = \argmax_{j=1,\dots,K} \left\{ \widehat{\mu}_{j,T_j(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) \right\},&lt;/script&gt;

&lt;p&gt;then at least one of the following holds&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\widehat{\mu}_{i^\star, T_{i^\star}(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_{i^\star}(t-1)} \right) &amp;\le \mu^\star 
	&amp;&amp; \#1 \\
\mu_i + (\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) &amp;&lt; 
	\widehat{\mu}_{i, T_i(t-1)} &amp;&amp; \#2 \\
\mu^\star - 2(\psi^*)^{-1} \left( \frac{\alpha \ln n}{T_i(t-1)} \right) &amp;&lt; \mu_i &amp;&amp; \#3.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The first indicates that our current UCB-adjusted estimate of the mean for the
optimal arm is less than its true value. It occurs with probability&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left(  \widehat{\mu}_{i^\star, T_{i^\star}(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_{i^\star}(t-1)} \right) 
	\ge \mu^\star \right) \le 
	\exp \left ( -\alpha \ln t \right) = t^{-\alpha}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The second indicates that our estimate for arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; exceeds its true value by
an amount greater than the UCB—hence the UCB adjustment is not yet helpful. 
It occurs with probability&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left(  \mu_i + (\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) &gt; 
	\widehat{\mu}_{i, T_i(t-1)} \right) \le 
	\exp \left ( -\alpha \ln t \right) = t^{-\alpha}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The third follows from similar logic as the second, and is illuminated by 
the rewriting:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\Delta_i  = \mu^\star - \mu_i &amp;&lt; 
	2(\psi^*)^{-1} \left( \frac{\alpha \ln n}{T_i(t-1)} \right) \\
\psi^*(\Delta_i / 2) &lt; \frac{\alpha \ln n}{T_i(t-1)} &amp;\iff
T_i(t-1) &lt; \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The probability of the third event is 0 when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(n) \ge u = 
  \left\lceil \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} \right\rceil&lt;/script&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If #1, #2, and #3 are false, then we pick the optimal arm, meaning we incur
no regret.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, we let’s consider the implications of these events on &lt;script type=&quot;math/tex&quot;&gt;\E T_i(t-1)&lt;/script&gt;,
because this will allow us to bound the pseudo-regret. We have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E T_i(n) &amp;= \E \sum_{t=1}^n \ind{}\{I_t = i\} \\
	&amp;\le u + \E \sum_{t=u+1}^n \ind{}\{I_t = i \textsf{ and inequality #3 is false}\} \\
	&amp;\le u + \E \sum_{t=u+1}^n \ind{}\{\textsf{inequality #1 or #2 is true}\} \\
	&amp;= u + \sum_{t=u+1}^n \prob\left( \ind{\textsf{inequality #1}} \right) + 
		\prob\left( \ind{\textsf{inequality #2}} \right) \\
	&amp;\le u + 2\sum_{t=1}^n \sum_{s=1}^t \frac{1}{t^\alpha} \\
	&amp;= u + 2\sum_{t=1}^n \frac{1}{t^{\alpha-1}} \\
	&amp;\le \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} + 
		2 \int_{1}^{\infty} \frac{dt}{t^{\alpha-1}} \\
	&amp;= \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} + \frac{\alpha}{\alpha-2}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;em&gt;(It took me a few times to follow that argument, so I would re-read it a few times.
I also put some notes in the &lt;a href=&quot;#the-intermediate-steps&quot;&gt;intermediate steps&lt;/a&gt;
subsection below.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now, we just sum over the suboptimal arms to get the pseudo-regret bound&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n \le \sum_{i: \Delta_i &gt; 0} \left( 
\frac{\alpha \Delta_i}{\psi^*(\Delta_i / 2)} \ln n + \frac{\alpha}{\alpha - 2}
\right).&lt;/script&gt;

&lt;p&gt;This is the proof given in Bubeck and Cesa-Bianchi’s &lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;bandits survey&lt;/a&gt;, 
which is an adaptation of the proof of Auer, Cesa-Bianchi, and Fischer’s
&lt;a href=&quot;http://cesa-bianchi.di.unimi.it/Pubblicazioni/ml-02.pdf&quot;&gt;original analysis&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… a proof of that cool inequality that helped us in the proof of 
concentration inequality implied by the 
&lt;a href=&quot;/jekyll/update/2018/04/07/lsi.html&quot;&gt;logarithmic Sobolev inequality&lt;/a&gt; a few posts back!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems&lt;/em&gt;
by S. Bubeck and N. Cesa-Bianchi. A digital copy can be found 
&lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Finite-time Analysis of the Multiarmed Bandit Problem&lt;/em&gt; by P. Auer, N. 
Cesa-Bianchi, and P. Fischer. A digital copy can be found &lt;a href=&quot;http://cesa-bianchi.di.unimi.it/Pubblicazioni/ml-02.pdf&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Prediction, Learning, and Games&lt;/em&gt; (a.k.a. “Perdition, Burning, and Flames”) 
by N. Cesa-Bianchi and G. Lugosi. Find a description of the book and its 
table of contents &lt;a href=&quot;http://cesa-bianchi.di.unimi.it/predbook/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;the-intermediate-steps&quot;&gt;The intermediate steps&lt;/h4&gt;

&lt;p&gt;We can interpret the relationship&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E T_i(n) = \E \sum_{t=1}^n \ind{}\{I_t = i\} \le 
	u + \E \sum_{t=u+1}^n \ind{}\{I_t = i \textsf{ and inequality #3 is false}\}&lt;/script&gt;

&lt;p&gt;by observing that the indicator &lt;script type=&quot;math/tex&quot;&gt;\ind{}\{I_t = i\}&lt;/script&gt; and be written as
&lt;script type=&quot;math/tex&quot;&gt;\ind{}\{I_t = i \textsf{ and inequality #3 is false or true}\}&lt;/script&gt;. 
Inequality #3 is true when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(k) \le u = 
	\left\lceil \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} \right\rceil&lt;/script&gt;.
So, the bound follows by assuming that indicator is active at &lt;script type=&quot;math/tex&quot;&gt;k=1,\dots,u&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Because we allow either #1 or #2 to be true, the event&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\big\{I_t = i \textsf{ and inequality #3 is false}\big\} \subseteq
	\big\{\textsf{inequality #1 or #2 is true}\big\},&lt;/script&gt;

&lt;p&gt;meaning the probability of the second event is larger.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today we’re going to prove the upper bound that results from the upper confidence bound (UCB) strategy. The UCB strategy allowed us to bound the pseudo-regret by a term which is logarithmic in the number of rounds played. Generally speaking, “good” regret bounds for bandit problems are sublinear in the number of rounds played.</summary></entry><entry><title type="html">Bandits!</title><link href="http://localhost:4000/jekyll/update/2018/04/14/bandits.html" rel="alternate" type="text/html" title="Bandits!" /><published>2018-04-14T17:00:00-06:00</published><updated>2018-04-14T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/14/bandits</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/14/bandits.html">&lt;p&gt;Today we’re talking about bandits. Bandit problems, not dissimilar from Markov 
chains, are one of those simple models that apply to a wide variety of
problems. Indeed, many results of “sequential decision making” stem from
the study of bandit problems. Plus the name is cool, so that should provide
some motivation for wanting to study them. The name &lt;strong&gt;bandit&lt;/strong&gt; originates 
from the term &lt;strong&gt;one-armed bandit&lt;/strong&gt;, which was used to describe slot machines.&lt;/p&gt;

&lt;p&gt;In their &lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;survey on bandits&lt;/a&gt;, Bubeck and Cesa-Bianchi define 
a multi-armed bandit problem as “a sequential allocation problem defined by a 
set of actions.” The allocation problem is similar to a (repeated) game: at 
each point in time, the player chooses an action &lt;em&gt;i.e.&lt;/em&gt;, an arm, and receives 
a reward.&lt;/p&gt;

&lt;p&gt;The player’s goal is to maximize her cumulative reward, which naturally leads to
an &lt;strong&gt;exploitation vs. exploration&lt;/strong&gt; problem. The player needs to simultaneously 
exploit arms known to yield high rewards and explore other arms in the hopes 
of finding other high-yield rewards.&lt;/p&gt;

&lt;p&gt;In bandit problems, we assess a player’s performance by her &lt;strong&gt;regret&lt;/strong&gt;, which
compares her performance to (something like) the best-possible performance. 
After the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds of the game, the player’s regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_n = \max_{i=1,\dots,K} \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t},&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; is the number of bandit arms, &lt;script type=&quot;math/tex&quot;&gt;X_{i,t}&lt;/script&gt; is the reward of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at
time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; is the player’s (possibly randomly) chosen arm.&lt;/p&gt;

&lt;h3 id=&quot;stochastic-bandit-problems&quot;&gt;Stochastic bandit problems&lt;/h3&gt;

&lt;p&gt;In this post, we’re going to focus on &lt;strong&gt;stochastic bandit problems&lt;/strong&gt; as opposed
to &lt;strong&gt;adversarially bandit problems&lt;/strong&gt;. Here’s the set-up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are &lt;script type=&quot;math/tex&quot;&gt;\{1,\dots,K\}&lt;/script&gt; arms.&lt;/li&gt;
  &lt;li&gt;Each arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; corresponds to an unknown probability distribution &lt;script type=&quot;math/tex&quot;&gt;p_i&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, the player selects an arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; (independently of 
previous choices) and receives a reward &lt;script type=&quot;math/tex&quot;&gt;X_{I_t,t} \sim p_{I_t}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll denote the mean of distribution &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;\mu_i&lt;/script&gt; and define&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu^\star = \max_{i=1,\dots,K} \mu_i \quad \textsf{and} \quad
	i^\star = \argmax_{i=1,\dots,K} \mu_i&lt;/script&gt;

&lt;p&gt;as optimal parameters. Instead of using the regret to assess our player’s performance,
we’ll use the &lt;strong&gt;pseudo-regret&lt;/strong&gt;, which is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\bar{R}_n &amp;= \max_{i=1,\dots,K} \E 
	\left[ \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t} \right] \\
	&amp;= n \mu^\star - \E \sum_{t=1}^n \mu_{I_t}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;We know that &lt;script type=&quot;math/tex&quot;&gt;\bar{R}_n \le \E R_n&lt;/script&gt; because of Jensen’s inequality for convex 
functions. For our purposes, a more informative form of the pseudo-regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n = \sum_{i=1}^K \Delta_i \E T_i(n),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\Delta_i = \mu^\star - \mu_i&lt;/script&gt; is the suboptimality of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and the
random variable &lt;script type=&quot;math/tex&quot;&gt;T_i(n) = \sum_{i=1}^n \ind{}\{I_t = i\}&lt;/script&gt; is the number of times 
arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is selected in the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds.&lt;/p&gt;

&lt;p&gt;This alternative expression for the pseudo-regret sums over arms rather than rounds.
To see how we switched from arms to rounds, play around with random variables 
&lt;script type=&quot;math/tex&quot;&gt;T_i(n)&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;upper-confidence-bounds&quot;&gt;Upper confidence bounds&lt;/h3&gt;

&lt;p&gt;One approach for simultaneously performing &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;exploitation&lt;/strong&gt; is 
to use &lt;strong&gt;upper confidence bound&lt;/strong&gt; (UCB) strategies. UCB strategies produce upper
bounds (based on a confidence level) on the current estimate for each arm’s mean 
reward. The player selects the arm that is the best using the UCB-modified estimate.&lt;/p&gt;

&lt;p&gt;In the spirit of brevity, we’re going to gloss over a few important details 
(&lt;em&gt;e.g.&lt;/em&gt;, Legendre–Fenchel duals and Hoeffding’s lemma) but here’s the gist of 
the UCB set-up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define &lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,n} = \frac{1}{n} \sum_{j=1}^n X_{i,j}&lt;/script&gt; as the sample
mean of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; after being played &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; times.&lt;/li&gt;
  &lt;li&gt;For a convex function &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; with convex conjugate &lt;script type=&quot;math/tex&quot;&gt;\psi^*&lt;/script&gt; and parameter 
&lt;script type=&quot;math/tex&quot;&gt;\lambda &gt; 0&lt;/script&gt;, the cumulant generating function of &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; is bounded by &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln \E e^{\lambda(X - \E X)} \le \psi(\lambda) \quad \textsf{and} \quad
\ln \E e^{\lambda(\E X - X)} \le \psi(\lambda).&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;By Markov’s inequality and the Cramér–Chernoff technique&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left( \mu_i - \widehat{\mu}_{i,n} \ge \varepsilon \right) \le
	e^{-n \psi^*(\varepsilon)}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Markov’s inequality means that, with probability &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;, we have an 
upper bound on the estimate of the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th arm:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mu_i &lt; \widehat{\mu}_{i,n} + (\psi^*)^{-1} 
	\left(\frac{1}{n} \ln \frac{1}{\delta} \right). %]]&gt;&lt;/script&gt;

&lt;p&gt;The UCB strategy is (very) simple; at each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, select the arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_t \in \argmax_{i=1,\dots,K} \left\{ \widehat{\mu}_{i,T_i(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) \right\}.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;The tradeoff.&lt;/strong&gt;
Let’s pick apart this term and see how it encourages exploration and exploitation.
We’re going to use &lt;script type=&quot;math/tex&quot;&gt;\psi(x) = x^2/8&lt;/script&gt; with convex conjugate 
&lt;script type=&quot;math/tex&quot;&gt;\psi^*(z) = 2z^2&lt;/script&gt;, so that &lt;script type=&quot;math/tex&quot;&gt;(\psi^*)^{-1}(z) = (x/2)^{1/2}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;When arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; has not been played many times before time $t$, &lt;em&gt;i.e.&lt;/em&gt;, when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; is small numerator of &lt;script type=&quot;math/tex&quot;&gt;\frac{\alpha \ln t}{T_i(t-1)}&lt;/script&gt; dominates 
and the UCB-adjusted estimate of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is likely to relatively high, which
encourages arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; to be chosen. In other words, it encourages exploration.&lt;/p&gt;

&lt;p&gt;As arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is chosen more, &lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; increases and the estimate
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; improves. If arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is the optimal arm, then the 
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; term dominates the estimates for other arms and the
UCB-adjustment further encourages selection of this arm. This means that the 
algorithm exploits high-yielding arms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Upper bound on pseudo-regret.&lt;/strong&gt;
If our player follows the UCB scheme specified above, then for &lt;script type=&quot;math/tex&quot;&gt;\alpha &gt; 2&lt;/script&gt;
her pseudo-regret is upperbounded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n \le \sum_{i: \Delta_i &gt; 0} \left( 
\frac{\alpha \Delta_i}{\psi^*(\Delta_i / 2)} \ln n + \frac{\alpha}{\alpha - 2} 
\right).&lt;/script&gt;

&lt;p&gt;We’re going to prove the bound in the next post.&lt;/p&gt;

&lt;h3 id=&quot;bandit-simulations&quot;&gt;Bandit simulations&lt;/h3&gt;

&lt;p&gt;Here’s an &lt;a href=&quot;https://github.com/jakeknigge/ucb-bandits/blob/master/bandits.R&quot;&gt;R script&lt;/a&gt; which uses the upper confidence bound algorithm.
For the plots below, there are &lt;script type=&quot;math/tex&quot;&gt;K = 3&lt;/script&gt; arms and &lt;script type=&quot;math/tex&quot;&gt;n = 1000&lt;/script&gt; rounds. The reward 
distributions are Bernoulli’s and the mean parameters the three arms are 0.46, 0.72, 
and 0.55.&lt;/p&gt;

&lt;p&gt;The first plot shows the evolution of each mean estimate as different rounds are
played.
&lt;img src=&quot;/assets/2018-04-14_bandit_arm_est.png&quot; alt=&quot;Bandit arm estimates&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next plot illustrates the exploration vs. exploitation trade-off. Even
though arm 2 yields the highest rewards, the algorithm occasionally plays 
arms 1 and 3 in later rounds.
&lt;img src=&quot;/assets/2018-04-14_bandit_arms_played.png&quot; alt=&quot;Bandit regret&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The final plot shows the player’s cumulative regret compared to the UCB-implied
upper bound on the regret; the lower bound is distribution-dependent and
asymptotic, which is why it exceeds the pseudo-regret until round 400ish.
&lt;img src=&quot;/assets/2018-04-14_bandit_regret.png&quot; alt=&quot;Bandit regret&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… a proof of the upper confidence bound regret rate!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems&lt;/em&gt;
by S. Bubeck and N. Cesa-Bianchi. A digital copy can be found 
&lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Prediction, Learning, and Games&lt;/em&gt; (a.k.a. “Perdition, Burning, and Flames”) 
by N. Cesa-Bianchi and G. Lugosi. Find a description of the book and its 
table of contents &lt;a href=&quot;http://cesa-bianchi.di.unimi.it/predbook/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I would also recommend checking out Sébastien Bubeck’s blog 
&lt;a href=&quot;https://blogs.princeton.edu/imabandit&quot;&gt;“I’m a bandit”&lt;/a&gt; and, in particular, his bandit tutorials:
&lt;a href=&quot;https://blogs.princeton.edu/imabandit/2016/05/11/bandit-theory-part-i/&quot;&gt;part 1&lt;/a&gt; and &lt;a href=&quot;https://blogs.princeton.edu/imabandit/2016/05/13/bandit-theory-part-ii/&quot;&gt;part 2&lt;/a&gt;. Also check out his new YouTube
channel: https://www.youtube.com/user/sebastienbubeck/videos.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today we’re talking about bandits. Bandit problems, not dissimilar from Markov chains, are one of those simple models that apply to a wide variety of problems. Indeed, many results of “sequential decision making” stem from the study of bandit problems. Plus the name is cool, so that should provide some motivation for wanting to study them. The name bandit originates from the term one-armed bandit, which was used to describe slot machines.</summary></entry><entry><title type="html">Logarithmic Sobolev inequalities</title><link href="http://localhost:4000/jekyll/update/2018/04/07/lsi.html" rel="alternate" type="text/html" title="Logarithmic Sobolev inequalities" /><published>2018-04-07T17:00:00-06:00</published><updated>2018-04-07T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/07/lsi</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/07/lsi.html">&lt;p&gt;As promised, this post will be about logarithmic Sobolev inequalities, which
are (exponential) concentration inequalities for functions defined on the
binary hypercube. In particular, we’ll review a specific case where we
get speedy concentration thanks to a variance-like bound on our function of
interest. Let’s concentrate some measure!&lt;/p&gt;

&lt;h3 id=&quot;starting-simple&quot;&gt;Starting simple&lt;/h3&gt;

&lt;p&gt;To get things going, we’ll look at a logarithmic Sobolev inequality for a 
function defined on the &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; dimensional binary hypercube&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f: \{-1,1\}^n \to \reals.&lt;/script&gt;

&lt;p&gt;Our random variables &lt;script type=&quot;math/tex&quot;&gt;X \in \{-1,1\}^n&lt;/script&gt; are Rademacher random variables, 
&lt;em&gt;i.e.&lt;/em&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
g_X(x) = 
\begin{cases}
+1, &amp; \textsf{with probability } 0.5 \\
-1, &amp; \textsf{with probability } 0.5.
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;We define &lt;script type=&quot;math/tex&quot;&gt;Z = f(X)&lt;/script&gt; as our real-valued random variable of interest. 
Logarithmic Sobolev inequalities compare to quantities related to &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;entropy functional&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(f) = \E \big[ f(X) \log f(X) \big] - 
				  \E f(X) \log \big( \E f(X) \big)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Efron–Stein-like functional&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{E}(f) = \frac{1}{2} \E \left[ \sum_{i=1}^n \left( f(X) - 
	f \left( \tilde{X}^{(i)} \right) \right)^2 \right].&lt;/script&gt;

&lt;p&gt;The quantity &lt;script type=&quot;math/tex&quot;&gt;\tilde{X}^{(i)}&lt;/script&gt; is the vector &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; with its &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th
component drawn from an independent copy—this is the same idea as in the
Efron–Stein inequality. For our purposes, this implies that &lt;script type=&quot;math/tex&quot;&gt;X_i&lt;/script&gt; changes
sign.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;logarithmic Sobolev inequality&lt;/strong&gt;for this set up is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(f^2) \le 2 \mathcal{E}(f).&lt;/script&gt;

&lt;h3 id=&quot;concentration-inequality&quot;&gt;Concentration inequality&lt;/h3&gt;

&lt;p&gt;With our logarithmic Sobolev inequality pinned down, we’ll now prove
a concentration inequality for a function satisfying&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^n \left( f(x) - f \left( \tilde{x}^{(i)} \right) \right)^2 \le v&lt;/script&gt;

&lt;p&gt;for some &lt;script type=&quot;math/tex&quot;&gt;v &gt; 0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;x \in \{-1,1\}^n&lt;/script&gt;. In particular, we’ll show that
for all &lt;script type=&quot;math/tex&quot;&gt;t &gt; 0&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob(Z &gt; \E Z + t) \le e^{-2t^2/v}.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Technical detail—hint.&lt;/strong&gt;
The proof hinges on the following fact (which we’ll show in a later post
because it uses some nice ideas)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left( e^{z/2} - e^{y/2} \right)^2 \le \frac{(z-y)^2}{8}(e^{z} + e^{y})&lt;/script&gt;

&lt;p&gt;for &lt;script type=&quot;math/tex&quot;&gt;z \ge y&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;We’re going to follow the so-called &lt;strong&gt;Herbst argument&lt;/strong&gt; to prove the
concentration inequality. The key ingredient of Herbst’s argument is the use
of a &lt;strong&gt;differential inequality&lt;/strong&gt; on a function &lt;script type=&quot;math/tex&quot;&gt;g(x) = e^{\lambda f(x)/2}&lt;/script&gt;
with parameter &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Part 1: defining a differential inequality.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The entropy of &lt;script type=&quot;math/tex&quot;&gt;g^2&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(g^2) = \mathrm{ent}(e^{\lambda f}) 
	= \lambda \E \big[ e^{\lambda f(X)} f(X) \big] -  
	  \E e^{\lambda f(X)} \log \big( \E e^{\lambda f(X)} \big).&lt;/script&gt;

&lt;p&gt;Now, if we stare at this for a moment and let our &lt;em&gt;cumulant generating 
function&lt;/em&gt; neurons fire, then we see that if we let 
&lt;script type=&quot;math/tex&quot;&gt;F(\lambda) = \E e^{\lambda f(X)}&lt;/script&gt;, then we get a &lt;strong&gt;differential inequality&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(g^2) = \lambda F'(\lambda) - F(\lambda) \log F(\lambda).&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Part 2: putting the logarithmic Sobolev inequality to work.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The logarithmic Sobolev inequality states&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathrm{ent}(g^2) &amp;\le 2 \mathcal{E}(g) \\
&amp;\stackrel{\textsf{def}}{=} 
	\E \left[ \sum_{i=1}^n \left( e^{\lambda f(X) / 2} - 
		e^{\lambda f \left( \tilde{X}^{(i)} \right) / 2} \right)^2 \right] \\
&amp;\stackrel{\textsf{hint}}{\le} 
	\frac{1}{8} \sum_{i=1}^n \E \left[ 
	\lambda^2 \left( f(X) - f \left( \tilde{X}^{(i)} \right) \right)^2 
	\left( e^{\lambda f(X)} - e^{\lambda f \left( \tilde{X}^{(i)} \right)} \right)
	\right] \\
&amp;\le \frac{\lambda^2 v}{8} \E \left[ e^{\lambda f(X)} \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Part 3: connecting the dots with some calculus.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Okay, cool; we’ve shown that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(e^{\lambda f}) \le \frac{\lambda^2 v}{8} 
	\E \left[ e^{\lambda f(X)} \right]&lt;/script&gt;

&lt;p&gt;which we can rewrite as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda F'(\lambda) - F(\lambda) \log F(\lambda) \le 
	\frac{\lambda^2 v}{8} F(\lambda).&lt;/script&gt;

&lt;p&gt;Now, let’s write this guy in a slightly different form in the spirit of
the Herbst argument:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\lambda F'(\lambda) - F(\lambda) \log F(\lambda)}{\lambda^2 F(\lambda)} 
	= \frac{\lambda F'(\lambda) - \log F(\lambda)}{\lambda^2 F(\lambda)}
	\le \frac{v}{8}.&lt;/script&gt;

&lt;p&gt;The calculus part of brain might be screaming something like&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{d}{dz} \left( \frac{\log z}{z} \right) = \frac{1 - \log z}{z^2},&lt;/script&gt;

&lt;p&gt;which we translate to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{d}{dz} \left( \frac{\log F(\lambda)}{\lambda} \right) \le \frac{v}{8}.&lt;/script&gt;

&lt;p&gt;Invoking more calculus ideas, l’Hospital’s rule says&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim_{\lambda \to 0} \frac{\log F(\lambda)}{\lambda} 
	= \frac{F'(0)}{F(0)} = \E Z.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Part 4: bounding via Cramér–Chernoff and Markov.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We’re almost there! Let’s assume that &lt;script type=&quot;math/tex&quot;&gt;\lambda &gt; 0&lt;/script&gt; and then integrate
the inequality between &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;. From l’Hospital’s rule, we get
that &lt;script type=&quot;math/tex&quot;&gt;\log F(\lambda) / \lambda \le \E Z + \lambda v / 8&lt;/script&gt;. Now, let’s undo
our &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;-in-the-denominator and our logarithmic term and write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(\lambda) \le e^{\lambda \E Z + \lambda^2 v / 8}.&lt;/script&gt;

&lt;p&gt;Finally, we can use the Cramér–Chernoff technique and Markov’s inequality to 
say that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\prob(Z &gt; \E Z + t) 
	&amp;\le \inf_{\lambda &gt; 0} F(\lambda)e^{-\lambda \E Z - \lambda t} \\
	&amp;\le \inf_{\lambda &gt; 0}  e^{\lambda^2 v / 8 - \lambda t} \\
	&amp;\le e^{-2t^2/v}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;(Note that &lt;script type=&quot;math/tex&quot;&gt;\lambda = 4t/v&lt;/script&gt; minimizes the upper bound.) Pat yourself on the 
back and give Mr. Herbst a (pretend) pat on the back too.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;…bandits!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from Chapter 5 of (my new favorite book):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by 
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">As promised, this post will be about logarithmic Sobolev inequalities, which are (exponential) concentration inequalities for functions defined on the binary hypercube. In particular, we’ll review a specific case where we get speedy concentration thanks to a variance-like bound on our function of interest. Let’s concentrate some measure!</summary></entry><entry><title type="html">Some (convex) relaxation</title><link href="http://localhost:4000/jekyll/update/2018/03/24/convex-relaxation.html" rel="alternate" type="text/html" title="Some (convex) relaxation" /><published>2018-03-24T17:00:00-06:00</published><updated>2018-03-24T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/03/24/convex-relaxation</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/03/24/convex-relaxation.html">&lt;p&gt;Okay, last time I said that the next post would be about logarithmic 
Sobolev inequalities… well, it’s not. I lied. Instead, we’re taking a 
momentary break from concentration inequalities. It’s time for some
relaxation of the convex variety.&lt;/p&gt;

&lt;p&gt;Actually, that’s a bit of lie too because the post isn’t about convex 
relaxation, but it &lt;strong&gt;is&lt;/strong&gt; about convex optimization. Andiamo!&lt;/p&gt;

&lt;h3 id=&quot;maximum-likelihood-of-poisson-distributions&quot;&gt;Maximum likelihood of Poisson distributions&lt;/h3&gt;

&lt;p&gt;We’re going to work through a problem from &lt;em&gt;Convex Optimization&lt;/em&gt; by Boyd
and Vandenberghe. (If you’re curious it’s problem 7.7.) Here’s the set up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We have &lt;script type=&quot;math/tex&quot;&gt;X_1,\dots,X_n&lt;/script&gt; independent Poisson random variables. That is
each &lt;script type=&quot;math/tex&quot;&gt;X_i&lt;/script&gt; has a probability mass function parameterized by 
&lt;script type=&quot;math/tex&quot;&gt;\lambda_i &gt; 0&lt;/script&gt; that is given by&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob (X_i = k) = \frac{e^{-\lambda_i}\lambda_i^k}{k!}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The data &lt;script type=&quot;math/tex&quot;&gt;x_1,\dots,x_n&lt;/script&gt; represent the number of times that one of &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;
possible events occurred (independently of one another).&lt;/li&gt;
  &lt;li&gt;We have &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; detectors and event &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is recorded by detector &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; with
probability &lt;script type=&quot;math/tex&quot;&gt;p_{ji}&lt;/script&gt;. We assume that &lt;script type=&quot;math/tex&quot;&gt;p_{ji} \ge 0&lt;/script&gt;, 
&lt;script type=&quot;math/tex&quot;&gt;\sum_{j=1}^m p_{ji} \le 1&lt;/script&gt;, &lt;strong&gt;and&lt;/strong&gt; that the &lt;script type=&quot;math/tex&quot;&gt;p_{ji}&lt;/script&gt; are given.&lt;/li&gt;
  &lt;li&gt;The total number of events recorded by detector &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; is&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_j = \sum_{i=1}^n y_{ji}, \quad j = 1,\dots,m.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Our goal is to estimate the &lt;script type=&quot;math/tex&quot;&gt;\lambda_i&lt;/script&gt; based on observations &lt;script type=&quot;math/tex&quot;&gt;y_j&lt;/script&gt;
and the given probabilities &lt;script type=&quot;math/tex&quot;&gt;p_{ji}&lt;/script&gt; by solving a convex optimization
problem.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To pose this estimation problem as a convex optimization problem, we’ll
use the fact that the &lt;script type=&quot;math/tex&quot;&gt;y_{ji}&lt;/script&gt; were generated from a Poisson distribution
with mean &lt;script type=&quot;math/tex&quot;&gt;p_{ji}\lambda_i&lt;/script&gt;. Intuitively, this means we only capture
a fraction, in particular &lt;script type=&quot;math/tex&quot;&gt;p_{ji}&lt;/script&gt;, of the Poisson-distributed events 
associated with &lt;script type=&quot;math/tex&quot;&gt;\lambda_i&lt;/script&gt;. For those who have had a course on Markov 
chains this should cause your &lt;strong&gt;thinned Poisson process&lt;/strong&gt; neurons to fire.&lt;/p&gt;

&lt;p&gt;Now, we use the fact that the sum of Poisson random variables is itself 
a Poisson random variable. In particular, we have that the &lt;script type=&quot;math/tex&quot;&gt;y_j&lt;/script&gt; were
generated by a Poisson distribution with parameter&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_j^T \lambda = \sum_{i=1}^n p_{ji}\lambda_i,&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;p_j \in \reals^n&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\lambda \in \reals_+^n&lt;/script&gt; is the vector of
&lt;script type=&quot;math/tex&quot;&gt;\lambda_i&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;likelihood&lt;/strong&gt; of the data has the form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prod_{j=1}^m \frac{(p_j^T \lambda)^{y_j}e^{-(p_j^T \lambda)}}{y_j!}&lt;/script&gt;

&lt;p&gt;which gives a &lt;strong&gt;log-likelihood&lt;/strong&gt; of&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{j=1}^m \left( y_j\log(p_j^T \lambda)-p_j^T \lambda-\log(y_j!) \right).&lt;/script&gt;

&lt;p&gt;We’ll throw away the &lt;script type=&quot;math/tex&quot;&gt;-\log(y_j!)&lt;/script&gt; term because it is a constant. So, the 
estimation problem is the convex optimization problem&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}[ll]
\mbox{\text{maximize}} &amp; \sum_{j=1}^m \big( y_j \log(p_j^T \lambda) -
	 p_j^T \lambda \big)
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;with optimization variable &lt;script type=&quot;math/tex&quot;&gt;\lambda \in \reals_+^n&lt;/script&gt; and problem data
&lt;script type=&quot;math/tex&quot;&gt;y_1,\dots,y_m&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;p_{ji}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i = 1,\dots,n&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;j = 1,d\dots,m&lt;/script&gt;.
More explicitly, we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}[ll]
\mbox{\text{maximize}} &amp; \sum_{j=1}^m \big( y_j \log(p_j^T \lambda) -
	 p_j^T \lambda \big) \\
\mbox{subject to} &amp; \lambda \succeq 0.
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Put it to use.&lt;/strong&gt; Now, go out and find yourself a particle accelerator, 
equip it with some detectors, start colliding particles and count your 
Higgs-Bosons and make some inferences.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… logarithmic Sobolev inequalities—for real this time (well, next time)!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Convex Optimization&lt;/em&gt; by Stephen Boyd and Lieven Vandenberghe. Check it
out here: &lt;em&gt;&lt;a href=&quot;https://web.stanford.edu/~boyd/cvxbook/&quot;&gt;Convex Optimization&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Okay, last time I said that the next post would be about logarithmic Sobolev inequalities… well, it’s not. I lied. Instead, we’re taking a momentary break from concentration inequalities. It’s time for some relaxation of the convex variety.</summary></entry><entry><title type="html">Entropy and its subadditivity</title><link href="http://localhost:4000/jekyll/update/2018/03/17/sub-entropy.html" rel="alternate" type="text/html" title="Entropy and its subadditivity" /><published>2018-03-17T20:00:00-06:00</published><updated>2018-03-17T20:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/03/17/sub-entropy</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/03/17/sub-entropy.html">&lt;p&gt;(Happy St. Patrick’s Day!)&lt;/p&gt;

&lt;p&gt;In this post, we’re picking up from the previous post and continuing with
some information-theoretic ideas as they arise in concentration inequalities.
We’ll quickly revisit the Efron–Stein inequality and then proceed towards
the subadditivity of entropy.&lt;/p&gt;

&lt;h3 id=&quot;efronstein&quot;&gt;Efron–Stein&lt;/h3&gt;

&lt;p&gt;To encourage the formation of new (or reinforce existing) neuronal 
connections, let’s remind ourselves of the Efron–Stein inequality. 
If we have independent random variables &lt;script type=&quot;math/tex&quot;&gt;X_1,\dots,X_n&lt;/script&gt; and a 
square-integrable function &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;Z = f(X)&lt;/script&gt;, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Var(Z) \le \sum_{i=1}^n \E \left[ \E^{(i)}[Z^2] - 
	\big( \E^{(i)}Z \big)^2 \right],&lt;/script&gt;

&lt;p&gt;where the operator &lt;script type=&quot;math/tex&quot;&gt;\E^{(i)}&lt;/script&gt; is the conditional expectation with respect
to the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th variable. The square-integrable condition on &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; ensures 
that its variance is finite.&lt;/p&gt;

&lt;h3 id=&quot;entropy&quot;&gt;Entropy&lt;/h3&gt;

&lt;p&gt;Now, let’s generalize the Efron–Stein inequality by observing that we
&lt;em&gt;could&lt;/em&gt; write it as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E [Z^2] - \big( \E Z \big)^2 \le 
	\sum_{i=1}^n \E \left[ \E^{(i)}[Z^2] - \big( \E^{(i)}Z \big)^2 \right],&lt;/script&gt;

&lt;p&gt;where we used the fact that &lt;script type=&quot;math/tex&quot;&gt;\Var(Y) = \E [Y^2] - \big( \E Y \big)^2&lt;/script&gt;.
If we stare at this representation of the various for a moment, 
we see that it has the form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E [g(Z)] - g( \E Z),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;g(x) = x^2&lt;/script&gt;. When &lt;script type=&quot;math/tex&quot;&gt;g(x) = x \log x&lt;/script&gt;, then quantity 
&lt;script type=&quot;math/tex&quot;&gt;\E [g(Z)] - g( \E Z)&lt;/script&gt; is often called the &lt;strong&gt;entropy&lt;/strong&gt; and is
denoted by &lt;script type=&quot;math/tex&quot;&gt;\mathrm{Ent}(Z)&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;subadditivity-of-entropy&quot;&gt;Subadditivity of entropy&lt;/h3&gt;

&lt;p&gt;Using the Efron–Stein inequality as our source of inspiration, we
might guess (or hope) that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E [g(Z)] - g( \E Z) \le 
	\sum_{i=1}^n \E \left[ \E^{(i)}g(Z) - g\big( \E^{(i)}Z \big) \right].&lt;/script&gt;

&lt;p&gt;If we did guess this, then we’d be correct! So, let’s prove it.&lt;/p&gt;

&lt;p&gt;We’ll assume that &lt;script type=&quot;math/tex&quot;&gt;X_1,\dots,X_n&lt;/script&gt; are independent random variables 
taking values in a finite set &lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; and that 
&lt;script type=&quot;math/tex&quot;&gt;f: \mathcal{S^n} \to \reals_+&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;Z = f(X_1,\dots,X_n)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The proof relies on an application of Han’s inequality for relative
entropies (which is an extension of what we showed in the 
&lt;a href=&quot;https://jakeknigge.github.io/jekyll/update/2018/03/11/han.html&quot;&gt;previous post&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Note that &lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; is always positive, so the result holds for any
&lt;script type=&quot;math/tex&quot;&gt;cZ&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;c&gt;0&lt;/script&gt;. Let’s use this to simplify our lives and assume that
&lt;script type=&quot;math/tex&quot;&gt;\E Z = 1&lt;/script&gt;. So, now we can write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E g(Z) - g( \E Z) = \E[Z \log Z] - 0.&lt;/script&gt;

&lt;p&gt;Now, we’re going to introduce the relative entropy component by
defining&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(x) = f(x)p(x) \iff \frac{q(x)}{p(x)} = f(x).&lt;/script&gt;

&lt;p&gt;The relative entropy neurons in your brain are probably going wild 
because we can now write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Z = f(X) = \frac{q(X)}{p(X)}.&lt;/script&gt;

&lt;p&gt;So, let’s take an expectation of &lt;script type=&quot;math/tex&quot;&gt;g(Z)&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E g(Z) &amp;= \E g\big( f(X) \big) \\
	&amp;= \E_P \left[ \frac{q(X)}{p(X)} \log \frac{q(X)}{p(X)} \right] \\
	&amp;= D_{\mathrm{kl}}(q(X), p(X)).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Here’s where &lt;strong&gt;Han’s inequality&lt;/strong&gt; comes to the scene, because the
relative entropy form of Han’s inequality says that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{\mathrm{kl}}(q(X), p(X)) \le \sum_{i=1}^n
	\left( D_{\mathrm{kl}}(q(X), p(X)) - 
	D_{\mathrm{kl}}\left(q^{(i)}(X), p^{(i)}(X)\right) \right).&lt;/script&gt;

&lt;p&gt;In other words, we have a bound on the (joint) relative entropy based on 
the sum of marginal relative entropies. Lastly, we’ll show that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^n 
	\left( D_{\mathrm{kl}}(q(X), p(X)) - 
	D_{\mathrm{kl}}\left(q^{(i)}(X), p^{(i)}(X)\right) \right) =
\sum_{i=1}^n 
	\E \left[ \E^{(i)} g(Z) - 
	g \left( \E^{(i)} Z \right) \right],&lt;/script&gt;

&lt;p&gt;which will conclude the proof. The tower property of expectation let’s us
write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{\mathrm{kl}}\left(q(X), p(X)\right) = \E \left[ \E^{(i)} g(Z) \right]&lt;/script&gt;

&lt;p&gt;and (with a bit more work)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
D_{\mathrm{kl}}\left(q^{(i)}(X), p^{(i)}(X)\right) &amp;=
\sum_{x^{(i)} \in \mathcal{S}^{n-1}} p^{(i)} \left( x^{(i)} \right)
	\left( \sum_{y \in \mathcal{S}} q^{(i)} \left( x^{(i)} \right) \right) 
	\log \frac{p^{(i)}\left( x^{(i)} \right) 
			\sum_{y \in \mathcal{S}} q^{(i)} \left( x^{(i)} \right)}
		{p^{(i)} \left( x^{(i)} \right)} \\
	&amp;= \sum_{x^{(i)} \in \mathcal{S}^{n-1}} p^{(i)} \left( x^{(i)} \right) 
	 	\left( \E^{(i)} Z \log \E^{(i)} Z \right) \\
	&amp;= \E \left[ g(\E^{(i)}Z) \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So, chaining everything together we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E [g(Z)] - g( \E Z) &amp;= D_{\mathrm{kl}}(Q, P) \\
	&amp;\le \sum_{i=1}^n 
	\left( D_{\mathrm{kl}}(Q, P) - 
			D_{\mathrm{kl}} \left( Q^{(i)}, P^{(i)} \right) \right) \\
	&amp;= \sum_{i=1}^n \E \left[ \E^{(i)}g(Z) - g\big( \E^{(i)}Z \big) \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;That’s it, that’s all folks.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… logarithmic Sobolev inequalities! Stay tuned—it’s gonna be good.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from Chapter 4 of (my new favorite book):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by 
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">(Happy St. Patrick’s Day!)</summary></entry></feed>