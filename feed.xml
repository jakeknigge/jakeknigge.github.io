<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-05-25T22:21:19-06:00</updated><id>http://localhost:4000/</id><title type="html">Eggink Blog</title><subtitle>Jake W. Knigge's blah, blah, blog... a place to discuss statistics, math, and  whatever else comes to mind.
</subtitle><entry><title type="html">Fisherian vignette - part 2</title><link href="http://localhost:4000/jekyll/update/2018/05/26/fisher-2.html" rel="alternate" type="text/html" title="Fisherian vignette - part 2" /><published>2018-05-26T11:30:00-06:00</published><updated>2018-05-26T11:30:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/26/fisher-2</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/26/fisher-2.html">&lt;p&gt;This post picks up with Fisher‚Äôs idea of the &lt;strong&gt;plug-in principle&lt;/strong&gt;. As with the last post,
the point of emphasis is on the connection between &lt;em&gt;maximum likelihood estimates&lt;/em&gt; and
the &lt;em&gt;bootstrap&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;the-plug-in-principle&quot;&gt;The plug-in principle&lt;/h3&gt;

&lt;p&gt;Part of Fisher‚Äôs genius is his practicality, and the plug-in principle is a prime example
of his problem solving tactics. Let‚Äôs say that we‚Äôre doing a linear regression problem&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_i = \beta^T x_i + \varepsilon_i
      \stackrel{\textsf{notation}}{=} y = X\beta + \varepsilon
      \iff \E [y | x] = X\beta
      \stackrel{\textsf{notation}}{=} \E [y_i | x_i] = \beta^T x_i,&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\beta \in \reals^d&lt;/script&gt; is a vector of parameters to be estimated based off of &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;
observations.&lt;/p&gt;

&lt;h4 id=&quot;fisher-style&quot;&gt;Fisher style&lt;/h4&gt;

&lt;p&gt;We‚Äôre interested in the standard error of the &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;th component of the
estimated coefficient vector &lt;script type=&quot;math/tex&quot;&gt;\hat{\beta}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathsf{se} \big( \hat{\beta}_k \big) = \sigma_\varepsilon \sqrt{(X^T X)^{-1}_{kk}}.&lt;/script&gt;

&lt;p&gt;Now, here‚Äôs where we go &lt;em&gt;Fisherian&lt;/em&gt; on this problem, use our plug-in estimates, and make
sure that everybody who should be wearing a hat &lt;em&gt;is&lt;/em&gt; wearing a hat&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\mathsf{se}} \big( \hat{\beta}_k \big)
      = \hat{\sigma}_\varepsilon \sqrt{(X^T X)^{-1}_{kk}}.&lt;/script&gt;

&lt;p&gt;All these quantities can be estimated based on the data &lt;script type=&quot;math/tex&quot;&gt;(X,y)&lt;/script&gt;, which means that we‚Äôre
in business.&lt;/p&gt;

&lt;h4 id=&quot;efron-style&quot;&gt;Efron style&lt;/h4&gt;

&lt;p&gt;Now, let‚Äôs look at the bootstrap version of these estimates:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\mathsf{se}}_\infty \big( \hat{\beta}_k \big)
      = \hat{\sigma}_\varepsilon \sqrt{(X^T X)^{-1}_{kk}},&lt;/script&gt;

&lt;p&gt;where we perform &lt;script type=&quot;math/tex&quot;&gt;B = \infty&lt;/script&gt; bootstrap samples. This results follows the fact that
the variance of a bootstrap estimate &lt;script type=&quot;math/tex&quot;&gt;\hat{\beta}^\star&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Var\left( \hat{\beta}^\star \right) = (X^T X)^{-1} X^T \Var(y^\star) X (X^T X)^{-1}
      = \hat{\sigma}^2_\varepsilon (X^T X)^{-1}.&lt;/script&gt;

&lt;p&gt;After we take the square root, we‚Äôre done.&lt;/p&gt;

&lt;h4 id=&quot;take-aways&quot;&gt;Take-aways&lt;/h4&gt;

&lt;p&gt;The bootstrap gives us the same standard error estimates as Fisher‚Äôs plug-in estimates,
but it does so by reversing the order of operations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MLE world:&lt;/strong&gt; compute, then plug in.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Compute an approximate formula for the standard error as a function of the unknown
parameters.&lt;/li&gt;
  &lt;li&gt;Plug in the estimates.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Bootstrap world:&lt;/strong&gt; plug in, then compute.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Plug in estimates for the unknown parameters.&lt;/li&gt;
  &lt;li&gt;Compute standard errors via bootstrap sampling (&lt;em&gt;i.e&lt;/em&gt;, simulation).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, where Fisher was clever in his mathematics, the bootstrap is clever in exploiting
cheap computation. Moreover, the bootstrap allows us to side step some (potentially nasty)
mathematics via (lots of) computation.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ confidence intervals!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;‚ÄúR.A. Fisher in the 21st Century‚Äù by Bradley Efron.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Computer Age Statistical Inference: Algorithms, Evidence, and Data Science&lt;/em&gt; by
Bradley Efron and Trevor Hastie. A digital copy lives here: &lt;a href=&quot;http://web.stanford.edu/~hastie/CASI/&quot;&gt;CASI&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;An Introduction to the Bootstrap&lt;/em&gt; by Bradley Efron and Robert J. Tibshirani.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">This post picks up with Fisher‚Äôs idea of the plug-in principle. As with the last post, the point of emphasis is on the connection between maximum likelihood estimates and the bootstrap.</summary></entry><entry><title type="html">Fisherian vignette - part 1</title><link href="http://localhost:4000/jekyll/update/2018/05/23/fisher-1.html" rel="alternate" type="text/html" title="Fisherian vignette - part 1" /><published>2018-05-23T21:30:00-06:00</published><updated>2018-05-23T21:30:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/23/fisher-1</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/23/fisher-1.html">&lt;p&gt;Today‚Äôs post is our first (short) vignette of the Fisher series. These vignettes are taken
from Brad Efron‚Äôs paper and they illustrate Fisher‚Äôs continued impact on modern
statistics. For the first one, we‚Äôre going to connect the &lt;strong&gt;Fisher information&lt;/strong&gt; with the
bootstrap.&lt;/p&gt;

&lt;p&gt;In what follows, we‚Äôre going to assume that we have data (&lt;em&gt;i.e.&lt;/em&gt;, realizations of
random variables) &lt;script type=&quot;math/tex&quot;&gt;x_1,\dots,x_n&lt;/script&gt; from a fixed and unknown distribution with density
function &lt;script type=&quot;math/tex&quot;&gt;f_\theta&lt;/script&gt;. The density is indexed by our &lt;em&gt;parameter-of-interest&lt;/em&gt; &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;fisher-information&quot;&gt;Fisher information&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Fisher information&lt;/strong&gt; is the expected value of the second derivative of the
log-density (which is also the derivative of the so called &lt;strong&gt;score function&lt;/strong&gt;):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_\theta = \E_\theta \left[\frac{-\partial^2 \log f_\theta(x)}{\partial \theta^2}\right].&lt;/script&gt;

&lt;p&gt;The Fisher information for the full sample is &lt;script type=&quot;math/tex&quot;&gt;n I_\theta&lt;/script&gt; because the observations are
(assumed to be) i.i.d.&lt;/p&gt;

&lt;p&gt;So, why do we care about the Fisher information? Well, Fisher showed us that the
asymptotic standard errors of his maximum likelihood estimates (MLEs) are related to the
information in the sample by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathsf{se}_\theta \big( \hat{\theta} \big) = \frac{1}{\sqrt{n I_\theta}}.&lt;/script&gt;

&lt;p&gt;Moreover, by the asymptotic efficiency of MLEs, no other (asymptotically) unbiased
estimator can do better (versus the Cram√©r‚ÄìRao lower bound).&lt;/p&gt;

&lt;p&gt;Okay, that‚Äôs cool but there‚Äôs a pesky &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; in the denominator. So let‚Äôs do what
Fisher would do and replace it by its &lt;em&gt;plug-in&lt;/em&gt; estimate, giving&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\mathsf{se}} = \frac{1}{\sqrt{n I_{\hat{\theta}}}}.&lt;/script&gt;

&lt;p&gt;Heck yeah. Now we‚Äôve got something actionable that we can use on MLEs as we please.&lt;/p&gt;

&lt;h3 id=&quot;the-bootstrap&quot;&gt;The bootstrap&lt;/h3&gt;

&lt;p&gt;If you haven‚Äôt met the bootstrap yet, do so pronto. It‚Äôs an unbelievably useful tool
that every statistician, machine learner, data scientist, computer scientist, and
person-who-works-with-real-data should know, use, and love.&lt;/p&gt;

&lt;p&gt;Here‚Äôs the gist of it.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We compute our statistic of interest &lt;script type=&quot;math/tex&quot;&gt;\hat{\theta} = T(x_1,\dots,x_n)&lt;/script&gt; using the data
we have.&lt;/li&gt;
  &lt;li&gt;Then we resample &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; points from our data &lt;em&gt;with replacement&lt;/em&gt;, which gives us a
&lt;strong&gt;bootstrap sample&lt;/strong&gt;. Some data may appear multiple times and others not at all.&lt;/li&gt;
  &lt;li&gt;From our bootstrap sample, we compute a bootstrap statistic
&lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}^\star_\textsf{boot} = T(x^\star_1,\dots,x^\star_n)&lt;/script&gt;, where
&lt;script type=&quot;math/tex&quot;&gt;x^\star_i&lt;/script&gt; is the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;-th bootstrap sample.&lt;/li&gt;
  &lt;li&gt;(Note that &lt;script type=&quot;math/tex&quot;&gt;x_i \neq x^\star_i&lt;/script&gt; in general.)&lt;/li&gt;
  &lt;li&gt;Do this many times and estimate the standard error,
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mathsf{se}}_\textsf{boot}&lt;/script&gt; of the statistic by the sample
standard deviation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For a large number of bootstrap samples, the bootstrap standard error estimate is
approximately equal to Fisher‚Äôs standard error estimate using the Fisher information.&lt;/p&gt;

&lt;p&gt;The bootstrap approach exploits computer-based computation, which is nice when our
statistic is some nasty function of the data; on the other hand, Fisher‚Äôs approach
often exploits clever manipulations, &lt;em&gt;i.e.&lt;/em&gt;, human-based computations to produce standard
error estimates. Both approaches are worth having in your pocket when standard errors
come a-knocking.&lt;/p&gt;

&lt;p&gt;That‚Äôs it for today.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ we‚Äôll dig into the &lt;strong&gt;plug-in principle&lt;/strong&gt; (which we had a flavor of today) for our
second vignette!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;‚ÄúR.A. Fisher in the 21st Century‚Äù by Bradley Efron.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Computer Age Statistical Inference: Algorithms, Evidence, and Data Science&lt;/em&gt; by
Bradley Efron and Trevor Hastie. A digital copy lives here: &lt;a href=&quot;http://web.stanford.edu/~hastie/CASI/&quot;&gt;CASI&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Today‚Äôs post is our first (short) vignette of the Fisher series. These vignettes are taken from Brad Efron‚Äôs paper and they illustrate Fisher‚Äôs continued impact on modern statistics. For the first one, we‚Äôre going to connect the Fisher information with the bootstrap.</summary></entry><entry><title type="html">A few flavors of Fisher‚Äôs style</title><link href="http://localhost:4000/jekyll/update/2018/05/22/fisher-0.html" rel="alternate" type="text/html" title="A few flavors of Fisher's style" /><published>2018-05-22T12:30:00-06:00</published><updated>2018-05-22T12:30:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/22/fisher-0</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/22/fisher-0.html">&lt;p&gt;Today‚Äôs post is the first in a sequence about Sir Ronald Aylmer Fisher and his approach to
statistics. These posts are very, very much related to the wonderful 1998 paper by Brad
Efron, titled, ‚ÄúR.A. Fisher in the 21st Century‚Äù. A digital copy lives here:
&lt;a href=&quot;https://projecteuclid.org/euclid.ss/1028905930&quot;&gt;R. A. Fisher in the 21st century&lt;/a&gt;. To quote Efron‚Äôs last paragraph:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;‚ÄúLet me say finally that Fisher was a genius of the first rank, who has a solid claim to
being the most important applied mathematician of the 20th century. His work has a unique
quality of daring mathematical synthesis combined with the utmost practicality.‚Äù&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;If that doesn‚Äôt whet your appetite, then these posts aren‚Äôt for you. üòâ&lt;/p&gt;

&lt;h3 id=&quot;fisherian-inference&quot;&gt;Fisherian inference&lt;/h3&gt;

&lt;p&gt;Statistics is often divided into two camps, the Bayesian (&lt;em&gt;i.e.&lt;/em&gt;, optimists, integrators,
subjectivists) and the frequentists (&lt;em&gt;i.e.&lt;/em&gt;, pessimists, ‚Äúderivatators‚Äù, objectivists).
Although historically divided, we can related the two camps via decision theory,
but that‚Äôs not our purpose here. Instead, we‚Äôre going to talk about a third flavor of
inference, &lt;strong&gt;Fisherian inference&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;As Efron and Hastie say, Fisherian inference ‚Äúoften drew on ideas neither Bayesian nor
frequentist in nature, or sometimes the two in combination.‚Äù Fisher‚Äôs style balanced
the correctness (‚Äúcoherency‚Äù) of Bayesian inference with the the accuracy (‚Äúoptimality‚Äù)
of frequentist inference. Fisher‚Äôs style of statistics isn‚Äôt simply a convex combination
of the Bayesian and frequentist schools, but something unique with its own merits and
disadvantages. To make things less philosophical and more concrete let‚Äôs review
Fisher‚Äôs primary tool, and the one that we‚Äôre &lt;em&gt;almost surely&lt;/em&gt; used,
&lt;strong&gt;maximum likelihood&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;maximum-likelihood&quot;&gt;Maximum likelihood&lt;/h3&gt;

&lt;p&gt;Assume we have a family of probability distributions indexed by a finite-dimensional
parameter &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;, &lt;em&gt;e.g.&lt;/em&gt;, exponential family distributions. We‚Äôll write the density
functions as &lt;script type=&quot;math/tex&quot;&gt;f_\theta&lt;/script&gt; and the &lt;strong&gt;log-likelihood&lt;/strong&gt; as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell_x(\theta) = \log f_\theta(x),&lt;/script&gt;

&lt;p&gt;where the notation &lt;script type=&quot;math/tex&quot;&gt;\ell_x&lt;/script&gt; suggests that the likelihood is fixed with respect to the
data &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. As a statistician, our goal is to estimate the parameter &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;. To do so,
we‚Äôll use Fisher‚Äôs &lt;strong&gt;maximum likelihood estimate&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\theta} = \argmax_{\theta \in \Theta} \ell_x(\theta).&lt;/script&gt;

&lt;p&gt;For many distributions of ‚Äúpractical interest‚Äù, &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt; is some subset of the real
numbers and the log-likelihood is a concave function. So, the maximization problem is
well posed (even if there are multiple maximizers). Moreover, maximum likelihood
estimation has achieved ‚Äúiconic status‚Äù because it has&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a straightforward recipe‚Äîtake derivatives, set them equal to zero, solve;&lt;/li&gt;
  &lt;li&gt;good frequentist properties;&lt;/li&gt;
  &lt;li&gt;a Bayesian interpretation;&lt;/li&gt;
  &lt;li&gt;a notion of optimality; and&lt;/li&gt;
  &lt;li&gt;a natural relationship with information and geometry.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Straightforward recipe.&lt;/strong&gt;
Maximum likelihood estimators are more-or-less automatic to constructs‚Äînumerical methods
may be required, but Newton‚Äôs method will (often) find the the problem in just a few
iterations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Good frequentist properties.&lt;/strong&gt;
Under ‚Äúsuitable‚Äù regularity conditions, which we‚Äôll scoot under the rug, maximum
likelihood estimates are asymptotically normal, asymptotically efficient (&lt;em&gt;i.e.&lt;/em&gt;, optimal,
&lt;em&gt;i.e.&lt;/em&gt;, achieve the Cram√©r-Rao lower bound), amenable to frequentist style confidence
intervals. Moreover, it is a &lt;strong&gt;consistent&lt;/strong&gt; estimator, meaning the estimator converges
in probability to its true value&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\theta}_n \stackrel{\textsf{prob.}}{\to} \theta \iff
\prob\left( \left| \hat{\theta}_n - \theta \right| &gt; \varepsilon \right) \to 0,&lt;/script&gt;

&lt;p&gt;for every &lt;script type=&quot;math/tex&quot;&gt;\varepsilon &gt; 0&lt;/script&gt; as &lt;script type=&quot;math/tex&quot;&gt;n \to \infty&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bayesian interpretation.&lt;/strong&gt;
Maximum likelihood estimates can be viewed as Bayesian posterior estimates when the prior
distribution was uniform (flat) over the parameter space &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Notion of optimality.&lt;/strong&gt;
As mentioned above, these guys have the smallest asymptotic variance, meaning they use
the data in an optimal way.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Natural relationship with information and geometry.&lt;/strong&gt;
The &lt;strong&gt;Fisher information&lt;/strong&gt; of a random variable quantifies how much information that
variable carries about the parameter of interest; it is closely related to the
information theoretic idea of &lt;strong&gt;relative entropy&lt;/strong&gt;. Moreover, the Fisher information
is a measure of curvature in the log-likelihood, where more curvature means more
information. Cool, huh?&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ our first vignette, connecting the ideas of &lt;strong&gt;Fisher information&lt;/strong&gt; and the
&lt;strong&gt;bootstrap&lt;/strong&gt;!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;‚ÄúR.A. Fisher in the 21st Century‚Äù by Bradley Efron.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Computer Age Statistical Inference: Algorithms, Evidence, and Data Science&lt;/em&gt; by
Bradley Efron and Trevor Hastie. A digital copy lives here: &lt;a href=&quot;http://web.stanford.edu/~hastie/CASI/&quot;&gt;CASI&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Today‚Äôs post is the first in a sequence about Sir Ronald Aylmer Fisher and his approach to statistics. These posts are very, very much related to the wonderful 1998 paper by Brad Efron, titled, ‚ÄúR.A. Fisher in the 21st Century‚Äù. A digital copy lives here: R. A. Fisher in the 21st century. To quote Efron‚Äôs last paragraph:</summary></entry><entry><title type="html">Online learning theory - strong convexity</title><link href="http://localhost:4000/jekyll/update/2018/05/14/ol-example.html" rel="alternate" type="text/html" title="Online learning theory - strong convexity" /><published>2018-05-14T22:00:00-06:00</published><updated>2018-05-14T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/14/ol-example</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/14/ol-example.html">&lt;p&gt;Today‚Äôs post is a neat example of what &lt;em&gt;exploiting structure&lt;/em&gt; can do. It ties back to
the post that introduced &lt;a href=&quot;/jekyll/update/2018/05/10/learning-theory-2.html&quot;&gt;online learning&lt;/a&gt;. In that discussion, we had an
online gradient descent algorithm that relied on an auxiliary sequence of models.
We calculated the auxiliary sequence using gradient descent and then we projected back
into our model space, which was all fine and good; however, in this post we‚Äôre going to
show that we can avoid that projection step when we have a loss function that is strongly
convex.&lt;/p&gt;

&lt;h3 id=&quot;strong-convexity&quot;&gt;Strong convexity&lt;/h3&gt;

&lt;p&gt;Before we defined strong convexity, try to guess what it could look like. If you imagined
a function that has positive (more precisely, nonnegative) curvature everywhere, then
you‚Äôre spot on!&lt;/p&gt;

&lt;p&gt;We‚Äôll assume that our loss function &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;-strongly, meaning&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l(w) - l(u) \le \nabla l(w)^T (w-u) - \frac{\sigma}{2} \|(w-u)\|^2.&lt;/script&gt;

&lt;p&gt;(Technically, strong convexity is defined with respect to a norm‚Äîin this case, it‚Äôs
the &lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt; norm.) So, strong convexity means that our function grows faster than
linearly in all directions.&lt;/p&gt;

&lt;h3 id=&quot;online-gradient-descent&quot;&gt;Online gradient descent&lt;/h3&gt;

&lt;p&gt;With strongly convex losses, the online gradient descent algorithm is a one-liner.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Algorithm&lt;/strong&gt; &lt;em&gt;online gradient descent with strongly convex losses.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;given&lt;/strong&gt; parameters &lt;script type=&quot;math/tex&quot;&gt;\alpha_1,\alpha_2,\dots&lt;/script&gt;, an initial model &lt;script type=&quot;math/tex&quot;&gt;w_1 = 0&lt;/script&gt;, and a
bound on the norm of the gradient, &lt;em&gt;i.e.&lt;/em&gt;, &lt;script type=&quot;math/tex&quot;&gt;\|\nabla l(w)\| \le G&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;repeat&lt;/strong&gt; for &lt;script type=&quot;math/tex&quot;&gt;t=1,2,\dots&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;compute a gradient step:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{t+1} = w_t - \alpha_t \nabla l_t(w_t).&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;That‚Äôs it! Now here‚Äôs the cool part. If we know the minimum eigenvalue
&lt;script type=&quot;math/tex&quot;&gt;\sigma = \lambda_\min(H)&lt;/script&gt;, associated with the Hessian of &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;, then we can choose
&lt;script type=&quot;math/tex&quot;&gt;\alpha_t = 1/t\sigma&lt;/script&gt; which gives&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{T} \sum_{t=1}^T \big( l_t(w_t) - l_t(u^\star_T) \big) \le \frac{G^2}{2\sigma}
      \frac{\ln T+1}{T}.&lt;/script&gt;

&lt;p&gt;We can interpret this bound as: convergence is fast when we have global information about
the sequence of loss functions. No proof this time (although it‚Äôs very similar to the
online gradient descent proof), so that‚Äôs it for today!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ a foray into the mind of R.A. Fisher with Brad Efron‚Äôs help!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicol√≤ Cesa-Bianchi‚Äôs lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today‚Äôs post is a neat example of what exploiting structure can do. It ties back to the post that introduced online learning. In that discussion, we had an online gradient descent algorithm that relied on an auxiliary sequence of models. We calculated the auxiliary sequence using gradient descent and then we projected back into our model space, which was all fine and good; however, in this post we‚Äôre going to show that we can avoid that projection step when we have a loss function that is strongly convex.</summary></entry><entry><title type="html">Learning theory - reconciliations and connections</title><link href="http://localhost:4000/jekyll/update/2018/05/12/learning-theory-3.html" rel="alternate" type="text/html" title="Learning theory - reconciliations and connections" /><published>2018-05-12T22:00:00-06:00</published><updated>2018-05-12T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/12/learning-theory-3</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/12/learning-theory-3.html">&lt;p&gt;Howdy learning theorists! Today we‚Äôre going to connect statistical learning and online
learning. We‚Äôll do so via model averaging and exploiting online learning‚Äôs local
perspective. To that end, this post could have easily been called ‚Äúthe power of local
optimization‚Äù, which has a nice ring to it.&lt;/p&gt;

&lt;p&gt;Our goal is address a few questions that pop up when the online learning approach is
unfamiliar.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What does the online learning regret bound mean?&lt;/li&gt;
  &lt;li&gt;How can that bound be used?&lt;/li&gt;
  &lt;li&gt;How well does the loss rate on the model sequence generalize?&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;the-approach&quot;&gt;The approach&lt;/h3&gt;

&lt;p&gt;Because online learning generates a sequence of models rather than a single model, we
have to pick a model to compare against the empirical risk minimizer. In particular, we‚Äôll
choose the average model. Then we can use the online analysis machinery to provide a
risk bound on that model.&lt;/p&gt;

&lt;p&gt;Assume we have&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;an &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;-dimensional sample &lt;script type=&quot;math/tex&quot;&gt;S = \{(x_1,y_1),\dots,(x_n,y_n)\}&lt;/script&gt; drawn
i.i.d. from a training set &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;a loss function &lt;script type=&quot;math/tex&quot;&gt;l_\mathcal{D}(w)&lt;/script&gt; for linear models &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;a ‚Äúbest‚Äù model &lt;script type=&quot;math/tex&quot;&gt;u^\star = \argmin_{u: \|u\| \le U} l_\mathcal{D}(u)&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We want to control the differences&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_\mathcal{D}(\hat{w}) - l_\mathcal{D}(u^\star),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\hat{w}&lt;/script&gt; is the average model. Here‚Äôs how we get &lt;script type=&quot;math/tex&quot;&gt;\hat{w}&lt;/script&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;run online gradient descent on our sample set &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;obtain a sequence of models &lt;script type=&quot;math/tex&quot;&gt;w_1,\dots,w_n&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;compute the average model&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{w} = \frac{1}{n} \sum_{i=1}^n w_i.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Aside on averaging.&lt;/strong&gt; Online analysis gives insight on the behavior of the model
sequence but not on any one particular model. So, we need to consolidate our sequence
into something we can analyze. Moreover, averaging is a good way (think of Leo Breiman
and &lt;strong&gt;bagging&lt;/strong&gt;) to reduce variance without impacting an estimator‚Äôs bias.&lt;/p&gt;

&lt;h3 id=&quot;expectation-bounds&quot;&gt;Expectation bounds&lt;/h3&gt;

&lt;p&gt;We start by showing that the expected value of the loss of the average model is less
than or equal to the average loss on the model sequence via Jensen‚Äôs inequality:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
l_\mathcal{D}\big( \hat{w} \big)
	&amp;= \E \left[ l\left( \frac{1}{n} \sum_{t=1}^n w_t, (X,Y) \right) \right] \\
	&amp;\le \frac{1}{n} \sum_{t=1}^n \E \, l\big(w_t, (X,Y) \big) \\
	&amp;= \frac{1}{n} \sum_{t=1}^n l_\mathcal{D}(w_t).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Cool, now we have something to compare to the best model in the class! But something feels
funny because we have something i.i.d. and something sequential‚Äîmartingales to the
rescue!&lt;/p&gt;

&lt;h3 id=&quot;martingale-differences&quot;&gt;Martingale differences&lt;/h3&gt;

&lt;p&gt;Martingales are perfectly equipped for taming our sequential process. In particular,
we‚Äôll define the &lt;strong&gt;conditional expectation&lt;/strong&gt; up to time &lt;script type=&quot;math/tex&quot;&gt;t-1&lt;/script&gt; as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_{t-1} [\, \cdot \,] = \E[\, \cdot \mid z_1,\dots,z_{t-1}].&lt;/script&gt;

&lt;p&gt;For now, let‚Äôs focus on time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and take the expectation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_{t-1} \big[ \color{red}{l_\mathcal{D}(w_t)}
	- \color{royalblue}{l\left(w_t, (x_t, y_t) \right)} \big] = 0&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\color{red}{l_\mathcal{D}(w_t)}&lt;/script&gt; is the &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;th model and
&lt;script type=&quot;math/tex&quot;&gt;\color{royalblue}{l\left(w_t, (x_t, y_t) \right)}&lt;/script&gt; is the expected loss on the next
example. The expectation is zero because&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the first &lt;script type=&quot;math/tex&quot;&gt;t-1&lt;/script&gt; examples are held fixed, meaning &lt;script type=&quot;math/tex&quot;&gt;l_\mathcal{D}(w_t)&lt;/script&gt; is a constant;
and&lt;/li&gt;
  &lt;li&gt;the expected loss, &lt;em&gt;i.e.&lt;/em&gt;, risk, at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; is
&lt;script type=&quot;math/tex&quot;&gt;\E \, \color{royalblue}{l\left(w_t, (x_t, y_t) \right)} = l_\mathcal{D}(w_t)&lt;/script&gt; because
our data is i.i.d. from &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, we average across our &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; examples&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n
	\E_{t-1} \big[ l_\mathcal{D}(w_t) - l\left(w_t, (x_t, y_t) \right) \big]
	\stackrel{\textsf{notation}}{=}
	\frac{1}{n} \sum_{t=1}^n \E_{t-1} Z_t = 0&lt;/script&gt;

&lt;p&gt;because &lt;script type=&quot;math/tex&quot;&gt;\E_{t-1} Z_t = 0&lt;/script&gt; for each &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;. The random variables &lt;script type=&quot;math/tex&quot;&gt;Z_1,\dots,Z_n&lt;/script&gt; form
a &lt;strong&gt;martingale difference sequence&lt;/strong&gt;, which means we can martingale concentration results
to bound the average. In particular, with probability at least &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n Z_t \le \E \frac{1}{n} \sum_{t=1}^n Z_t +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).&lt;/script&gt;

&lt;p&gt;With this fact, we can bound the risk of the average model!&lt;/p&gt;

&lt;h3 id=&quot;bounding-via-online-analysis&quot;&gt;Bounding via online analysis&lt;/h3&gt;

&lt;p&gt;Thanks to our martingale convergence result, this is a plug-and-play step. So, with
probability at least &lt;script type=&quot;math/tex&quot;&gt;1- \delta&lt;/script&gt; with respect to the random draw of our sample &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
l_\mathcal{D}(\hat{w}) &amp;\le \frac{1}{n} \sum_{t=1}^n l_\mathcal{D}(w_t) \\
	&amp;\le \frac{1}{n} \sum_{t=1}^n l\big(w_t, (x_t, y_t)\big) +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Neural connection.&lt;/strong&gt; This is the same object as what we had in the online learning
analysis because we have a loss rate on the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; models in the sequence‚Äîand
all we needed was a slightly modified (&lt;em&gt;i.e.&lt;/em&gt;, &lt;em&gt;martingalified&lt;/em&gt;) concentration result!&lt;/p&gt;

&lt;p&gt;Our last step is to use online analysis to bound the loss rate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(w_t, (x_t, y_t)\big),&lt;/script&gt;

&lt;p&gt;which will give us something that we can compare to the empirical risk minimizer. To make
things concrete, we‚Äôll look at a specific example.&lt;/p&gt;

&lt;h3 id=&quot;linear-regression-with-squared-loss&quot;&gt;Linear regression with squared loss&lt;/h3&gt;

&lt;p&gt;We‚Äôre going to show that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(w_t, (x_t, y_t)\big) \le
	\min_{u: \|u\| \le U} \frac{1}{n} \sum_{t=1}^n l\big(u, (x_t, y_t)\big) +
		\delta (UX)^2 \sqrt{\frac{2}{T}}.&lt;/script&gt;

&lt;p&gt;We‚Äôll define &lt;script type=&quot;math/tex&quot;&gt;u^\star_t&lt;/script&gt; as the minimizer of
&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(u, (x_t, y_t)\big)&lt;/script&gt;, which allows us to say that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(u_n^\star, (x_t, y_t)\big) \le
	\frac{1}{n} \sum_{t=1}^n l\big(u^\star, (x_t, y_t)\big),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;u^\star&lt;/script&gt; is the model with the smallest statistical risk over &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;,
not just &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;. So, &lt;script type=&quot;math/tex&quot;&gt;u^\star&lt;/script&gt; may not have the smallest risk over &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;.
(&lt;strong&gt;Neural connection!&lt;/strong&gt; This is the same trick we used in the Rademacher analysis in the
&lt;a href=&quot;/jekyll/update/2018/05/06/learning-theory-1.html&quot;&gt;statistical learning theory post&lt;/a&gt;!)&lt;/p&gt;

&lt;p&gt;Via the Chernoff bound, with probability at least &lt;script type=&quot;math/tex&quot;&gt;1-\delta&lt;/script&gt; we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(u_n^\star, (x_t, y_t)\big) \le
	l_\mathcal{D}(u^\star) +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).&lt;/script&gt;

&lt;p&gt;This last expression yields the bound on the average model:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_\mathcal{D}(\hat{w}) - l_\mathcal{D}(u^\star) \le + c\frac{UX^2}{\sqrt{n}}
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; is a constant. This is the same bound obtained from the Rademacher analysis!&lt;/p&gt;

&lt;h3 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The average loss on a sequence of models is a good proxy for the risk of the average
model.&lt;/li&gt;
  &lt;li&gt;Local optimization performs well (up to constant factors), compared to empirical risk
minimization, &lt;em&gt;i.e.&lt;/em&gt;, globabl optimization.
 	+ So, local optimization isn‚Äôt doing anything crazy‚Äîit‚Äôs doing something quite
    similar to global optimization.
    &lt;ul&gt;
      &lt;li&gt;In other words, doing local optimization and then averaging is a good and viable
strategy, especially when we‚Äôre dealing with big problems.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, let‚Äôs revisit our questions.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What does the online learning regret bound mean?
    &lt;ul&gt;
      &lt;li&gt;In some sense, it means that we‚Äôre bounding an object not unlike the empirical
risk.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How can that bound be used?
    &lt;ul&gt;
      &lt;li&gt;The online learning bound can be used to bound an &lt;em&gt;average&lt;/em&gt; model, which is
comparable to a model found via empirical risk minimization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How well does the loss rate on the model sequence generalize?
    &lt;ul&gt;
      &lt;li&gt;Up to constant factors, it generalizes as well as well the model found through
empirical risk minimization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ a short and sweet example of how strong convexity speeds things up in the online
learning setting! Then a foray into the mind of R.A. Fisher with Brad Efron‚Äôs help.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicol√≤ Cesa-Bianchi‚Äôs lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Howdy learning theorists! Today we‚Äôre going to connect statistical learning and online learning. We‚Äôll do so via model averaging and exploiting online learning‚Äôs local perspective. To that end, this post could have easily been called ‚Äúthe power of local optimization‚Äù, which has a nice ring to it.</summary></entry><entry><title type="html">Learning theory - online learning</title><link href="http://localhost:4000/jekyll/update/2018/05/10/learning-theory-2.html" rel="alternate" type="text/html" title="Learning theory - online learning" /><published>2018-05-10T22:00:00-06:00</published><updated>2018-05-10T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/10/learning-theory-2</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/10/learning-theory-2.html">&lt;p&gt;Welcome back! Today‚Äôs post focuses on the &lt;strong&gt;online learning&lt;/strong&gt; perspective of learning.
The online learning approach differs from statistical learning because it makes no
assumption on the data source. In other words, the process generating the data is
arbitrary!&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Instead of focusing on the data source, online learning makes assumptions
on the sequence of loss functions to attain some level of tractability. Yep, you read
that correctly: we will have a sequence of loss functions‚Äînot just one to
&lt;em&gt;rule them all&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-protocol-for-online-learning&quot;&gt;A protocol for online learning&lt;/h3&gt;

&lt;p&gt;Here‚Äôs how our online learning world works.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An algorithm generates an initial model &lt;script type=&quot;math/tex&quot;&gt;w_1&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t = 1, 2, \dots&lt;/script&gt;, the model is tested on a data point.&lt;/li&gt;
  &lt;li&gt;After being tested, the algorithm updates &lt;script type=&quot;math/tex&quot;&gt;w_t \to w_{t+1}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second step suggests that we‚Äôre going to need some notion of loss‚Äî&lt;em&gt;i.e.&lt;/em&gt;, something
like risk‚Äîto help us &lt;em&gt;test&lt;/em&gt; our model. For our purposes, we‚Äôll assume that
the loss functions we encounter are &lt;strong&gt;convex&lt;/strong&gt;, &lt;strong&gt;nonnegative&lt;/strong&gt;, and &lt;strong&gt;differentiable&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For application-minded readers, model spaces are typically linear but can be finite
dimensional (&lt;em&gt;e.g.&lt;/em&gt;, regression or support vector machine parameters) or infinite
dimensional, via reproducing Kernel Hilbert spaces.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h3 id=&quot;assessing-performance&quot;&gt;Assessing performance&lt;/h3&gt;

&lt;p&gt;We‚Äôre going to assess the performance of our (model-generating) algorithm via its
&lt;strong&gt;loss rate&lt;/strong&gt;, defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{T} \sum_{t=1}^T l_t(w_t).&lt;/script&gt;

&lt;p&gt;But this is only part of the story. A loss rate by itself is uninteresting because
losses are arbitrary. So, we‚Äôll focus on controlling our &lt;strong&gt;regret&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{T} \sum_{t=1}^T l_t(w_t) - l_t(w^\star_T),&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^\star_T = \argmin_{u: \|u\| \le U} \frac{1}{T} \sum_{t=1}^T l_t(u)&lt;/script&gt;

&lt;p&gt;is the best model in the class. When the regret goes to zero, then we are learning and
also experiencing some type of consistency.&lt;/p&gt;

&lt;h3 id=&quot;the-algorithm-of-choice---online-gradient-descent&quot;&gt;The algorithm of choice - online gradient descent&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Online gradient descent&lt;/strong&gt; (OGD) is akin to empirical risk minimization in statistical
learning theory, but it‚Äôs a bit different than typical gradient descent because the losses
can vary over time. Nonetheless, the algorithm is quite simple.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Algorithm&lt;/strong&gt; &lt;em&gt;online gradient descent.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;given&lt;/strong&gt; parameters &lt;script type=&quot;math/tex&quot;&gt;\alpha_1,\alpha_2,\dots&lt;/script&gt;, a radius &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt;, and an initial model
&lt;script type=&quot;math/tex&quot;&gt;w_1 = 0&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;repeat&lt;/strong&gt; for &lt;script type=&quot;math/tex&quot;&gt;t=1,2,\dots&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;compute a tentative gradient step:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{w}_{t+1} = w_t - \alpha_t \nabla l_t(w_t).&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;project back to the model space:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{t+1} = \argmin_{w: \|w\| \le U} \|w - \tilde{w}_{t+1}\|.&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Neural connection.&lt;/strong&gt; Online gradient descent is similar to stochastic gradient except
there‚Äôs no stochasticity in the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Food for thought.&lt;/strong&gt;
Online gradient descent is a local optimization perspective rather than global
optimization as in empirical risk minimization. Because of this, online gradient descent
scales gracefully to large problems.&lt;/p&gt;

&lt;h3 id=&quot;analyzing-online-gradient-descent&quot;&gt;Analyzing online gradient descent&lt;/h3&gt;

&lt;p&gt;Let‚Äôs fix a time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and analyze the instantaneous regret&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_t(w_t) - l_t(u).&lt;/script&gt;

&lt;p&gt;By convexity, the first-order Taylor expansion of &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; around &lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; gives,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_t(w_t) - l_t(u) \le \nabla l_t (w_t)^T (w_t - u).&lt;/script&gt;

&lt;p&gt;This is pretty much the definition of convexity.&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; By the OGD algorithm, we
calculate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
l_t(w_t) - l_t(u)
&amp;\le \nabla l_t (w_t)^T (w_t - u) \\
&amp;= \frac{1}{\alpha_t} (\tilde{w}_{t+1} - w_t)^T (w_t - u) \\
&amp;\stackrel{\textsf{(a)}}{=}
	\frac{1}{\alpha_t} \left( \frac{1}{2} \|w_t - u\|^2
		- \frac{1}{2} \|\tilde{w}_{t+1} - u\|^2
		+ \frac{1}{2} \|\tilde{w}_{t+1} - w_t\|^2 \right) \\
&amp;\stackrel{\textsf{(b)}}{\le}
	\frac{1}{\alpha_t} \left( \frac{1}{2} \|w_t - u\|^2
		- \frac{1}{2} \|w_{t+1} - u\|^2
		+ \frac{1}{2} \|\tilde{w}_{t+1} - w_t\|^2 \right) \\
&amp;\stackrel{\textsf{(c)}}{=}
	\frac{1}{2\alpha_t} \|w_t - u\|^2
		- \frac{1}{2\alpha_{t+1}} \|w_{t+1} - u\|^2
		- \frac{1}{2\alpha_t} \|w_{t+1} - u\|^2 \\
		&amp;\qquad + \frac{1}{2\alpha_{t+1}} \|w_{t+1} - u\|^2
		+ \frac{1}{2\alpha_t} \|\tilde{w}_{t+1} - w_t\|^2.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;In (a) we compare the current model at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; to the best model &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; plus a
penalty for changing models. In (b) we use the fact that projecting
&lt;script type=&quot;math/tex&quot;&gt;\tilde{w}_{t+1} \to w_{t+1}&lt;/script&gt; reduces the distance to &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt;; since that term is
negative, we get the inequality. In (c) we add and subtract the same term for reasons
which will become clear shortly.&lt;/p&gt;

&lt;h4 id=&quot;summing-it-up&quot;&gt;Summing it up&lt;/h4&gt;

&lt;p&gt;Now, we need to sum over &lt;script type=&quot;math/tex&quot;&gt;t = 1, 2,\dots&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum_{t=1}^T l_t(w_t) - l_t(u) &amp;\le
	\frac{1}{2\alpha_1} \|w_1 - u\|^2 -
	\frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2
		\\ &amp;\qquad +
	\frac{1}{2} \sum_{t=1}^T \|w_{t+1} - u\|^2 \left( \frac{1}{\alpha_{t+1}} -
		\frac{1}{\alpha_t} \right)
		\\ &amp;\qquad +
	\frac{1}{2} \sum_{t=1}^T \frac{1}{\alpha_t} \|\tilde{w}_{t+1} - w_t\|^2,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;w_1 = 0&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\|w_{t+1} - u\|^2 \le 4U^2&lt;/script&gt;, and
&lt;script type=&quot;math/tex&quot;&gt;\|\tilde{w}_{t+1} - w_t\|^2 = \alpha_t^2 \|\nabla l_t(w_t)\|^2&lt;/script&gt;. Continuing from our
last line and using &lt;script type=&quot;math/tex&quot;&gt;\|\nabla l_t(w_t)\| \le G&lt;/script&gt;, we calculate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum_{t=1}^T l_t(w_t) - l_t(u) &amp;\le
	\frac{U^2}{2\alpha_1} - \frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2
		\\ &amp;\qquad
	+ 2U^2 \sum_{t=1}^{T-1}
		\left( \frac{1}{\alpha_{t+1}} - \frac{1}{\alpha_t} \right)
		\\ &amp;\qquad
	+ \frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2
	- \frac{1}{2\alpha_T} \|w_T - u\|^2
		\\ &amp;\qquad
	+ \frac{G^2}{2} \sum_{t=1}^T \alpha_t,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;by removing the last two terms,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2 \quad \textsf{and} \quad
\frac{1}{2\alpha_T} \|w_T - u\|^2,&lt;/script&gt;

&lt;p&gt;from the summation term involving &lt;script type=&quot;math/tex&quot;&gt;\alpha_{t+1}^{-1} - \alpha_t^{-1}&lt;/script&gt;.
The &lt;script type=&quot;math/tex&quot;&gt;\|w_{T+1} - u\|^2&lt;/script&gt; terms cancel each other and we throw about the &lt;script type=&quot;math/tex&quot;&gt;\|w_T - u\|^2&lt;/script&gt;
term since it‚Äôs negative, leaving us with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum_{t=1}^T l_t(w_t) - l_t(u) &amp;\le
	\frac{U^2}{2\alpha_1} + 2U^2 \sum_{t=1}^{T-1}
		\left( \frac{1}{\alpha_{t+1}} - \frac{1}{\alpha_t} \right)
	+ \frac{G^2}{2} \sum_{t=1}^T \alpha_t \\
&amp;\stackrel{\textsf{(a)}}{\le}
	\frac{2U^2}{\alpha_T} + \frac{G^2}{2} \sum_{t=1}^T \alpha_t,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where we use telescoping and the &lt;em&gt;throw-away-a-negative-term&lt;/em&gt; trick to get the
inequality (a).&lt;/p&gt;

&lt;h4 id=&quot;putting-it-all-together&quot;&gt;Putting it all together&lt;/h4&gt;

&lt;p&gt;We can pick our &lt;script type=&quot;math/tex&quot;&gt;\alpha_t&lt;/script&gt; terms to equate terms in the sum. Specifically,
we choose them as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_t = \frac{\alpha}{\sqrt{t}}.&lt;/script&gt;

&lt;p&gt;So, choosing &lt;script type=&quot;math/tex&quot;&gt;\alpha_t&lt;/script&gt; as above, selecting &lt;script type=&quot;math/tex&quot;&gt;\alpha = U\sqrt{2}/G&lt;/script&gt;, and dividing by
&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt;, our final bound, &lt;em&gt;i.e.&lt;/em&gt;, our &lt;strong&gt;rate&lt;/strong&gt;, is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac{1}{T} \sum_{t=1}^T l_t(w_t) - l_t(u)
	&amp;\le \frac{2U^2}{\alpha\sqrt{T}} + \frac{\alpha G^2}{\sqrt{T}} \\
	&amp;= UG \sqrt{\frac{8}{T}}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;linear-regression-with-squared-loss&quot;&gt;Linear regression with squared loss&lt;/h3&gt;

&lt;p&gt;Let‚Äôs do linear regression with squared loss using the assumptions&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G = 4UX^2&lt;/script&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\|x_t\| \le X&lt;/script&gt;, and&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\|y\| \le UX&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Under this set up our regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;8UX^2\sqrt{2/T}&lt;/script&gt;

&lt;p&gt;since &lt;script type=&quot;math/tex&quot;&gt;\nabla l(w) = 2(w^T x - y)x&lt;/script&gt;.
(The norm bound on &lt;script type=&quot;math/tex&quot;&gt;\nabla l(w)&lt;/script&gt; makes use of the Cauchy‚ÄìSchwarz inequality.)
Now, hold on a sec‚Ä¶ this is the same rate as the Rademacher complexity for the
statistical learning approach!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ reconciling and connecting statistical learning and online learning!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicol√≤ Cesa-Bianchi‚Äôs lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;If you‚Äôre like me, with more of stats background, then this might be an
‚Äúaha!‚Äù moment. If it is, take a moment to enjoy it.¬†&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Don‚Äôt worry if you‚Äôve never heard of reproducing Kernel Hilbert spaces. They won‚Äôt
show up here.¬†&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;The inequality may look more familiar as
&lt;script type=&quot;math/tex&quot;&gt;l_t(w_t) - \nabla l_t (w_t)^T w_t \le l_t(u) - \nabla l_t (w_t)^T u&lt;/script&gt;.¬†&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Welcome back! Today‚Äôs post focuses on the online learning perspective of learning. The online learning approach differs from statistical learning because it makes no assumption on the data source. In other words, the process generating the data is arbitrary!1 Instead of focusing on the data source, online learning makes assumptions on the sequence of loss functions to attain some level of tractability. Yep, you read that correctly: we will have a sequence of loss functions‚Äînot just one to rule them all. If you‚Äôre like me, with more of stats background, then this might be an¬†&amp;#8617;</summary></entry><entry><title type="html">Statistical learning theory - complexity example</title><link href="http://localhost:4000/jekyll/update/2018/05/07/slt-example.html" rel="alternate" type="text/html" title="Statistical learning theory - complexity example" /><published>2018-05-07T22:00:00-06:00</published><updated>2018-05-07T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/07/slt-example</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/07/slt-example.html">&lt;p&gt;This post illustrates how we use Rademacher complexities in statistical learning theory.
To that end, we‚Äôll assume that we‚Äôre working with our toolbox developed in the
&lt;a href=&quot;/jekyll/update/2018/05/06/learning-theory-1.html&quot;&gt;last post&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-quick-recap&quot;&gt;A quick recap&lt;/h3&gt;

&lt;p&gt;Last post, our main result was that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right] \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right],&lt;/script&gt;

&lt;p&gt;which allowed us to bound the statistical risk as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right] +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right),&lt;/script&gt;

&lt;p&gt;with at least probability &lt;script type=&quot;math/tex&quot;&gt;1-\delta&lt;/script&gt;. In other words, Rademacher complexity helps
us measure the tendency of a model class to overfit a sample.&lt;/p&gt;

&lt;h3 id=&quot;warm-up&quot;&gt;Warm up&lt;/h3&gt;

&lt;p&gt;Let‚Äôs Rademacherize our minds with a straightforward application of last post‚Äôs bound.
We‚Äôll assume that our loss functions are &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-Lipschitz. With this and this alone, we
can show that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
	\sum_{i=1}^n \sigma_i l_f(z_i) \right] \le
	L \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
		\sum_{i=1}^n \sigma_i f(x_i) \right].&lt;/script&gt;

&lt;p&gt;This is cool for at least two reasons. The first is that the righthand side doesn‚Äôt
depend on &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; anymore‚Äîonly &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. The second is that the expectation no longer
depends on &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;, but only on &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;linear-regression-with-squared-loss&quot;&gt;Linear regression with squared loss&lt;/h3&gt;

&lt;p&gt;To make these ideas concrete, we‚Äôll look at one of the most commone models arising in
statistics / machine learning: ordinary linear regression. Here‚Äôs our set up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Our class of functions is &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F} = \{\theta \mid x \mapsto \theta^T x\}&lt;/script&gt; where
&lt;script type=&quot;math/tex&quot;&gt;\|\theta\| \le B_\theta&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\|x\| \le B_x&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;By assumption on &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;, we have &lt;script type=&quot;math/tex&quot;&gt;\|y\| \le B_\theta B_x&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Our loss function &lt;script type=&quot;math/tex&quot;&gt;l(\theta^T x, y) = (\theta^T x - y)^2&lt;/script&gt;, with &lt;script type=&quot;math/tex&quot;&gt;L = 4B_\theta B_x&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We‚Äôre interested in the Rademacher complexity of our function class on &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples
&lt;script type=&quot;math/tex&quot;&gt;S = \{(x_1,y_1),\dots,(x_n,y_n)\}&lt;/script&gt;, &lt;em&gt;i.e.&lt;/em&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathcal{R}(\mathcal{F}, S) &amp;= \E_\sigma \left[ \sup_{\theta: \theta \le B_\theta}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \theta^T x_i \right] \\
	&amp;= \frac{1}{n} \E_\sigma \left[ \sup_\theta \theta^T \left(
		\sum_{i=1}^n \sigma_i x_i \right) \right]
		&amp;&amp; {\small \textsf{(linearity)}} \\
	&amp;= \frac{1}{n} \E_\sigma \left[ B_\theta \left\|
		\sum_{i=1}^n \sigma_i x_i \right\| \right]
		&amp;&amp; {\small \textsf{(bound on $\theta$)}} \\
	&amp;= \frac{B_\theta}{n} \E_\sigma \sqrt{ \left\|
		\sum_{i=1}^n \sigma_i x_i \right\|^2 }
		&amp;&amp; {\small \textsf{(square-square root trick)}} \\
	&amp;\le \frac{B_\theta}{n} \sqrt{\E_\sigma \left\|
		\sum_{i=1}^n \sigma_i x_i \right\|^2}
		&amp;&amp; {\small \textsf{(Jensen for concave functions)}} \\
	&amp;\le \frac{B_\theta}{n} \sqrt{n B_x^2}
		&amp;&amp; {\small \textsf{(independence of $\sigma_i$ and $\|\sigma_i\|=1$)}}\\
	&amp;= \frac{B_\theta B_x}{\sqrt{n}} \\
	&amp;= \frac{\textsf{size of model class}}{\textsf{convergence rate}}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The trickiest step is the one that exploits the independence of the Rademacher
random variables and the bound on their norm. It‚Äôs easy to see if we write out
the double sum&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_k \sum_j \sigma_k \sigma_j x_k^T x_j = \sum_k \sigma_k^2 x_k^T x_k +
	\sum_{j \neq k} \sigma_j \sigma_k x_j^T x_k = \sum_k x_k^T x_k,&lt;/script&gt;

&lt;p&gt;because the &lt;script type=&quot;math/tex&quot;&gt;\sigma_j&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\sigma_k&lt;/script&gt; are independent.&lt;/p&gt;

&lt;h3 id=&quot;putting-it-all-together&quot;&gt;Putting it all together&lt;/h3&gt;

&lt;p&gt;From last post and the above calculation, we conclude that with probability at least
&lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) &amp;\le
	\frac{8(B_\theta B_x)^2}{\sqrt{n}} +
	\mathcal{O}\left( \sqrt{\frac{1}{m} \ln \frac{1}{\delta}} \right) \\
	&amp;=\mathcal{R}(\mathcal{F}, S) L +
	\mathcal{O}\left( \sqrt{\frac{1}{m} \ln \frac{1}{\delta}} \right),
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;for empirical risk minimization. Hot diggity!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ the online learning perspective!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicol√≤ Cesa-Bianchi‚Äôs lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">This post illustrates how we use Rademacher complexities in statistical learning theory. To that end, we‚Äôll assume that we‚Äôre working with our toolbox developed in the last post.</summary></entry><entry><title type="html">Learning theory - statistical learning</title><link href="http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1.html" rel="alternate" type="text/html" title="Learning theory - statistical learning" /><published>2018-05-06T11:30:00-06:00</published><updated>2018-05-06T11:30:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1.html">&lt;p&gt;Today‚Äôs post is the first in a set of three that will discuss two theories of learning.
In particular, today‚Äôs post will cover (a very narrow aspect of)
&lt;strong&gt;statistical learning theory&lt;/strong&gt;. The next post will present a game-theoretic
view of learning, using &lt;strong&gt;online learning&lt;/strong&gt; as its primary analytical framework. The
final post will connect the two perspectives.&lt;/p&gt;

&lt;h3 id=&quot;a-bit-of-background&quot;&gt;A bit of background&lt;/h3&gt;

&lt;p&gt;Learning problems, specifically machine learning problems can be analyzed from at
least two perspectives. In either case, our goal is to have a toolbox from which
we can analyze how well a learning system works. For example, we want to be able to
say when learning occurs, when it doesn‚Äôt, and how quickly it occurs or doesn‚Äôt. To
make this problem tractable, we‚Äôll require&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a model for the data;&lt;/li&gt;
  &lt;li&gt;assumptions on the source of that data;&lt;/li&gt;
  &lt;li&gt;functions to generate predictions;&lt;/li&gt;
  &lt;li&gt;loss functions to assess the quality of our predictions; and&lt;/li&gt;
  &lt;li&gt;learning algorithms to help us improve our predictions by understanding our losses.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-set-up&quot;&gt;The set-up&lt;/h3&gt;

&lt;p&gt;We assume that our data consists of &lt;script type=&quot;math/tex&quot;&gt;(x, y)&lt;/script&gt; feature-output pairs with
&lt;script type=&quot;math/tex&quot;&gt;x \in \reals^d&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y \in \reals&lt;/script&gt;. The data comes from some &lt;strong&gt;fixed but unknown&lt;/strong&gt;
source that could be &lt;strong&gt;stochastic&lt;/strong&gt; (as in the statistical learning framework) or
&lt;strong&gt;nonstochastic&lt;/strong&gt; (as in online learning framework).&lt;/p&gt;

&lt;p&gt;We a function &lt;script type=&quot;math/tex&quot;&gt;f: \reals^d \to \reals&lt;/script&gt; that maps data to
estimates/forecasts/predictions. So, &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; gives us a mechanism to
generate our own &lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;‚Äôs that we can compare against the true &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;‚Äôs; we assess
our estimates via a loss function &lt;script type=&quot;math/tex&quot;&gt;l: \reals^n \times \reals \to \reals&lt;/script&gt;. You probably
have many loss functions that you know and love‚Ä¶&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;squared-error loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \|y - \hat{y}\|^2_2&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;absolute-error: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \|y - \hat{y} \|_1&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Kullback‚ÄìLeibler: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = y \log \frac{y}{\hat{y}}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;hinge loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \max \{0, 1 - y \cdot \hat{y} \}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;logistic loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \ln \frac{\hat{y}}{1 - \hat{y}}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The final ingredient is a &lt;strong&gt;learning algorithm&lt;/strong&gt;, which we can think of as a map from data
to models. This is way that V. Vapnik and A. Chervonenkis conceptualized learning
algorithms and we think that it‚Äôs a useful mental model.&lt;/p&gt;

&lt;p&gt;Before diving into either framework let‚Äôs give ourselves a learning goal: our algorithms
should output good models with respect to the data source.&lt;/p&gt;

&lt;h3 id=&quot;statistical-learning-theory&quot;&gt;Statistical learning theory&lt;/h3&gt;

&lt;p&gt;In the statistical learning setting, we assume that our data is generated by a probability
(&lt;em&gt;i.e.&lt;/em&gt;, stochastic) model with distribution
&lt;script type=&quot;math/tex&quot;&gt;\mathcal{D} \subseteq \reals^d \times \reals&lt;/script&gt;. In particular, we‚Äôll assume&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(x, y) \stackrel{\textsf{i.i.d.}}{\sim} \mathcal{D}.&lt;/script&gt;

&lt;p&gt;We are interested in learning by controlling the &lt;strong&gt;statistical risk&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f) = \E \left[ l\big(f(X), Y\big) \right],&lt;/script&gt;

&lt;p&gt;where the expectation is over the randomness in the data &lt;script type=&quot;math/tex&quot;&gt;(X,Y)&lt;/script&gt; and the model &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;
belongs to some class of models &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;. The class of models is a design
parameter that we specify. For example, we could choose a set of linear predictors&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{F} = \left\{\theta \in \reals^d \mid x \mapsto \theta^T x\right\}.&lt;/script&gt;

&lt;p&gt;Since we‚Äôre restricting our models to the class &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;, we‚Äôre really interested
in controlling our risk over that class. So we want a model&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f^\star \in \argmin_{f \in \mathcal{F}} R_{\mathcal{D}}(f).&lt;/script&gt;

&lt;p&gt;But this is statistics, so we don‚Äôt have access to &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; at the population
level. Instead, we have knowledge of &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; through &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples
&lt;script type=&quot;math/tex&quot;&gt;(x_1,y_1),\dots,(x_n,y_n)&lt;/script&gt;. Hmmm‚Ä¶&lt;/p&gt;

&lt;h3 id=&quot;empirical-risk-minimization&quot;&gt;Empirical risk minimization&lt;/h3&gt;

&lt;p&gt;As statistically-minded individuals, we‚Äôll use the &lt;strong&gt;empirical risk&lt;/strong&gt; as a surrogate
for the population risk and pick our model as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_n^\star \in \argmin_{f \in \mathcal{F}} R_n(f)
	= \argmin_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n l\big(f(x_i), y_i\big).&lt;/script&gt;

&lt;p&gt;We want the empirical risk to a be a good proxy for the statistical risk. More
specifically, we want it to be uniformly close to the statistical risk. By &lt;em&gt;uniformly
close&lt;/em&gt;, we mean that we‚Äôre close over all models within our class and all data.&lt;/p&gt;

&lt;p&gt;This might seem a bit extreme, but it prevents us from being lulled into believing we have
a ‚Äúgood‚Äù model by getting easy training data or having an overly complex model
class‚Äîthink interpolating the data.&lt;/p&gt;

&lt;h3 id=&quot;rademacher-complexity&quot;&gt;Rademacher complexity&lt;/h3&gt;

&lt;p&gt;To help us assess our algorithms and models, we turn to &lt;strong&gt;Rademacher averages&lt;/strong&gt;, which
is a Vapnik‚ÄìChervonenkis type notion of complexity that (also) has its origins in the
Russian school of statistics (~1970s). We defined the empirical Rademacher average&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{R}_n(\mathcal{F}, S) = \E_\sigma \left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i f(x_i) \right],&lt;/script&gt;

&lt;p&gt;for a class of functions &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples &lt;script type=&quot;math/tex&quot;&gt;S = \{x_1,\dots,x_n\}&lt;/script&gt;.
Before moving on, note that the empirical Rademacher average does not depend on
&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;, but only on the data. This will prove useful in the sequel.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aside:&lt;/strong&gt; see the &lt;a href=&quot;/jekyll/update/2018/03/04/rademacher.html&quot;&gt;Rademachers are rad - part I&lt;/a&gt; and
&lt;a href=&quot;/jekyll/update/2018/03/06/rademacher_2.html&quot;&gt;Rademachers are rad - part II&lt;/a&gt; post for Rademacher fun in the spirit of
Rademacher complexity.&lt;/p&gt;

&lt;h3 id=&quot;assessing-empirical-risk&quot;&gt;Assessing empirical risk&lt;/h3&gt;

&lt;p&gt;Okay, now we‚Äôre going ready to assess how well empirical risk minimization works by
studying the difference&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f) - R_{\mathcal{D}}(f^\star),&lt;/script&gt;

&lt;p&gt;which is the difference between a suboptimal model and the optimal model‚Äînote that we
don‚Äôt have an empirical risk term‚Ä¶ yet.&lt;/p&gt;

&lt;p&gt;Nonetheless, here goes. We can add and subtract the empirical risk getting&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) &amp;=
	R_{\mathcal{D}}(f_n^\star) - R_n(f_n^\star) +
		R_n(f_n^\star) - R_{\mathcal{D}}(f^\star) \\
	&amp;\le \sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\} +
		R_n(f^\star) - R_{\mathcal{D}}(f^\star).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The &lt;script type=&quot;math/tex&quot;&gt;\sup&lt;/script&gt; term is a comparison of the selected model on the whole distribution versus
the sample. The second term is the error of using the ‚Äúbest‚Äù model on the training sample
versus the whole distribution. The inequality follows from the &lt;script type=&quot;math/tex&quot;&gt;\sup&lt;/script&gt; and the fact that
&lt;script type=&quot;math/tex&quot;&gt;R_n(f_n^\star) \le R_n(f^\star)&lt;/script&gt; by definition of &lt;script type=&quot;math/tex&quot;&gt;f_n^\star&lt;/script&gt;. Also, we can interpret
the first term as a measurement of how much the model overfits the data. And, in some
sense, this is what we want to understand!&lt;/p&gt;

&lt;h3 id=&quot;high-probability-bounds&quot;&gt;High probability bounds&lt;/h3&gt;

&lt;p&gt;Both terms on the righthand side are random variables because they depend on the
training data. So via Chernoff bounds (which we‚Äôre excluding from the current discussion),
we can say that with probability &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\} &amp;\le
	\E \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right]+
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right) \\
R_n(f^\star) - R_{\mathcal{D}}(f^\star) &amp;\le
	\E \bigg[ R_n(f^\star) - R_{\mathcal{D}}(f^\star) \bigg]+
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The expected value of the second term is 0 because the expected value of the empirical
risk, by our i.i.d. assumption, is the statistical risk. You can think of this term as
a bias-like term. The first term is more interesting; it may have caused your
Rademacher neurons to fire, but it‚Äôs not quite a Rademacher average‚Ä¶ yet.&lt;/p&gt;

&lt;h3 id=&quot;the-ghost-sample&quot;&gt;The ghost sample&lt;/h3&gt;

&lt;p&gt;Now, we‚Äôre going to use one of ‚Äúmodern‚Äù statistics favorite tricks: the &lt;strong&gt;ghost sample&lt;/strong&gt;.
The ghost sample allows us to replace a (population) quantity by the sample quantity by
pretending that we have access to a second, made-up sample from the distribution‚Äîit‚Äôs
like we have a second training set. By the ghost sample trick (first equality) and
Jensen‚Äôs inequality, our term is bounded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right]
	&amp;= \E_S \left[\sup_{f \in \mathcal{F}}
		\bigg\{\E_{\tilde{S}} R_{\tilde{n}}(f) - R_n(f)\bigg\}\right]\\
	&amp;\le \E_S \E_{\tilde{S}}
		\left[\sup_{f \in \mathcal{F}}\big\{R_{\tilde{n}}(f) - R_n(f)\big\}\right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Okay, cool. The righthand side is the difference between two empirical risk quantities,
one for the original training sample and the other for the ghost sample. We‚Äôre getting
closer to bounding the overfitting term‚Ä¶&lt;/p&gt;

&lt;h3 id=&quot;rademacher-magic&quot;&gt;Rademacher magic&lt;/h3&gt;

&lt;p&gt;Now, we introduce Rademacher random variables &lt;script type=&quot;math/tex&quot;&gt;\sigma_i \sim \mathsf{Rademacher}&lt;/script&gt; into
the problem which will allow us to bound the overfitting. Think of the Rademachers as
randomly permuting an example from the training set with an example from the ghost sample.
We want to control how much the risk changes when we exchange examples and do so via the
empirical Rademacher average&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_\sigma \left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \big( l_f(\tilde{z}_i) - l_f(z_i) \big) \right],&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;z_i = (x_i, y_i)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_f(z_i)&lt;/script&gt; is the loss function for &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; evaluated on
example &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt;. Now let‚Äôs manipulate this quantity, first distributing terms
and then exchanging the supremum with a sum to get an inequality:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E_\sigma &amp;\left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \big( l_f(\tilde{z}_i) - l_f(z_i) \big) \right]\\
	&amp;= \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) +
	   	\frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right] \\
	&amp;\le \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) + \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right] \\
	&amp;= \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	      \frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) \right] +
		\E_\sigma \left[ \sup_{f \in \mathcal{F}}
	      \frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So, this last calculation, the fact that &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; has the same distribution as
&lt;script type=&quot;math/tex&quot;&gt;-\sigma&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;z \sim \tilde{z}&lt;/script&gt;, imply that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right] \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right].&lt;/script&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ a short-and-sweet example of the material from this post and then the online learning
perspective!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicol√≤ Cesa-Bianchi‚Äôs lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today‚Äôs post is the first in a set of three that will discuss two theories of learning. In particular, today‚Äôs post will cover (a very narrow aspect of) statistical learning theory. The next post will present a game-theoretic view of learning, using online learning as its primary analytical framework. The final post will connect the two perspectives.</summary></entry><entry><title type="html">The entropy method</title><link href="http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro.html" rel="alternate" type="text/html" title="The entropy method" /><published>2018-04-29T22:00:00-06:00</published><updated>2018-04-29T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro.html">&lt;p&gt;Welcome back! This post is going to start us down the path of the &lt;strong&gt;entropy method&lt;/strong&gt;
for obtaining concentration inequalities. The idea is pretty straightforward. We
take a (relevant) modified logarithmic Sobolev inequality and, via a Herbst-type
argument, derive exponential concentration inequalities.&lt;/p&gt;

&lt;p&gt;In a deviation from previous posts, we‚Äôre going to take as given the concentration
behavior (&lt;em&gt;i.e.&lt;/em&gt;, we‚Äôre doing an example instead of a proof) and look at a neat
application that puts it to work.&lt;/p&gt;

&lt;h3 id=&quot;an-eigenvalue-bound&quot;&gt;An eigenvalue bound&lt;/h3&gt;

&lt;p&gt;The largest eigenvalue of a random symmetric matrix is a quantity that naturally
arises in many ‚Äúmodern‚Äù statistical problems‚Äî&lt;em&gt;e.g.&lt;/em&gt;, in random correlation matrices.
We can describe the behavior of the variance of this eigenvalue using the Efron‚ÄìStein
inequality; however, we can obtain concentration convergence rates using the entropy
method. In particular, we‚Äôll use bounded differences-inspired condition to evoke
a fast concentration inequality.&lt;/p&gt;

&lt;p&gt;Assume we have independent random &lt;script type=&quot;math/tex&quot;&gt;X_{ij}, 1 \le i \le j \le n&lt;/script&gt; that are bounded
by 1 in absolute value. The symmetric matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; has entries &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt;. Our
object of interest is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Z = \lambda_{\max} = \sup_{\|u\| = 1} u^T A u = v^T A v,&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; is the eigenvector associated with &lt;script type=&quot;math/tex&quot;&gt;\lambda_{\max}&lt;/script&gt;. Assume that
&lt;script type=&quot;math/tex&quot;&gt;\tilde{X}_{ij}&lt;/script&gt; is an independent copy of &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}_{ij}&lt;/script&gt;
is the matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; with entropy &lt;script type=&quot;math/tex&quot;&gt;(i,j)&lt;/script&gt; replaced by the independent copy.
Similarly, let &lt;script type=&quot;math/tex&quot;&gt;\tilde{Z}_{ij}&lt;/script&gt; be the maximum eigenvalue of &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}_{ij}&lt;/script&gt;.
Here‚Äôs where it starts to get good.&lt;/p&gt;

&lt;p&gt;In the spirit of bounded differences, we can calculate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\big(Z - \tilde{Z}_{ij}\big)_+ &amp;\le
	(v^TAv - v^T\tilde{A}_{ij}v) \ind{} \{Z &gt; \tilde{Z}_{ij}\} \\
	&amp;= \big( v^T(A-\tilde{A}_{ij})v \big) \ind{} \{Z &gt; \tilde{Z}_{ij}\} \\
	&amp;\le 2 \left( v_i v_j \left( X_{ij} - \tilde{X}_{ij} \right) \right)_+ \\
	&amp;\le 4 |v_i v_j|.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The first line results from the assumption on &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; and the use of the indicator variable.
The third line follows from a rewriting of the matrix multiplication and the observation
that all but two entries of the sum cancel each other.&lt;/p&gt;

&lt;p&gt;If we throw this guy into the Efron‚ÄìStein inequality, we get that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Var(Z) \le 16.&lt;/script&gt;

&lt;p&gt;Now, we can use the logarithmic Sobolev machinery to get the exponential
concentration inequality&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob(Z - \E Z &gt; t) \le e^{-t^2 / (2c)} = e^{-t^2 / (32)},&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; is a constant that bounds &lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^n (Z - \tilde{Z}_{ij})^2&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;linear-algebra-aside&quot;&gt;Linear algebra aside&lt;/h3&gt;

&lt;p&gt;A theorem from linear algebra tells us that the maximum eigenvalue of a symmetric
matrix is upper-bounded by the largest row sum and lower-bounded the smallest row
sum. So, the above ideas become interesting and useful when have big matrices‚Ä¶
precisely the kind arising in &lt;em&gt;modern&lt;/em&gt; applications!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ honestly, I‚Äôm not sure! I‚Äôm thinking we could start to unpack the machinery
that supported our blind use of the entropy method. Or it could be about bandits,
prediction with expert advice, Markov chains, something from convex optimization‚Ä¶&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapters 3 and 6 of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Welcome back! This post is going to start us down the path of the entropy method for obtaining concentration inequalities. The idea is pretty straightforward. We take a (relevant) modified logarithmic Sobolev inequality and, via a Herbst-type argument, derive exponential concentration inequalities.</summary></entry><entry><title type="html">Rademachers are rad - part III</title><link href="http://localhost:4000/jekyll/update/2018/04/25/rademacher_3.html" rel="alternate" type="text/html" title="Rademachers are rad - part III" /><published>2018-04-25T17:00:00-06:00</published><updated>2018-04-25T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/25/rademacher_3</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/25/rademacher_3.html">&lt;p&gt;After some ambivalence, I decided that we‚Äôll pay homage to our Rademacher friends
once again. We‚Äôre going to prove a minimax lower bound for an expert prediction
problem. As we‚Äôll see, Rademacher random variables will come to our rescue 
(twice, in fact).&lt;/p&gt;

&lt;h3 id=&quot;prediction-with-experts&quot;&gt;Prediction with experts&lt;/h3&gt;

&lt;p&gt;Let‚Äôs say that we disagree with statistical learning theory on philosophical grounds,
&lt;em&gt;i.e.&lt;/em&gt;, we don‚Äôt believe that our data are generated via a stochastic model that
assumes independence (or exchangeability). Can we predict in the absence of a
statistical assumptions? If so, how would we do it?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Can we predict in the absence of a statistical assumptions?&lt;/em&gt; &lt;strong&gt;Yes!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;If so, how could we do it?&lt;/em&gt; &lt;strong&gt;Using the advice of experts!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;prediction with expert advice&lt;/strong&gt; framework has the following set up:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a decision space &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;an outcome space &lt;script type=&quot;math/tex&quot;&gt;\mathcal{Y}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;a loss function &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;; and&lt;/li&gt;
  &lt;li&gt;a set of expert indices &lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}&lt;/script&gt;;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t = 1, 2, \dots&lt;/script&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;the environment chooses the next outcome &lt;script type=&quot;math/tex&quot;&gt;y_t&lt;/script&gt; and the experts choose
 &lt;script type=&quot;math/tex&quot;&gt;\left\{ f_{E,t} \in \mathcal{D} \mid E \in \mathcal{E} \right\}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the expert advice is provided to the forecaster;&lt;/li&gt;
  &lt;li&gt;the forecast chooses a prediction &lt;script type=&quot;math/tex&quot;&gt;\widehat{p}_t \in \mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the environment reveals the next outcome &lt;script type=&quot;math/tex&quot;&gt;y_t \in \mathcal{Y}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the forecaster incurs a loss &lt;script type=&quot;math/tex&quot;&gt;l(\widehat{p}_t, y_t)&lt;/script&gt; and each expert &lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt; incurs
 a loss &lt;script type=&quot;math/tex&quot;&gt;l(f_{E,t}, y_t)&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;minimax-lower-bound&quot;&gt;Minimax lower bound&lt;/h3&gt;

&lt;p&gt;We want to show that if &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is the absolute loss, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sup_{n,N} \frac{\mathfrak{M}(n,N,l)}{\sqrt{(n/2) \ln N}} \ge 1&lt;/script&gt;

&lt;p&gt;where the minimax regret &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n,N,l) = \inf_P \sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } 
	\sup_{y^n \in \mathcal{Y}^n} \max_{i=1,\dots,N}
	\left\{ \sum_{i=1}^n l(\hat{p}_t, y_t) - l \left( f_{i,t}, y_t \right) \right\},&lt;/script&gt;

&lt;p&gt;with &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt; is a set of &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; static experts, &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; is a forecasting strategy, 
&lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is a &lt;script type=&quot;math/tex&quot;&gt;[0,1]&lt;/script&gt;-valued convex loss function, and &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is the number of rounds.
(A static expert is one with constant-valued predictions, &lt;em&gt;i.e.&lt;/em&gt;, they only depend on the 
current round.)&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;We‚Äôre going to lower bound a lower bound on &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}(n,N,l)&lt;/script&gt;, which may seem
odd, but is a fairly common technique. (So keep it in your back pocket the next time
you have to bound something.) In particular, we‚Äôre going to use the fact that a fixed
class of static experts lower bounds the minimax regret as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n,N,l) \ge 
	\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l)&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l) = \inf_P \sup_{y^n \in \{0,1\}} \sup_{f \in \mathcal{F}}
	\left\{ \sum_{t=1}^n |\hat{p}_t - y_t| -  |f_t - y_t| \right\}.&lt;/script&gt;

&lt;p&gt;Then we‚Äôll lower bound &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l)&lt;/script&gt;, which implies the minimax
regret bound.&lt;/p&gt;

&lt;p&gt;First, we use the &lt;em&gt;average-is-less-than-the-max&lt;/em&gt; trick to get&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l) \ge \inf_P \E \left[ \sup_{f \in \mathcal{F}}
	\left\{ \sum_{t=1}^n |\hat{p}_t - Y_t| -  |f_t - Y_t| \right\} \right],&lt;/script&gt;

&lt;p&gt;where the expectation is over the randomness in &lt;script type=&quot;math/tex&quot;&gt;Y_t&lt;/script&gt;. By the definitions of the 
infimum and supremum, we can rewrite this guy as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\inf_P \E \left[ \sum_{t=1}^n |\hat{p}_t - Y_t| \right] -  
 \E \left[ \inf_{f \in \mathcal{F}} \sum_{t=1}^n |f_t - Y_t| \right].&lt;/script&gt;

&lt;p&gt;Okay, cool. Now we‚Äôre going to use the fact that 
&lt;script type=&quot;math/tex&quot;&gt;\E \sum_{t=1}^n |\hat{p}_t - Y_t| = n/2&lt;/script&gt; for all
forecasting strategies because of the randomness of the &lt;script type=&quot;math/tex&quot;&gt;Y_t&lt;/script&gt;. (To see this, split the
absolute value into two parts, enjoy some nice cancellations and sum it all up.)
We‚Äôll use this fact and then introduce some Rademacher random variables defined as 
&lt;script type=&quot;math/tex&quot;&gt;W_t = 1 - 2Y_t&lt;/script&gt; to write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathfrak{M}(n, \mathcal{F}, l) &amp;\ge 
\frac{n}{2} - \E \left[ \inf_{f \in \mathcal{F}} \sum_{t=1}^n |f_t - Y_t| \right] \\
	&amp;= \E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n \frac{1}{2} - |f_t - Y_t| \right]\\
	&amp;= \E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n 
		\left( \frac{1}{2} - f_t \right)  W_t \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now, let‚Äôs take supremums of both sides, do another Rademacher trick, and then 
exploit the symmetry of Rademachers:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l) 
	&amp;\ge \sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } 
		\E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n \left( \frac{1}{2} - f_t \right) 
		 W_t \right] \\
	&amp;\ge \frac{1}{2} \E \left[ \max_{i=1,...,N} \sum_{t=1}^n Z_{i,t} W_t \right] \\
	&amp;= \frac{1}{2} \E \left[ \max_{i=1,...,N} \sum_{t=1}^n Z_{i,t} \right],
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where we used that &lt;script type=&quot;math/tex&quot;&gt;(1/2)(1 - 2f_t) = (1/2)Z_{i,t}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Z_{i,t}W_t \sim Z_{i,t}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The final step is an appeal to &lt;em&gt;ye-old&lt;/em&gt; central limit theorem and a maximal inequality
for (sub-)Gaussian random variables. The CLT says that for each &lt;script type=&quot;math/tex&quot;&gt;i = 1,\dots,N&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{\sqrt{n}} \sum_{t=1}^n Z_{i,t} \sim N(0,1) \implies
\lim_{n \to \infty} \E \left[ \frac{1}{\sqrt{n}} \max_{i=1,...,N} 
								\sum_{t=1}^n Z_{i,t} \right] =
	\E \left[ \max_{i=1,...,N} X_i \right].&lt;/script&gt;

&lt;p&gt;for standard normals &lt;script type=&quot;math/tex&quot;&gt;X_1,\dots,X_n&lt;/script&gt;. The maximal inequality gives&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E \left[ \max_{i=1,...,N} X_i \right] \le \sqrt{2 \ln N}.&lt;/script&gt;

&lt;p&gt;Now, we stitch everything back together and conclude the proof with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathfrak{M}(n,N,l) &amp;\ge 
	\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l) \\
	&amp;\ge \frac{\E \left[ \max_{i=1,...,N} X_i \right]}{\sqrt{2 \ln N}} \\
	&amp;\ge 1.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Rademacher‚Äôs to the rescue once again.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;‚Ä¶ modified logarithmic Sobolev inequalities &lt;strong&gt;or&lt;/strong&gt; bandits!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapters 2 and 3 of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Prediction, Learning, and Games&lt;/em&gt; by N. Cesa-Bianchi and G. Lugosi.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">After some ambivalence, I decided that we‚Äôll pay homage to our Rademacher friends once again. We‚Äôre going to prove a minimax lower bound for an expert prediction problem. As we‚Äôll see, Rademacher random variables will come to our rescue (twice, in fact).</summary></entry></feed>