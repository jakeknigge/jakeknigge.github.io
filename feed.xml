<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-05-12T12:36:23-06:00</updated><id>http://localhost:4000/</id><title type="html">Eggink Blog</title><subtitle>Jake W. Knigge's blah, blah, blog... a place to discuss statistics, math, and  whatever else comes to mind.
</subtitle><entry><title type="html">Learning theory - reconciliations and connections</title><link href="http://localhost:4000/jekyll/update/2018/05/12/learning-theory-3.html" rel="alternate" type="text/html" title="Learning theory - reconciliations and connections" /><published>2018-05-12T22:00:00-06:00</published><updated>2018-05-12T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/12/learning-theory-3</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/12/learning-theory-3.html">&lt;p&gt;Howdy learning theorists! Today we’re going to connect statistical learning and online
learning. We’ll do via model averaging and exploiting online learning’s local perspective.
To that end, this post could have easily been called “the power of local optimization”,
which has a nice ring to it.&lt;/p&gt;

&lt;p&gt;Our goal is address a few questions that pop up when the online learning approach is
unfamiliar.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What does the online learning regret bound mean?&lt;/li&gt;
  &lt;li&gt;How can that bound be used?&lt;/li&gt;
  &lt;li&gt;How well does the loss rate on the model sequence generalize?&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;the-approach&quot;&gt;The approach&lt;/h3&gt;

&lt;p&gt;Because online learning generates a sequence of models rather than a single model, we
have to pick a model to compare to the empirical risk minimizer. In particular, we’ll
choose the average model. Then we can use the online analysis machinery to provide a
risk bound on that model.&lt;/p&gt;

&lt;p&gt;Assume we have&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;an &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;-dimensional sample &lt;script type=&quot;math/tex&quot;&gt;S = \{(x_1,y_1),\dots,(x_n,y_n)\}&lt;/script&gt; drawn
i.i.d. from a training set &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;a loss function &lt;script type=&quot;math/tex&quot;&gt;l_\mathcal{D}(w)&lt;/script&gt; for linear models &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;a “best” model &lt;script type=&quot;math/tex&quot;&gt;u^\star = \argmin_{u: \|u\| \le U} l_\mathcal{D}(u)&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We want to control the differences&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_\mathcal{D}(\hat{w}) - l_\mathcal{D}(u^\star),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\hat{w}&lt;/script&gt; is the average model. Here’s how we get &lt;script type=&quot;math/tex&quot;&gt;\hat{w}&lt;/script&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;run online gradient descent on our sample set &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;obtain a sequence of models &lt;script type=&quot;math/tex&quot;&gt;w_1,\dots,w_n&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;compute the average model&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{w} = \frac{1}{n} \sum_{i=1}^n w_i.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Aside on averaging.&lt;/strong&gt; Online analysis gives insight on the behavior of the model
sequence but not on any one particular model. So, we need to consolidate our sequence
into something we can analyze. Moreover, averaging is a good way (think of Leo Breiman
and &lt;strong&gt;bagging&lt;/strong&gt;) to reduce variance without impacting an estimator’s bias.&lt;/p&gt;

&lt;h3 id=&quot;expectation-bounds&quot;&gt;Expectation bounds&lt;/h3&gt;

&lt;p&gt;We start by showing that the expected value of the loss of the average model is less
than or equal to the average loss on the model sequence via Jensen’s inequality:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
l_\mathcal{D}\big( \hat{w} \big)
	&amp;= \E \left[ l\left( \frac{1}{n} \sum_{t=1}^n w_t, (X,Y) \right) \right] \\
	&amp;\le \frac{1}{n} \sum_{t=1}^n \E \, l\big(w_t, (X,Y) \big) \\
	&amp;= \frac{1}{n} \sum_{t=1}^n l_\mathcal{D}(w_t).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Cool, now we have something to compare to the best model in the class! But something feels
funny because we have something i.i.d. and something sequential—martingales to the
rescue!&lt;/p&gt;

&lt;h3 id=&quot;martingale-differences&quot;&gt;Martingale differences&lt;/h3&gt;

&lt;p&gt;Martingales are perfectly equipped for taming our sequential process. In particular,
we’ll define the &lt;strong&gt;conditional expectation&lt;/strong&gt; up to time &lt;script type=&quot;math/tex&quot;&gt;t-1&lt;/script&gt; as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_{t-1} [\, \cdot \,] = \E[\, \cdot \mid z_1,\dots,z_{t-1}].&lt;/script&gt;

&lt;p&gt;For now, let’s focus on time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and take the expectation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_{t-1} \big[ \color{red}{l_\mathcal{D}(w_t)}
	- \color{royalblue}{l\left(w_t, (x_t, y_t) \right)} \big] = 0&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\color{red}{l_\mathcal{D}(w_t)}&lt;/script&gt; is the &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;th model and
&lt;script type=&quot;math/tex&quot;&gt;\color{royalblue}{l\left(w_t, (x_t, y_t) \right)}&lt;/script&gt; is the expected loss on the next
example. The expectation is zero because&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the first &lt;script type=&quot;math/tex&quot;&gt;t-1&lt;/script&gt; examples are held fixed, meaning &lt;script type=&quot;math/tex&quot;&gt;l_\mathcal{D}(w_t)&lt;/script&gt; is a constant;
and&lt;/li&gt;
  &lt;li&gt;the expected loss, &lt;em&gt;i.e.&lt;/em&gt;, risk, at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; is
&lt;script type=&quot;math/tex&quot;&gt;\E \, \color{royalblue}{l\left(w_t, (x_t, y_t) \right)} = l_\mathcal{D}(w_t)&lt;/script&gt; because
our data is i.i.d. from &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, we average across our &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; examples&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n
	\E_{t-1} \big[ l_\mathcal{D}(w_t) - l\left(w_t, (x_t, y_t) \right) \big]
	\stackrel{\textsf{notation}}{=}
	\frac{1}{n} \sum_{t=1}^n \E_{t-1} Z_t = 0&lt;/script&gt;

&lt;p&gt;because &lt;script type=&quot;math/tex&quot;&gt;\E_{t-1} Z_t = 0&lt;/script&gt; for each &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;. The random variables &lt;script type=&quot;math/tex&quot;&gt;Z_1,\dots,Z_n&lt;/script&gt; form
a &lt;strong&gt;martingale difference sequence&lt;/strong&gt;, which means we can martingale concentration results
to bound the average. In particular, with probability at least &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n Z_t \le \E \frac{1}{n} \sum_{t=1}^n Z_t +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).&lt;/script&gt;

&lt;p&gt;With this fact, we can bound the risk of the average model!&lt;/p&gt;

&lt;h3 id=&quot;bounding-via-online-analysis&quot;&gt;Bounding via online analysis&lt;/h3&gt;

&lt;p&gt;Thanks to our martingale convergence result, this is a plug-and-play step. So, with
probability at least &lt;script type=&quot;math/tex&quot;&gt;1- \delta&lt;/script&gt; with respect to the random draw of our sample &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
l_\mathcal{D}(\hat{w}) &amp;\le \frac{1}{n} \sum_{t=1}^n l_\mathcal{D}(w_t) \\
	&amp;\le \frac{1}{n} \sum_{t=1}^n l\big(w_t, (x_t, y_t)\big) +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Neural connection.&lt;/strong&gt; This is the same object as what we had in the online learning
analysis because we have a loss rate on the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; models in the sequence—and
all we needed was a slightly modified (&lt;em&gt;i.e.&lt;/em&gt;, &lt;em&gt;martingalified&lt;/em&gt;) concentration result!&lt;/p&gt;

&lt;p&gt;Our last step is to use online analysis to bound the loss rate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(w_t, (x_t, y_t)\big),&lt;/script&gt;

&lt;p&gt;which will give us something that we can compare to the empirical risk minimizer. To make
things concrete, we’ll look at a specific example.&lt;/p&gt;

&lt;h3 id=&quot;linear-regression-with-squared-loss&quot;&gt;Linear regression with squared loss&lt;/h3&gt;

&lt;p&gt;We’re going to show that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(w_t, (x_t, y_t)\big) \le
	\min_{u: \|u\| \le U} \frac{1}{n} \sum_{t=1}^n l\big(u, (x_t, y_t)\big) +
		\delta (UX)^2 \sqrt{\frac{2}{T}}.&lt;/script&gt;

&lt;p&gt;We’ll define &lt;script type=&quot;math/tex&quot;&gt;u^\star_t&lt;/script&gt; as the minimizer of
&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(u, (x_t, y_t)\big)&lt;/script&gt;, which allows us to say that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(u_n^\star, (x_t, y_t)\big) \le
	\frac{1}{n} \sum_{t=1}^n l\big(u^\star, (x_t, y_t)\big),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;u^\star&lt;/script&gt; is the model with the smallest statistical risk over &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;,
not just &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;. So, &lt;script type=&quot;math/tex&quot;&gt;u^\star&lt;/script&gt; may not have the smallest risk over &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;.
(&lt;strong&gt;Neural connection!&lt;/strong&gt; This is the same trick we used in the Rademacher analysis in the
&lt;a href=&quot;/jekyll/update/2018/05/06/learning-theory-1.html&quot;&gt;statistical learning theory post&lt;/a&gt;!)&lt;/p&gt;

&lt;p&gt;Via the Chernoff bound, with probability at least &lt;script type=&quot;math/tex&quot;&gt;1-\delta&lt;/script&gt; we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{n} \sum_{t=1}^n l\big(u_n^\star, (x_t, y_t)\big) \le
	l_\mathcal{D}(u^\star) +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).&lt;/script&gt;

&lt;p&gt;This last expression yields the bound on the average model:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_\mathcal{D}(\hat{w}) - l_\mathcal{D}(u^\star) \le + c\frac{UX^2}{\sqrt{n}}
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; is a constant. This is the same bound obtained from the Rademacher analysis!&lt;/p&gt;

&lt;h3 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The average loss on a sequence of models is a good proxy for the risk of the average
model.&lt;/li&gt;
  &lt;li&gt;Local optimization performs well (up to constant factors), compared to empirical risk
minimization, &lt;em&gt;i.e.&lt;/em&gt;, globabl optimization.
 	+ So, local optimization isn’t doing anything crazy—it’s doing something quite
    similar to global optimization.
    &lt;ul&gt;
      &lt;li&gt;In other words, doing local optimization and then averaging is a good and viable
strategy, especially when we’re dealing with big problems.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, let’s revisit our questions.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;What does the online learning regret bound mean?
    &lt;ul&gt;
      &lt;li&gt;In some sense, it means that we’re bounding an object not unlike the empirical
risk.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How can that bound be used?
    &lt;ul&gt;
      &lt;li&gt;The online learning bound can be used to bound an &lt;em&gt;average&lt;/em&gt; model, which is
comparable to a model found via empirical risk minimization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How well does the loss rate on the model sequence generalize?
    &lt;ul&gt;
      &lt;li&gt;Up to constant factors, it generalizes as well as well the model found through
empirical risk minimization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… a short and sweet example of how strong convexity speeds things up in the online
learning setting! Then a foray into the mind of R.A. Fisher with Brad Efron’s help.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicolò Cesa-Bianchi’s lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Howdy learning theorists! Today we’re going to connect statistical learning and online learning. We’ll do via model averaging and exploiting online learning’s local perspective. To that end, this post could have easily been called “the power of local optimization”, which has a nice ring to it.</summary></entry><entry><title type="html">Learning theory - online learning</title><link href="http://localhost:4000/jekyll/update/2018/05/10/learning-theory-2.html" rel="alternate" type="text/html" title="Learning theory - online learning" /><published>2018-05-10T22:00:00-06:00</published><updated>2018-05-10T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/10/learning-theory-2</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/10/learning-theory-2.html">&lt;p&gt;Welcome back! Today’s post focuses on the &lt;strong&gt;online learning&lt;/strong&gt; perspective of learning.
The online learning approach differs from statistical learning because it makes no
assumption on the data source. In other words, the process generating the data is
arbitrary!&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Instead of focusing on the data source, online learning makes assumptions
on the sequence of loss functions to attain some level of tractability. Yep, you read
that correctly: we will have a sequence of loss functions—not just one to
&lt;em&gt;rule them all&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-protocol-for-online-learning&quot;&gt;A protocol for online learning&lt;/h3&gt;

&lt;p&gt;Here’s how our online learning world works.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An algorithm generates an initial model &lt;script type=&quot;math/tex&quot;&gt;w_1&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t = 1, 2, \dots&lt;/script&gt;, the model is tested on a data point.&lt;/li&gt;
  &lt;li&gt;After being tested, the algorithm updates &lt;script type=&quot;math/tex&quot;&gt;w_t \to w_{t+1}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second step suggests that we’re going to need some notion of loss—&lt;em&gt;i.e.&lt;/em&gt;, something
like risk—to help us &lt;em&gt;test&lt;/em&gt; our model. For our purposes, we’ll assume that
the loss functions we encounter are &lt;strong&gt;convex&lt;/strong&gt;, &lt;strong&gt;nonnegative&lt;/strong&gt;, and &lt;strong&gt;differentiable&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For application-minded readers, model spaces are typically linear but can be finite
dimensional (&lt;em&gt;e.g.&lt;/em&gt;, regression or support vector machine parameters) or infinite
dimensional, via reproducing Kernel Hilbert spaces.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h3 id=&quot;assessing-performance&quot;&gt;Assessing performance&lt;/h3&gt;

&lt;p&gt;We’re going to assess the performance of our (model-generating) algorithm via its
&lt;strong&gt;loss rate&lt;/strong&gt;, defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{T} \sum_{t=1}^T l_t(w_t).&lt;/script&gt;

&lt;p&gt;But this is only part of the story. A loss rate by itself is uninteresting because
losses are arbitrary. So, we’ll focus on controlling our &lt;strong&gt;regret&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{T} \sum_{t=1}^T l_t(w_t) - l_t(w^\star_T),&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w^\star_T = \argmin_{u: \|u\| \le U} \frac{1}{T} \sum_{t=1}^T l_t(u)&lt;/script&gt;

&lt;p&gt;is the best model in the class. When the regret goes to zero, then we are learning and
also experiencing some type of consistency.&lt;/p&gt;

&lt;h3 id=&quot;the-algorithm-of-choice---online-gradient-descent&quot;&gt;The algorithm of choice - online gradient descent&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Online gradient descent&lt;/strong&gt; (OGD) is akin to empirical risk minimization in statistical
learning theory, but it’s a bit different than typical gradient descent because the losses
can vary over time. Nonetheless, the algorithm is quite simple.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Algorithm&lt;/strong&gt; &lt;em&gt;online gradient descent.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;given&lt;/strong&gt; parameters &lt;script type=&quot;math/tex&quot;&gt;\alpha_1,\alpha_2,\dots&lt;/script&gt;, a radius &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt;, and an initial model
&lt;script type=&quot;math/tex&quot;&gt;w_1 = 0&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;repeat&lt;/strong&gt; for &lt;script type=&quot;math/tex&quot;&gt;t=1,2,\dots&lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;compute a tentative gradient step:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{w}_{t+1} = w_t - \alpha_t \nabla l_t(w_t).&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;project back to the model space:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{t+1} = \argmin_{w: \|w\| \le U} \|w - \tilde{w}_{t+1}\|.&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Neural connection.&lt;/strong&gt; Online gradient descent is similar to stochastic gradient except
there’s no stochasticity in the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Food for thought.&lt;/strong&gt;
Online gradient descent is a local optimization perspective rather than global
optimization as in empirical risk minimization. Because of this, online gradient descent
scales gracefully to large problems.&lt;/p&gt;

&lt;h3 id=&quot;analyzing-online-gradient-descent&quot;&gt;Analyzing online gradient descent&lt;/h3&gt;

&lt;p&gt;Let’s fix a time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and analyze the instantaneous regret&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_t(w_t) - l_t(u).&lt;/script&gt;

&lt;p&gt;By convexity, the first-order Taylor expansion of &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; around &lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; gives,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_t(w_t) - l_t(u) \le \nabla l_t (w_t)^T (w_t - u).&lt;/script&gt;

&lt;p&gt;This is pretty much the definition of convexity.&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; By the OGD algorithm, we
calculate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
l_t(w_t) - l_t(u)
&amp;\le \nabla l_t (w_t)^T (w_t - u) \\
&amp;= \frac{1}{\alpha_t} (\tilde{w}_{t+1} - w_t)^T (w_t - u) \\
&amp;\stackrel{\textsf{(a)}}{=}
	\frac{1}{\alpha_t} \left( \frac{1}{2} \|w_t - u\|^2
		- \frac{1}{2} \|\tilde{w}_{t+1} - u\|^2
		+ \frac{1}{2} \|\tilde{w}_{t+1} - w_t\|^2 \right) \\
&amp;\stackrel{\textsf{(b)}}{\le}
	\frac{1}{\alpha_t} \left( \frac{1}{2} \|w_t - u\|^2
		- \frac{1}{2} \|w_{t+1} - u\|^2
		+ \frac{1}{2} \|\tilde{w}_{t+1} - w_t\|^2 \right) \\
&amp;\stackrel{\textsf{(c)}}{=}
	\frac{1}{2\alpha_t} \|w_t - u\|^2
		- \frac{1}{2\alpha_{t+1}} \|w_{t+1} - u\|^2
		- \frac{1}{2\alpha_t} \|w_{t+1} - u\|^2 \\
		&amp;\qquad + \frac{1}{2\alpha_{t+1}} \|w_{t+1} - u\|^2
		+ \frac{1}{2\alpha_t} \|\tilde{w}_{t+1} - w_t\|^2.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;In (a) we compare the current model at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; to the best model &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt; plus a
penalty for changing models. In (b) we use the fact that projecting
&lt;script type=&quot;math/tex&quot;&gt;\tilde{w}_{t+1} \to w_{t+1}&lt;/script&gt; reduces the distance to &lt;script type=&quot;math/tex&quot;&gt;u&lt;/script&gt;; since that term is
negative, we get the inequality. In (c) we add and subtract the same term for reasons
which will become clear shortly.&lt;/p&gt;

&lt;h4 id=&quot;summing-it-up&quot;&gt;Summing it up&lt;/h4&gt;

&lt;p&gt;Now, we need to sum over &lt;script type=&quot;math/tex&quot;&gt;t = 1, 2,\dots&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum_{t=1}^T l_t(w_t) - l_t(u) &amp;\le
	\frac{1}{2\alpha_1} \|w_1 - u\|^2 -
	\frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2
		\\ &amp;\qquad +
	\frac{1}{2} \sum_{t=1}^T \|w_{t+1} - u\|^2 \left( \frac{1}{\alpha_{t+1}} -
		\frac{1}{\alpha_t} \right)
		\\ &amp;\qquad +
	\frac{1}{2} \sum_{t=1}^T \frac{1}{\alpha_t} \|\tilde{w}_{t+1} - w_t\|^2,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;w_1 = 0&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\|w_{t+1} - u\|^2 \le 4U^2&lt;/script&gt;, and
&lt;script type=&quot;math/tex&quot;&gt;\|\tilde{w}_{t+1} - w_t\|^2 = \alpha_t^2 \|\nabla l_t(w_t)\|^2&lt;/script&gt;. Continuing from our
last line and using &lt;script type=&quot;math/tex&quot;&gt;\|\nabla l_t(w_t)\| \le G&lt;/script&gt;, we calculate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum_{t=1}^T l_t(w_t) - l_t(u) &amp;\le
	\frac{U^2}{2\alpha_1} - \frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2
		\\ &amp;\qquad
	+ 2U^2 \sum_{t=1}^{T-1}
		\left( \frac{1}{\alpha_{t+1}} - \frac{1}{\alpha_t} \right)
		\\ &amp;\qquad
	+ \frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2
	- \frac{1}{2\alpha_T} \|w_T - u\|^2
		\\ &amp;\qquad
	+ \frac{G^2}{2} \sum_{t=1}^T \alpha_t,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;by removing the last two terms,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{2\alpha_{T+1}} \|w_{T+1} - u\|^2 \quad \textsf{and} \quad
\frac{1}{2\alpha_T} \|w_T - u\|^2,&lt;/script&gt;

&lt;p&gt;from the summation term involving &lt;script type=&quot;math/tex&quot;&gt;\alpha_{t+1}^{-1} - \alpha_t^{-1}&lt;/script&gt;.
The &lt;script type=&quot;math/tex&quot;&gt;\|w_{T+1} - u\|^2&lt;/script&gt; terms cancel each other and we throw about the &lt;script type=&quot;math/tex&quot;&gt;\|w_T - u\|^2&lt;/script&gt;
term since it’s negative, leaving us with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sum_{t=1}^T l_t(w_t) - l_t(u) &amp;\le
	\frac{U^2}{2\alpha_1} + 2U^2 \sum_{t=1}^{T-1}
		\left( \frac{1}{\alpha_{t+1}} - \frac{1}{\alpha_t} \right)
	+ \frac{G^2}{2} \sum_{t=1}^T \alpha_t \\
&amp;\stackrel{\textsf{(a)}}{\le}
	\frac{2U^2}{\alpha_T} + \frac{G^2}{2} \sum_{t=1}^T \alpha_t,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where we use telescoping and the &lt;em&gt;throw-away-a-negative-term&lt;/em&gt; trick to get the
inequality (a).&lt;/p&gt;

&lt;h4 id=&quot;putting-it-all-together&quot;&gt;Putting it all together&lt;/h4&gt;

&lt;p&gt;We can pick our &lt;script type=&quot;math/tex&quot;&gt;\alpha_t&lt;/script&gt; terms to equate terms in the sum. Specifically,
we choose them as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha_t = \frac{\alpha}{\sqrt{t}}.&lt;/script&gt;

&lt;p&gt;So, choosing &lt;script type=&quot;math/tex&quot;&gt;\alpha_t&lt;/script&gt; as above, selecting &lt;script type=&quot;math/tex&quot;&gt;\alpha = U\sqrt{2}/G&lt;/script&gt;, and dividing by
&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt;, our final bound, &lt;em&gt;i.e.&lt;/em&gt;, our &lt;strong&gt;rate&lt;/strong&gt;, is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac{1}{T} \sum_{t=1}^T l_t(w_t) - l_t(u)
	&amp;\le \frac{2U^2}{\alpha\sqrt{T}} + \frac{\alpha G^2}{\sqrt{T}} \\
	&amp;= UG \sqrt{\frac{8}{T}}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;linear-regression-with-squared-loss&quot;&gt;Linear regression with squared loss&lt;/h3&gt;

&lt;p&gt;Let’s do linear regression with squared loss using the assumptions&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;G = 4UX^2&lt;/script&gt;,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\|x_t\| \le X&lt;/script&gt;, and&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\|y\| \le UX&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Under this set up our regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;8UX^2\sqrt{2/T}&lt;/script&gt;

&lt;p&gt;since &lt;script type=&quot;math/tex&quot;&gt;\nabla l(w) = 2(w^T x - y)x&lt;/script&gt;.
(The norm bound on &lt;script type=&quot;math/tex&quot;&gt;\nabla l(w)&lt;/script&gt; makes use of the Cauchy–Schwarz inequality.)
Now, hold on a sec… this is the same rate as the Rademacher complexity for the
statistical learning approach!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… reconciling and connecting statistical learning and online learning!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicolò Cesa-Bianchi’s lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;If you’re like me, with more of stats background, then this might be an
“aha!” moment. If it is, take a moment to enjoy it. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Don’t worry if you’ve never heard of reproducing Kernel Hilbert spaces. They won’t
show up here. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;The inequality may look more familiar as
&lt;script type=&quot;math/tex&quot;&gt;l_t(w_t) - \nabla l_t (w_t)^T w_t \le l_t(u) - \nabla l_t (w_t)^T u&lt;/script&gt;. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Welcome back! Today’s post focuses on the online learning perspective of learning. The online learning approach differs from statistical learning because it makes no assumption on the data source. In other words, the process generating the data is arbitrary!1 Instead of focusing on the data source, online learning makes assumptions on the sequence of loss functions to attain some level of tractability. Yep, you read that correctly: we will have a sequence of loss functions—not just one to rule them all. If you’re like me, with more of stats background, then this might be an &amp;#8617;</summary></entry><entry><title type="html">Statistical learning theory - complexity example</title><link href="http://localhost:4000/jekyll/update/2018/05/07/slt-example.html" rel="alternate" type="text/html" title="Statistical learning theory - complexity example" /><published>2018-05-07T22:00:00-06:00</published><updated>2018-05-07T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/07/slt-example</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/07/slt-example.html">&lt;p&gt;This post illustrates how we use Rademacher complexities in statistical learning theory.
To that end, we’ll assume that we’re working with our toolbox developed in the
&lt;a href=&quot;/jekyll/update/2018/05/06/learning-theory-1.html&quot;&gt;last post&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;a-quick-recap&quot;&gt;A quick recap&lt;/h3&gt;

&lt;p&gt;Last post, our main result was that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right] \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right],&lt;/script&gt;

&lt;p&gt;which allowed us to bound the statistical risk as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right] +
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right),&lt;/script&gt;

&lt;p&gt;with at least probability &lt;script type=&quot;math/tex&quot;&gt;1-\delta&lt;/script&gt;. In other words, Rademacher complexity helps
us measure the tendency of a model class to overfit a sample.&lt;/p&gt;

&lt;h3 id=&quot;warm-up&quot;&gt;Warm up&lt;/h3&gt;

&lt;p&gt;Let’s Rademacherize our minds with a straightforward application of last post’s bound.
We’ll assume that our loss functions are &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;-Lipschitz. With this and this alone, we
can show that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
	\sum_{i=1}^n \sigma_i l_f(z_i) \right] \le
	L \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
		\sum_{i=1}^n \sigma_i f(x_i) \right].&lt;/script&gt;

&lt;p&gt;This is cool for at least two reasons. The first is that the righthand side doesn’t
depend on &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; anymore—only &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. The second is that the expectation no longer
depends on &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;, but only on &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;linear-regression-with-squared-loss&quot;&gt;Linear regression with squared loss&lt;/h3&gt;

&lt;p&gt;To make these ideas concrete, we’ll look at one of the most commone models arising in
statistics / machine learning: ordinary linear regression. Here’s our set up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Our class of functions is &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F} = \{\theta \mid x \mapsto \theta^T x\}&lt;/script&gt; where
&lt;script type=&quot;math/tex&quot;&gt;\|\theta\| \le B_\theta&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\|x\| \le B_x&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;By assumption on &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;, we have &lt;script type=&quot;math/tex&quot;&gt;\|y\| \le B_\theta B_x&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Our loss function &lt;script type=&quot;math/tex&quot;&gt;l(\theta^T x, y) = (\theta^T x - y)^2&lt;/script&gt;, with &lt;script type=&quot;math/tex&quot;&gt;L = 4B_\theta B_x&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’re interested in the Rademacher complexity of our function class on &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples
&lt;script type=&quot;math/tex&quot;&gt;S = \{(x_1,y_1),\dots,(x_n,y_n)\}&lt;/script&gt;, &lt;em&gt;i.e.&lt;/em&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathcal{R}(\mathcal{F}, S) &amp;= \E_\sigma \left[ \sup_{\theta: \theta \le B_\theta}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \theta^T x_i \right] \\
	&amp;= \frac{1}{n} \E_\sigma \left[ \sup_\theta \theta^T \left(
		\sum_{i=1}^n \sigma_i x_i \right) \right]
		&amp;&amp; {\small \textsf{(linearity)}} \\
	&amp;= \frac{1}{n} \E_\sigma \left[ B_\theta \left\|
		\sum_{i=1}^n \sigma_i x_i \right\| \right]
		&amp;&amp; {\small \textsf{(bound on $\theta$)}} \\
	&amp;= \frac{B_\theta}{n} \E_\sigma \sqrt{ \left\|
		\sum_{i=1}^n \sigma_i x_i \right\|^2 }
		&amp;&amp; {\small \textsf{(square-square root trick)}} \\
	&amp;\le \frac{B_\theta}{n} \sqrt{\E_\sigma \left\|
		\sum_{i=1}^n \sigma_i x_i \right\|^2}
		&amp;&amp; {\small \textsf{(Jensen for concave functions)}} \\
	&amp;\le \frac{B_\theta}{n} \sqrt{n B_x^2}
		&amp;&amp; {\small \textsf{(independence of $\sigma_i$ and $\|\sigma_i\|=1$)}}\\
	&amp;= \frac{B_\theta B_x}{\sqrt{n}} \\
	&amp;= \frac{\textsf{size of model class}}{\textsf{convergence rate}}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The trickiest step is the one that exploits the independence of the Rademacher
random variables and the bound on their norm. It’s easy to see if we write out
the double sum&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_k \sum_j \sigma_k \sigma_j x_k^T x_j = \sum_k \sigma_k^2 x_k^T x_k +
	\sum_{j \neq k} \sigma_j \sigma_k x_j^T x_k = \sum_k x_k^T x_k,&lt;/script&gt;

&lt;p&gt;because the &lt;script type=&quot;math/tex&quot;&gt;\sigma_j&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\sigma_k&lt;/script&gt; are independent.&lt;/p&gt;

&lt;h3 id=&quot;putting-it-all-together&quot;&gt;Putting it all together&lt;/h3&gt;

&lt;p&gt;From last post and the above calculation, we conclude that with probability at least
&lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) &amp;\le
	\frac{8(B_\theta B_x)^2}{\sqrt{n}} +
	\mathcal{O}\left( \sqrt{\frac{1}{m} \ln \frac{1}{\delta}} \right) \\
	&amp;=\mathcal{R}(\mathcal{F}, S) L +
	\mathcal{O}\left( \sqrt{\frac{1}{m} \ln \frac{1}{\delta}} \right),
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;for empirical risk minimization. Hot diggity!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… the online learning perspective!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicolò Cesa-Bianchi’s lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">This post illustrates how we use Rademacher complexities in statistical learning theory. To that end, we’ll assume that we’re working with our toolbox developed in the last post.</summary></entry><entry><title type="html">Learning theory - statistical learning</title><link href="http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1.html" rel="alternate" type="text/html" title="Learning theory - statistical learning" /><published>2018-05-06T11:30:00-06:00</published><updated>2018-05-06T11:30:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/05/06/learning-theory-1.html">&lt;p&gt;Today’s post is the first in a set of three that will discuss two theories of learning.
In particular, today’s post will cover (a very narrow aspect of)
&lt;strong&gt;statistical learning theory&lt;/strong&gt;. The next post will present a game-theoretic
view of learning, using &lt;strong&gt;online learning&lt;/strong&gt; as its primary analytical framework. The
final post will connect the two perspectives.&lt;/p&gt;

&lt;h3 id=&quot;a-bit-of-background&quot;&gt;A bit of background&lt;/h3&gt;

&lt;p&gt;Learning problems, specifically machine learning problems can be analyzed from at
least two perspectives. In either case, our goal is to have a toolbox from which
we can analyze how well a learning system works. For example, we want to be able to
say when learning occurs, when it doesn’t, and how quickly it occurs or doesn’t. To
make this problem tractable, we’ll require&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a model for the data;&lt;/li&gt;
  &lt;li&gt;assumptions on the source of that data;&lt;/li&gt;
  &lt;li&gt;functions to generate predictions;&lt;/li&gt;
  &lt;li&gt;loss functions to assess the quality of our predictions; and&lt;/li&gt;
  &lt;li&gt;learning algorithms to help us improve our predictions by understanding our losses.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-set-up&quot;&gt;The set-up&lt;/h3&gt;

&lt;p&gt;We assume that our data consists of &lt;script type=&quot;math/tex&quot;&gt;(x, y)&lt;/script&gt; feature-output pairs with
&lt;script type=&quot;math/tex&quot;&gt;x \in \reals^d&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y \in \reals&lt;/script&gt;. The data comes from some &lt;strong&gt;fixed but unknown&lt;/strong&gt;
source that could be &lt;strong&gt;stochastic&lt;/strong&gt; (as in the statistical learning framework) or
&lt;strong&gt;nonstochastic&lt;/strong&gt; (as in online learning framework).&lt;/p&gt;

&lt;p&gt;We a function &lt;script type=&quot;math/tex&quot;&gt;f: \reals^d \to \reals&lt;/script&gt; that maps data to
estimates/forecasts/predictions. So, &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; gives us a mechanism to
generate our own &lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;’s that we can compare against the true &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;’s; we assess
our estimates via a loss function &lt;script type=&quot;math/tex&quot;&gt;l: \reals^n \times \reals \to \reals&lt;/script&gt;. You probably
have many loss functions that you know and love…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;squared-error loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \|y - \hat{y}\|^2_2&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;absolute-error: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \|y - \hat{y} \|_1&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Kullback–Leibler: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = y \log \frac{y}{\hat{y}}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;hinge loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \max \{0, 1 - y \cdot \hat{y} \}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;logistic loss: &lt;script type=&quot;math/tex&quot;&gt;l(y, \hat{y}) = \ln \frac{\hat{y}}{1 - \hat{y}}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The final ingredient is a &lt;strong&gt;learning algorithm&lt;/strong&gt;, which we can think of as a map from data
to models. This is way that V. Vapnik and A. Chervonenkis conceptualized learning
algorithms and we think that it’s a useful mental model.&lt;/p&gt;

&lt;p&gt;Before diving into either framework let’s give ourselves a learning goal: our algorithms
should output good models with respect to the data source.&lt;/p&gt;

&lt;h3 id=&quot;statistical-learning-theory&quot;&gt;Statistical learning theory&lt;/h3&gt;

&lt;p&gt;In the statistical learning setting, we assume that our data is generated by a probability
(&lt;em&gt;i.e.&lt;/em&gt;, stochastic) model with distribution
&lt;script type=&quot;math/tex&quot;&gt;\mathcal{D} \subseteq \reals^d \times \reals&lt;/script&gt;. In particular, we’ll assume&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(x, y) \stackrel{\textsf{i.i.d.}}{\sim} \mathcal{D}.&lt;/script&gt;

&lt;p&gt;We are interested in learning by controlling the &lt;strong&gt;statistical risk&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f) = \E \left[ l\big(f(X), Y\big) \right],&lt;/script&gt;

&lt;p&gt;where the expectation is over the randomness in the data &lt;script type=&quot;math/tex&quot;&gt;(X,Y)&lt;/script&gt; and the model &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;
belongs to some class of models &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;. The class of models is a design
parameter that we specify. For example, we could choose a set of linear predictors&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{F} = \left\{\theta \in \reals^d \mid x \mapsto \theta^T x\right\}.&lt;/script&gt;

&lt;p&gt;Since we’re restricting our models to the class &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;, we’re really interested
in controlling our risk over that class. So we want a model&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f^\star \in \argmin_{f \in \mathcal{F}} R_{\mathcal{D}}(f).&lt;/script&gt;

&lt;p&gt;But this is statistics, so we don’t have access to &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; at the population
level. Instead, we have knowledge of &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; through &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples
&lt;script type=&quot;math/tex&quot;&gt;(x_1,y_1),\dots,(x_n,y_n)&lt;/script&gt;. Hmmm…&lt;/p&gt;

&lt;h3 id=&quot;empirical-risk-minimization&quot;&gt;Empirical risk minimization&lt;/h3&gt;

&lt;p&gt;As statistically-minded individuals, we’ll use the &lt;strong&gt;empirical risk&lt;/strong&gt; as a surrogate
for the population risk and pick our model as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_n^\star \in \argmin_{f \in \mathcal{F}} R_n(f)
	= \argmin_{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n l\big(f(x_i), y_i\big).&lt;/script&gt;

&lt;p&gt;We want the empirical risk to a be a good proxy for the statistical risk. More
specifically, we want it to be uniformly close to the statistical risk. By &lt;em&gt;uniformly
close&lt;/em&gt;, we mean that we’re close over all models within our class and all data.&lt;/p&gt;

&lt;p&gt;This might seem a bit extreme, but it prevents us from being lulled into believing we have
a “good” model by getting easy training data or having an overly complex model
class—think interpolating the data.&lt;/p&gt;

&lt;h3 id=&quot;rademacher-complexity&quot;&gt;Rademacher complexity&lt;/h3&gt;

&lt;p&gt;To help us assess our algorithms and models, we turn to &lt;strong&gt;Rademacher averages&lt;/strong&gt;, which
is a Vapnik–Chervonenkis type notion of complexity that (also) has its origins in the
Russian school of statistics (~1970s). We defined the empirical Rademacher average&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{R}_n(\mathcal{F}, S) = \E_\sigma \left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i f(x_i) \right],&lt;/script&gt;

&lt;p&gt;for a class of functions &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; samples &lt;script type=&quot;math/tex&quot;&gt;S = \{x_1,\dots,x_n\}&lt;/script&gt;.
Before moving on, note that the empirical Rademacher average does not depend on
&lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;, but only on the data. This will prove useful in the sequel.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aside:&lt;/strong&gt; see the &lt;a href=&quot;/jekyll/update/2018/03/04/rademacher.html&quot;&gt;Rademachers are rad - part I&lt;/a&gt; and
&lt;a href=&quot;/jekyll/update/2018/03/06/rademacher_2.html&quot;&gt;Rademachers are rad - part II&lt;/a&gt; post for Rademacher fun in the spirit of
Rademacher complexity.&lt;/p&gt;

&lt;h3 id=&quot;assessing-empirical-risk&quot;&gt;Assessing empirical risk&lt;/h3&gt;

&lt;p&gt;Okay, now we’re going ready to assess how well empirical risk minimization works by
studying the difference&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{\mathcal{D}}(f) - R_{\mathcal{D}}(f^\star),&lt;/script&gt;

&lt;p&gt;which is the difference between a suboptimal model and the optimal model—note that we
don’t have an empirical risk term… yet.&lt;/p&gt;

&lt;p&gt;Nonetheless, here goes. We can add and subtract the empirical risk getting&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
R_{\mathcal{D}}(f_n^\star) - R_{\mathcal{D}}(f^\star) &amp;=
	R_{\mathcal{D}}(f_n^\star) - R_n(f_n^\star) +
		R_n(f_n^\star) - R_{\mathcal{D}}(f^\star) \\
	&amp;\le \sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\} +
		R_n(f^\star) - R_{\mathcal{D}}(f^\star).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The &lt;script type=&quot;math/tex&quot;&gt;\sup&lt;/script&gt; term is a comparison of the selected model on the whole distribution versus
the sample. The second term is the error of using the “best” model on the training sample
versus the whole distribution. The inequality follows from the &lt;script type=&quot;math/tex&quot;&gt;\sup&lt;/script&gt; and the fact that
&lt;script type=&quot;math/tex&quot;&gt;R_n(f_n^\star) \le R_n(f^\star)&lt;/script&gt; by definition of &lt;script type=&quot;math/tex&quot;&gt;f_n^\star&lt;/script&gt;. Also, we can interpret
the first term as a measurement of how much the model overfits the data. And, in some
sense, this is what we want to understand!&lt;/p&gt;

&lt;h3 id=&quot;high-probability-bounds&quot;&gt;High probability bounds&lt;/h3&gt;

&lt;p&gt;Both terms on the righthand side are random variables because they depend on the
training data. So via Chernoff bounds (which we’re excluding from the current discussion),
we can say that with probability &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\} &amp;\le
	\E \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right]+
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right) \\
R_n(f^\star) - R_{\mathcal{D}}(f^\star) &amp;\le
	\E \bigg[ R_n(f^\star) - R_{\mathcal{D}}(f^\star) \bigg]+
	\mathcal{O} \left( \sqrt{\frac{1}{n} \ln \frac{1}{\delta}} \right).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The expected value of the second term is 0 because the expected value of the empirical
risk, by our i.i.d. assumption, is the statistical risk. You can think of this term as
a bias-like term. The first term is more interesting; it may have caused your
Rademacher neurons to fire, but it’s not quite a Rademacher average… yet.&lt;/p&gt;

&lt;h3 id=&quot;the-ghost-sample&quot;&gt;The ghost sample&lt;/h3&gt;

&lt;p&gt;Now, we’re going to use one of “modern” statistics favorite tricks: the &lt;strong&gt;ghost sample&lt;/strong&gt;.
The ghost sample allows us to replace a (population) quantity by the sample quantity by
pretending that we have access to a second, made-up sample from the distribution—it’s
like we have a second training set. By the ghost sample trick (first equality) and
Jensen’s inequality, our term is bounded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right]
	&amp;= \E_S \left[\sup_{f \in \mathcal{F}}
		\bigg\{\E_{\tilde{S}} R_{\tilde{n}}(f) - R_n(f)\bigg\}\right]\\
	&amp;\le \E_S \E_{\tilde{S}}
		\left[\sup_{f \in \mathcal{F}}\big\{R_{\tilde{n}}(f) - R_n(f)\big\}\right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Okay, cool. The righthand side is the difference between two empirical risk quantities,
one for the original training sample and the other for the ghost sample. We’re getting
closer to bounding the overfitting term…&lt;/p&gt;

&lt;h3 id=&quot;rademacher-magic&quot;&gt;Rademacher magic&lt;/h3&gt;

&lt;p&gt;Now, we introduce Rademacher random variables &lt;script type=&quot;math/tex&quot;&gt;\sigma_i \sim \mathsf{Rademacher}&lt;/script&gt; into
the problem which will allow us to bound the overfitting. Think of the Rademachers as
randomly permuting an example from the training set with an example from the ghost sample.
We want to control how much the risk changes when we exchange examples and do so via the
empirical Rademacher average&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_\sigma \left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \big( l_f(\tilde{z}_i) - l_f(z_i) \big) \right],&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;z_i = (x_i, y_i)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_f(z_i)&lt;/script&gt; is the loss function for &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; evaluated on
example &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt;. Now let’s manipulate this quantity, first distributing terms
and then exchanging the supremum with a sum to get an inequality:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E_\sigma &amp;\left[ \sup_{f \in \mathcal{F}}
 	\frac{1}{n} \sum_{i=1}^n \sigma_i \big( l_f(\tilde{z}_i) - l_f(z_i) \big) \right]\\
	&amp;= \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) +
	   	\frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right] \\
	&amp;\le \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) + \sup_{f \in \mathcal{F}}
	   	\frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right] \\
	&amp;= \E_\sigma \left[ \sup_{f \in \mathcal{F}}
	      \frac{1}{n} \sum_{i=1}^n \sigma_i l_f(\tilde{z}_i) \right] +
		\E_\sigma \left[ \sup_{f \in \mathcal{F}}
	      \frac{1}{n} \sum_{i=1}^n (-\sigma_i) l_f(z_i) \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;So, this last calculation, the fact that &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; has the same distribution as
&lt;script type=&quot;math/tex&quot;&gt;-\sigma&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;z \sim \tilde{z}&lt;/script&gt;, imply that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E_S \left[\sup_{f \in \mathcal{F}} \big\{ R_{\mathcal{D}}(f) - R_n(f) \big\}\right] \le
	2 \E_S \E_\sigma \left[ \sup_{f \in \mathcal{F}} \frac{1}{n}
					\sum_{i=1}^n \sigma_i l_f(z_i) \right].&lt;/script&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… a short-and-sweet example of the material from this post and then the online learning
perspective!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Nicolò Cesa-Bianchi’s lectures at the Bordeaux
Machine Learning Summer School in 2011. Watch them here: &lt;a href=&quot;http://videolectures.net/mlss2011_cesa_bianchi_learningtheory/&quot;&gt;MLSS 2011 lectures&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today’s post is the first in a set of three that will discuss two theories of learning. In particular, today’s post will cover (a very narrow aspect of) statistical learning theory. The next post will present a game-theoretic view of learning, using online learning as its primary analytical framework. The final post will connect the two perspectives.</summary></entry><entry><title type="html">The entropy method</title><link href="http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro.html" rel="alternate" type="text/html" title="The entropy method" /><published>2018-04-29T22:00:00-06:00</published><updated>2018-04-29T22:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/29/entropy_method_intro.html">&lt;p&gt;Welcome back! This post is going to start us down the path of the &lt;strong&gt;entropy method&lt;/strong&gt;
for obtaining concentration inequalities. The idea is pretty straightforward. We
take a (relevant) modified logarithmic Sobolev inequality and, via a Herbst-type
argument, derive exponential concentration inequalities.&lt;/p&gt;

&lt;p&gt;In a deviation from previous posts, we’re going to take as given the concentration
behavior (&lt;em&gt;i.e.&lt;/em&gt;, we’re doing an example instead of a proof) and look at a neat
application that puts it to work.&lt;/p&gt;

&lt;h3 id=&quot;an-eigenvalue-bound&quot;&gt;An eigenvalue bound&lt;/h3&gt;

&lt;p&gt;The largest eigenvalue of a random symmetric matrix is a quantity that naturally
arises in many “modern” statistical problems—&lt;em&gt;e.g.&lt;/em&gt;, in random correlation matrices.
We can describe the behavior of the variance of this eigenvalue using the Efron–Stein
inequality; however, we can obtain concentration convergence rates using the entropy
method. In particular, we’ll use bounded differences-inspired condition to evoke
a fast concentration inequality.&lt;/p&gt;

&lt;p&gt;Assume we have independent random &lt;script type=&quot;math/tex&quot;&gt;X_{ij}, 1 \le i \le j \le n&lt;/script&gt; that are bounded
by 1 in absolute value. The symmetric matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; has entries &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt;. Our
object of interest is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Z = \lambda_{\max} = \sup_{\|u\| = 1} u^T A u = v^T A v,&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; is the eigenvector associated with &lt;script type=&quot;math/tex&quot;&gt;\lambda_{\max}&lt;/script&gt;. Assume that
&lt;script type=&quot;math/tex&quot;&gt;\tilde{X}_{ij}&lt;/script&gt; is an independent copy of &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}_{ij}&lt;/script&gt;
is the matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; with entropy &lt;script type=&quot;math/tex&quot;&gt;(i,j)&lt;/script&gt; replaced by the independent copy.
Similarly, let &lt;script type=&quot;math/tex&quot;&gt;\tilde{Z}_{ij}&lt;/script&gt; be the maximum eigenvalue of &lt;script type=&quot;math/tex&quot;&gt;\tilde{A}_{ij}&lt;/script&gt;.
Here’s where it starts to get good.&lt;/p&gt;

&lt;p&gt;In the spirit of bounded differences, we can calculate&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\big(Z - \tilde{Z}_{ij}\big)_+ &amp;\le
	(v^TAv - v^T\tilde{A}_{ij}v) \ind{} \{Z &gt; \tilde{Z}_{ij}\} \\
	&amp;= \big( v^T(A-\tilde{A}_{ij})v \big) \ind{} \{Z &gt; \tilde{Z}_{ij}\} \\
	&amp;\le 2 \left( v_i v_j \left( X_{ij} - \tilde{X}_{ij} \right) \right)_+ \\
	&amp;\le 4 |v_i v_j|.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;The first line results from the assumption on &lt;script type=&quot;math/tex&quot;&gt;v&lt;/script&gt; and the use of the indicator variable.
The third line follows from a rewriting of the matrix multiplication and the observation
that all but two entries of the sum cancel each other.&lt;/p&gt;

&lt;p&gt;If we throw this guy into the Efron–Stein inequality, we get that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Var(Z) \le 16.&lt;/script&gt;

&lt;p&gt;Now, we can use the logarithmic Sobolev machinery to get the exponential
concentration inequality&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob(Z - \E Z &gt; t) \le e^{-t^2 / (2c)} = e^{-t^2 / (32)},&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; is a constant that bounds &lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^n (Z - \tilde{Z}_{ij})^2&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;linear-algebra-aside&quot;&gt;Linear algebra aside&lt;/h3&gt;

&lt;p&gt;A theorem from linear algebra tells us that the maximum eigenvalue of a symmetric
matrix is upper-bounded by the largest row sum and lower-bounded the smallest row
sum. So, the above ideas become interesting and useful when have big matrices…
precisely the kind arising in &lt;em&gt;modern&lt;/em&gt; applications!&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… honestly, I’m not sure! I’m thinking we could start to unpack the machinery
that supported our blind use of the entropy method. Or it could be about bandits,
prediction with expert advice, Markov chains, something from convex optimization…&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapters 3 and 6 of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Welcome back! This post is going to start us down the path of the entropy method for obtaining concentration inequalities. The idea is pretty straightforward. We take a (relevant) modified logarithmic Sobolev inequality and, via a Herbst-type argument, derive exponential concentration inequalities.</summary></entry><entry><title type="html">Rademachers are rad - part III</title><link href="http://localhost:4000/jekyll/update/2018/04/25/rademacher_3.html" rel="alternate" type="text/html" title="Rademachers are rad - part III" /><published>2018-04-25T17:00:00-06:00</published><updated>2018-04-25T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/25/rademacher_3</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/25/rademacher_3.html">&lt;p&gt;After some ambivalence, I decided that we’ll pay homage to our Rademacher friends
once again. We’re going to prove a minimax lower bound for an expert prediction
problem. As we’ll see, Rademacher random variables will come to our rescue 
(twice, in fact).&lt;/p&gt;

&lt;h3 id=&quot;prediction-with-experts&quot;&gt;Prediction with experts&lt;/h3&gt;

&lt;p&gt;Let’s say that we disagree with statistical learning theory on philosophical grounds,
&lt;em&gt;i.e.&lt;/em&gt;, we don’t believe that our data are generated via a stochastic model that
assumes independence (or exchangeability). Can we predict in the absence of a
statistical assumptions? If so, how would we do it?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Can we predict in the absence of a statistical assumptions?&lt;/em&gt; &lt;strong&gt;Yes!&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;If so, how could we do it?&lt;/em&gt; &lt;strong&gt;Using the advice of experts!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;prediction with expert advice&lt;/strong&gt; framework has the following set up:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a decision space &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;an outcome space &lt;script type=&quot;math/tex&quot;&gt;\mathcal{Y}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;a loss function &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;; and&lt;/li&gt;
  &lt;li&gt;a set of expert indices &lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}&lt;/script&gt;;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t = 1, 2, \dots&lt;/script&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;the environment chooses the next outcome &lt;script type=&quot;math/tex&quot;&gt;y_t&lt;/script&gt; and the experts choose
 &lt;script type=&quot;math/tex&quot;&gt;\left\{ f_{E,t} \in \mathcal{D} \mid E \in \mathcal{E} \right\}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the expert advice is provided to the forecaster;&lt;/li&gt;
  &lt;li&gt;the forecast chooses a prediction &lt;script type=&quot;math/tex&quot;&gt;\widehat{p}_t \in \mathcal{D}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the environment reveals the next outcome &lt;script type=&quot;math/tex&quot;&gt;y_t \in \mathcal{Y}&lt;/script&gt;;&lt;/li&gt;
  &lt;li&gt;the forecaster incurs a loss &lt;script type=&quot;math/tex&quot;&gt;l(\widehat{p}_t, y_t)&lt;/script&gt; and each expert &lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt; incurs
 a loss &lt;script type=&quot;math/tex&quot;&gt;l(f_{E,t}, y_t)&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;minimax-lower-bound&quot;&gt;Minimax lower bound&lt;/h3&gt;

&lt;p&gt;We want to show that if &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is the absolute loss, then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sup_{n,N} \frac{\mathfrak{M}(n,N,l)}{\sqrt{(n/2) \ln N}} \ge 1&lt;/script&gt;

&lt;p&gt;where the minimax regret &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n,N,l) = \inf_P \sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } 
	\sup_{y^n \in \mathcal{Y}^n} \max_{i=1,\dots,N}
	\left\{ \sum_{i=1}^n l(\hat{p}_t, y_t) - l \left( f_{i,t}, y_t \right) \right\},&lt;/script&gt;

&lt;p&gt;with &lt;script type=&quot;math/tex&quot;&gt;\mathcal{F}&lt;/script&gt; is a set of &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; static experts, &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; is a forecasting strategy, 
&lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt; is a &lt;script type=&quot;math/tex&quot;&gt;[0,1]&lt;/script&gt;-valued convex loss function, and &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is the number of rounds.
(A static expert is one with constant-valued predictions, &lt;em&gt;i.e.&lt;/em&gt;, they only depend on the 
current round.)&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;We’re going to lower bound a lower bound on &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}(n,N,l)&lt;/script&gt;, which may seem
odd, but is a fairly common technique. (So keep it in your back pocket the next time
you have to bound something.) In particular, we’re going to use the fact that a fixed
class of static experts lower bounds the minimax regret as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n,N,l) \ge 
	\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l)&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l) = \inf_P \sup_{y^n \in \{0,1\}} \sup_{f \in \mathcal{F}}
	\left\{ \sum_{t=1}^n |\hat{p}_t - y_t| -  |f_t - y_t| \right\}.&lt;/script&gt;

&lt;p&gt;Then we’ll lower bound &lt;script type=&quot;math/tex&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l)&lt;/script&gt;, which implies the minimax
regret bound.&lt;/p&gt;

&lt;p&gt;First, we use the &lt;em&gt;average-is-less-than-the-max&lt;/em&gt; trick to get&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathfrak{M}(n, \mathcal{F}, l) \ge \inf_P \E \left[ \sup_{f \in \mathcal{F}}
	\left\{ \sum_{t=1}^n |\hat{p}_t - Y_t| -  |f_t - Y_t| \right\} \right],&lt;/script&gt;

&lt;p&gt;where the expectation is over the randomness in &lt;script type=&quot;math/tex&quot;&gt;Y_t&lt;/script&gt;. By the definitions of the 
infimum and supremum, we can rewrite this guy as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\inf_P \E \left[ \sum_{t=1}^n |\hat{p}_t - Y_t| \right] -  
 \E \left[ \inf_{f \in \mathcal{F}} \sum_{t=1}^n |f_t - Y_t| \right].&lt;/script&gt;

&lt;p&gt;Okay, cool. Now we’re going to use the fact that 
&lt;script type=&quot;math/tex&quot;&gt;\E \sum_{t=1}^n |\hat{p}_t - Y_t| = n/2&lt;/script&gt; for all
forecasting strategies because of the randomness of the &lt;script type=&quot;math/tex&quot;&gt;Y_t&lt;/script&gt;. (To see this, split the
absolute value into two parts, enjoy some nice cancellations and sum it all up.)
We’ll use this fact and then introduce some Rademacher random variables defined as 
&lt;script type=&quot;math/tex&quot;&gt;W_t = 1 - 2Y_t&lt;/script&gt; to write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathfrak{M}(n, \mathcal{F}, l) &amp;\ge 
\frac{n}{2} - \E \left[ \inf_{f \in \mathcal{F}} \sum_{t=1}^n |f_t - Y_t| \right] \\
	&amp;= \E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n \frac{1}{2} - |f_t - Y_t| \right]\\
	&amp;= \E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n 
		\left( \frac{1}{2} - f_t \right)  W_t \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now, let’s take supremums of both sides, do another Rademacher trick, and then 
exploit the symmetry of Rademachers:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l) 
	&amp;\ge \sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } 
		\E \left[ \sup_{f \in \mathcal{F}} \sum_{t=1}^n \left( \frac{1}{2} - f_t \right) 
		 W_t \right] \\
	&amp;\ge \frac{1}{2} \E \left[ \max_{i=1,...,N} \sum_{t=1}^n Z_{i,t} W_t \right] \\
	&amp;= \frac{1}{2} \E \left[ \max_{i=1,...,N} \sum_{t=1}^n Z_{i,t} \right],
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where we used that &lt;script type=&quot;math/tex&quot;&gt;(1/2)(1 - 2f_t) = (1/2)Z_{i,t}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Z_{i,t}W_t \sim Z_{i,t}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The final step is an appeal to &lt;em&gt;ye-old&lt;/em&gt; central limit theorem and a maximal inequality
for (sub-)Gaussian random variables. The CLT says that for each &lt;script type=&quot;math/tex&quot;&gt;i = 1,\dots,N&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{\sqrt{n}} \sum_{t=1}^n Z_{i,t} \sim N(0,1) \implies
\lim_{n \to \infty} \E \left[ \frac{1}{\sqrt{n}} \max_{i=1,...,N} 
								\sum_{t=1}^n Z_{i,t} \right] =
	\E \left[ \max_{i=1,...,N} X_i \right].&lt;/script&gt;

&lt;p&gt;for standard normals &lt;script type=&quot;math/tex&quot;&gt;X_1,\dots,X_n&lt;/script&gt;. The maximal inequality gives&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E \left[ \max_{i=1,...,N} X_i \right] \le \sqrt{2 \ln N}.&lt;/script&gt;

&lt;p&gt;Now, we stitch everything back together and conclude the proof with&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathfrak{M}(n,N,l) &amp;\ge 
	\sup_{ \{ \mathcal{F}: |\mathcal{F}| = N \} } \mathfrak{M}(n, \mathcal{F}, l) \\
	&amp;\ge \frac{\E \left[ \max_{i=1,...,N} X_i \right]}{\sqrt{2 \ln N}} \\
	&amp;\ge 1.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Rademacher’s to the rescue once again.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… modified logarithmic Sobolev inequalities &lt;strong&gt;or&lt;/strong&gt; bandits!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapters 2 and 3 of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Prediction, Learning, and Games&lt;/em&gt; by N. Cesa-Bianchi and G. Lugosi.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">After some ambivalence, I decided that we’ll pay homage to our Rademacher friends once again. We’re going to prove a minimax lower bound for an expert prediction problem. As we’ll see, Rademacher random variables will come to our rescue (twice, in fact).</summary></entry><entry><title type="html">A neat inequality</title><link href="http://localhost:4000/jekyll/update/2018/04/21/ineq.html" rel="alternate" type="text/html" title="A neat inequality" /><published>2018-04-21T17:00:00-06:00</published><updated>2018-04-21T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/21/ineq</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/21/ineq.html">&lt;p&gt;As promised, this post will be about the useful inequality from 
&lt;a href=&quot;/jekyll/update/2018/04/07/lsi.html&quot;&gt;logarithmic Sobolev inequality post&lt;/a&gt;. Without further ado…&lt;/p&gt;

&lt;h3 id=&quot;starting-simple&quot;&gt;Starting simple&lt;/h3&gt;

&lt;p&gt;We are going to prove the inequality&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left( e^{z/2} - e^{y/2} \right)^2 \le \frac{(z-y)^2}{8}(e^{z} + e^{y})&lt;/script&gt;

&lt;p&gt;for real numbers &lt;script type=&quot;math/tex&quot;&gt;z \ge y&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;We can rewrite the inequality as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left( e^{(z-y)/2} - 1 \right)^2 \le \frac{(z-y)^2}{8}(e^{z-y} + 1).&lt;/script&gt;

&lt;p&gt;Now, let’s define &lt;script type=&quot;math/tex&quot;&gt;x = z - y&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;x \ge 0&lt;/script&gt; because &lt;script type=&quot;math/tex&quot;&gt;z \ge y&lt;/script&gt;. Let’s
move everything to the righthand side and open up the square, which gives&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0 \le \frac{x^2}{8} (e^x + 1) - \left( e^x - 2e^{x/2} + 1 \right).&lt;/script&gt;

&lt;p&gt;Now, let’s collect like terms&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0 \le e^x \left( \frac{x^2}{8} - 1 \right) + \frac{x^2}{8} + 2e^{x/2} - 1 = f(x).&lt;/script&gt;

&lt;p&gt;When &lt;script type=&quot;math/tex&quot;&gt;x = 0&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;f(x)&lt;/script&gt;, &lt;em&gt;i.e.&lt;/em&gt;, the righthand side, is also 0. Let’s look at the
derivative of &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; to see whether the function is increasing or decreasing:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{df(x)}{dx} = \frac{1}{8} e^x (x^2 + 2x - 8) + \frac{x}{4} + e^{x/2}.&lt;/script&gt;

&lt;p&gt;Unfortunately, that pesky &lt;script type=&quot;math/tex&quot;&gt;-e^x&lt;/script&gt; means we still have some work to do. Let’s 
keep taking derivatives and see if we can’t get rid of that negative:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\frac{d^2f(x)}{dx^2} &amp;= 
	\frac{1}{8} \left( e^x \left( x^2 + 4x - 6 \right) + 4e^{x/2} + 2 \right) \\
\frac{d^3f(x)}{dx^3} &amp;= 
	\frac{1}{8} \left( e^x \left( x^2 + 6x - 2 \right) + 2e^{x/2} \right) \\
\frac{d^4f(x)}{dx^4} &amp;= 
	\frac{1}{8} \left( e^x \left( x^2 + 8x + 4 \right) + e^{x/2} \right).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Cool! The righthand side of &lt;script type=&quot;math/tex&quot;&gt;\frac{d^4f(x)}{dx^4} &gt; 0&lt;/script&gt; since &lt;script type=&quot;math/tex&quot;&gt;x \ge 0&lt;/script&gt;. 
Also, we have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{df(0)}{dx} = \frac{d^2f(0)}{dx^2} = \frac{d^3f(0)}{dx^3} = 0,&lt;/script&gt;

&lt;p&gt;which means we’re in good shape (because the fourth derivative being positive). 
In particular, we integrate the fourth derivative four times and conclude that 
our original function that is always greater than or equal to zero&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
0 \le
\int \frac{d^4f(x)}{dx^4} \, d^4x &amp;= \frac{e^x (x^2 - 8)}{8} + 2 e^{(x/2)}
	+ \frac{c_1 x^3}{6} + \frac{c_2 x^2}{2} + c_3 x + c_4 \\
		&amp;= e^x \left( \frac{x^2}{8} - 1 \right) + \frac{x^2}{8} + 2e^{x/2} - 1,
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;c_4 = -1&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;c_3 = 0&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;c_2 = 1/4&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;c_1 = 0&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;remarks&quot;&gt;Remarks&lt;/h4&gt;

&lt;p&gt;This inequality is neat because you can approach it a few different ways. If
we didn’t use &lt;script type=&quot;math/tex&quot;&gt;x = z - y&lt;/script&gt;, and worked directly with the function of &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt;
and &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;, we could’ve gotten away with taking two derivatives instead of 
four. I find the “&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;-consolidated”, “fourth derivative” approach easier 
as it requires less bookkeeping for &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;And the best for last: the easiest way to solve this problem is to plot it. 😏&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… more Rademacher rad-ness, modified logarithmic Sobolev inequalities &lt;strong&gt;or&lt;/strong&gt; 
bandits!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is related to material from Chapter 5 of (my new favorite book):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by 
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">As promised, this post will be about the useful inequality from logarithmic Sobolev inequality post. Without further ado…</summary></entry><entry><title type="html">Upper confidence bounds</title><link href="http://localhost:4000/jekyll/update/2018/04/18/ucb.html" rel="alternate" type="text/html" title="Upper confidence bounds" /><published>2018-04-18T21:00:00-06:00</published><updated>2018-04-18T21:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/18/ucb</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/18/ucb.html">&lt;p&gt;Today we’re going to prove the upper bound that results from the upper
confidence bound (UCB) strategy. The UCB strategy allowed us to bound
the pseudo-regret by a term which is logarithmic in the number of
rounds played. Generally speaking, “good” regret bounds for bandit problems
are sublinear in the number of rounds played.&lt;/p&gt;

&lt;h3 id=&quot;stochastic-bandit-problems&quot;&gt;Stochastic bandit problems&lt;/h3&gt;

&lt;p&gt;As a quick review, here’s the set-up for the stochastic multi-armed bandit
problem.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are &lt;script type=&quot;math/tex&quot;&gt;\{1,\dots,K\}&lt;/script&gt; arms.&lt;/li&gt;
  &lt;li&gt;Each arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; corresponds to an unknown probability distribution &lt;script type=&quot;math/tex&quot;&gt;p_i&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, the player selects an arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; (independently of 
previous choices) and receives a reward &lt;script type=&quot;math/tex&quot;&gt;X_{I_t,t} \sim p_{I_t}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;We assess a player’s performance by her &lt;strong&gt;regret&lt;/strong&gt;, which
compares her performance to (something like) the best-possible performance.&lt;/li&gt;
  &lt;li&gt;After the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds of the game, the player’s regret is&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_n = \max_{i=1,\dots,K} \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t},&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;where &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; is the number of bandit arms, &lt;script type=&quot;math/tex&quot;&gt;X_{i,t}&lt;/script&gt; is the reward of arm 
&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; is the player’s (possibly randomly) chosen arm.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll denote the mean of distribution &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;\mu_i&lt;/script&gt; and define&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu^\star = \max_{i=1,\dots,K} \mu_i \quad \textsf{and} \quad
	i^\star = \argmax_{i=1,\dots,K} \mu_i&lt;/script&gt;

&lt;p&gt;as optimal parameters. Instead of using the regret to assess our player’s performance,
we’ll use the &lt;strong&gt;pseudo-regret&lt;/strong&gt;, which is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\bar{R}_n &amp;= \max_{i=1,\dots,K} \E 
	\left[ \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t} \right] \\
	&amp;= n \mu^\star - \E \sum_{t=1}^n \mu_{I_t}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;We know that &lt;script type=&quot;math/tex&quot;&gt;\bar{R}_n \le \E R_n&lt;/script&gt; because of Jensen’s inequality for convex 
functions. For our purposes, a more informative form of the pseudo-regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n = \sum_{i=1}^K \Delta_i \E T_i(n),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\Delta_i = \mu^\star - \mu_i&lt;/script&gt; is the suboptimality of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and the
random variable &lt;script type=&quot;math/tex&quot;&gt;T_i(n) = \sum_{i=1}^n \ind{}\{I_t = i\}&lt;/script&gt; is the number of times 
arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is selected in the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds.&lt;/p&gt;

&lt;h3 id=&quot;upper-confidence-bounds&quot;&gt;Upper confidence bounds&lt;/h3&gt;

&lt;p&gt;One approach for simultaneously performing &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;exploitation&lt;/strong&gt; is 
to use &lt;strong&gt;upper confidence bound&lt;/strong&gt; (UCB) strategies. UCB strategies produce upper
bounds (based on a confidence level) on the current estimate for each arm’s mean 
reward. The player selects the arm that is the best using the UCB-modified estimate.&lt;/p&gt;

&lt;p&gt;In the spirit of brevity, we’re going to gloss over a few important details 
(&lt;em&gt;e.g.&lt;/em&gt;, Legendre–Fenchel duals and Hoeffding’s lemma) but here’s the gist of 
the UCB set-up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define &lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,n} = \frac{1}{n} \sum_{j=1}^n X_{i,j}&lt;/script&gt; as the sample
mean of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; after being played &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; times.&lt;/li&gt;
  &lt;li&gt;For a convex function &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; with convex conjugate &lt;script type=&quot;math/tex&quot;&gt;\psi^*&lt;/script&gt; and parameter 
&lt;script type=&quot;math/tex&quot;&gt;\lambda &gt; 0&lt;/script&gt;, the cumulant generating function of &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; is bounded by &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln \E e^{\lambda(X - \E X)} \le \psi(\lambda) \quad \textsf{and} \quad
\ln \E e^{\lambda(\E X - X)} \le \psi(\lambda).&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;By Markov’s inequality and the Cramér–Chernoff technique&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left( \mu_i - \widehat{\mu}_{i,n} \ge \varepsilon \right) \le
	e^{-n \psi^*(\varepsilon)}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Markov’s inequality means that, with probability &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;, we have an 
upper bound on the estimate of the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th arm:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mu_i &lt; \widehat{\mu}_{i,n} + (\psi^*)^{-1} 
	\left(\frac{1}{n} \ln \frac{1}{\delta} \right). %]]&gt;&lt;/script&gt;

&lt;p&gt;The &lt;strong&gt;UCB strategy&lt;/strong&gt; is (very) simple; at each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, select the arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_t \in \argmax_{i=1,\dots,K} \left\{ \widehat{\mu}_{i,T_i(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) \right\}.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;The tradeoff.&lt;/strong&gt;
Let’s pick apart this term and see how it encourages exploration and exploitation.
We’re going to use &lt;script type=&quot;math/tex&quot;&gt;\psi(x) = x^2/8&lt;/script&gt; with convex conjugate 
&lt;script type=&quot;math/tex&quot;&gt;\psi^*(z) = 2z^2&lt;/script&gt;, so that &lt;script type=&quot;math/tex&quot;&gt;(\psi^*)^{-1}(z) = (x/2)^{1/2}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;When arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; has not been played many times before time $t$, &lt;em&gt;i.e.&lt;/em&gt;, when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; is small numerator of &lt;script type=&quot;math/tex&quot;&gt;\frac{\alpha \ln t}{T_i(t-1)}&lt;/script&gt; dominates 
and the UCB-adjusted estimate of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is likely to relatively high, which
encourages arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; to be chosen. In other words, it encourages exploration.&lt;/p&gt;

&lt;p&gt;As arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is chosen more, &lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; increases and the estimate
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; improves. If arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is the optimal arm, then the 
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; term dominates the estimates for other arms and the
UCB-adjustment further encourages selection of this arm. This means that the 
algorithm exploits high-yielding arms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Upper bound on pseudo-regret.&lt;/strong&gt;
If our player follows the UCB scheme specified above, then for &lt;script type=&quot;math/tex&quot;&gt;\alpha &gt; 2&lt;/script&gt;
her pseudo-regret is upperbounded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n \le \sum_{i: \Delta_i &gt; 0} \left( 
\frac{\alpha \Delta_i}{\psi^*(\Delta_i / 2)} \ln n + \frac{\alpha}{\alpha - 2} 
\right).&lt;/script&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;Okay, here goes. We incur regret when we don’t pick the optimal arm, &lt;em&gt;i.e.&lt;/em&gt;,
when &lt;script type=&quot;math/tex&quot;&gt;I_t \neq i^\star&lt;/script&gt;. So, we need to analyze the conditions that lead
us to choose a suboptimal arm.&lt;/p&gt;

&lt;p&gt;Assume we’ve played arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; a total of &lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; times and arm &lt;script type=&quot;math/tex&quot;&gt;i^\star&lt;/script&gt; 
a total of &lt;script type=&quot;math/tex&quot;&gt;T_{i^\star}(t-1)&lt;/script&gt; times. By the set up of our bandit scenario, 
if &lt;script type=&quot;math/tex&quot;&gt;I_t = i&lt;/script&gt;, &lt;em&gt;i.e.&lt;/em&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_t = i = \argmax_{j=1,\dots,K} \left\{ \widehat{\mu}_{j,T_j(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) \right\},&lt;/script&gt;

&lt;p&gt;then at least one of the following holds&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\widehat{\mu}_{i^\star, T_{i^\star}(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_{i^\star}(t-1)} \right) &amp;\le \mu^\star 
	&amp;&amp; \#1 \\
\mu_i + (\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) &amp;&lt; 
	\widehat{\mu}_{i, T_i(t-1)} &amp;&amp; \#2 \\
\mu^\star - 2(\psi^*)^{-1} \left( \frac{\alpha \ln n}{T_i(t-1)} \right) &amp;&lt; \mu_i &amp;&amp; \#3.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The first indicates that our current UCB-adjusted estimate of the mean for the
optimal arm is less than its true value. It occurs with probability&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left(  \widehat{\mu}_{i^\star, T_{i^\star}(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_{i^\star}(t-1)} \right) 
	\ge \mu^\star \right) \le 
	\exp \left ( -\alpha \ln t \right) = t^{-\alpha}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The second indicates that our estimate for arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; exceeds its true value by
an amount greater than the UCB—hence the UCB adjustment is not yet helpful. 
It occurs with probability&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left(  \mu_i + (\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) &gt; 
	\widehat{\mu}_{i, T_i(t-1)} \right) \le 
	\exp \left ( -\alpha \ln t \right) = t^{-\alpha}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The third follows from similar logic as the second, and is illuminated by 
the rewriting:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\Delta_i  = \mu^\star - \mu_i &amp;&lt; 
	2(\psi^*)^{-1} \left( \frac{\alpha \ln n}{T_i(t-1)} \right) \\
\psi^*(\Delta_i / 2) &lt; \frac{\alpha \ln n}{T_i(t-1)} &amp;\iff
T_i(t-1) &lt; \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The probability of the third event is 0 when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(n) \ge u = 
  \left\lceil \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} \right\rceil&lt;/script&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If #1, #2, and #3 are false, then we pick the optimal arm, meaning we incur
no regret.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, we let’s consider the implications of these events on &lt;script type=&quot;math/tex&quot;&gt;\E T_i(t-1)&lt;/script&gt;,
because this will allow us to bound the pseudo-regret. We have that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\E T_i(n) &amp;= \E \sum_{t=1}^n \ind{}\{I_t = i\} \\
	&amp;\le u + \E \sum_{t=u+1}^n \ind{}\{I_t = i \textsf{ and inequality #3 is false}\} \\
	&amp;\le u + \E \sum_{t=u+1}^n \ind{}\{\textsf{inequality #1 or #2 is true}\} \\
	&amp;= u + \sum_{t=u+1}^n \prob\left( \ind{\textsf{inequality #1}} \right) + 
		\prob\left( \ind{\textsf{inequality #2}} \right) \\
	&amp;\le u + 2\sum_{t=1}^n \sum_{s=1}^t \frac{1}{t^\alpha} \\
	&amp;= u + 2\sum_{t=1}^n \frac{1}{t^{\alpha-1}} \\
	&amp;\le \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} + 
		2 \int_{1}^{\infty} \frac{dt}{t^{\alpha-1}} \\
	&amp;= \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} + \frac{\alpha}{\alpha-2}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;em&gt;(It took me a few times to follow that argument, so I would re-read it a few times.
I also put some notes in the &lt;a href=&quot;#the-intermediate-steps&quot;&gt;intermediate steps&lt;/a&gt;
subsection below.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now, we just sum over the suboptimal arms to get the pseudo-regret bound&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n \le \sum_{i: \Delta_i &gt; 0} \left( 
\frac{\alpha \Delta_i}{\psi^*(\Delta_i / 2)} \ln n + \frac{\alpha}{\alpha - 2}
\right).&lt;/script&gt;

&lt;p&gt;This is the proof given in Bubeck and Cesa-Bianchi’s &lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;bandits survey&lt;/a&gt;, 
which is an adaptation of the proof of Auer, Cesa-Bianchi, and Fischer’s
&lt;a href=&quot;http://cesa-bianchi.di.unimi.it/Pubblicazioni/ml-02.pdf&quot;&gt;original analysis&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… a proof of that cool inequality that helped us in the proof of 
concentration inequality implied by the 
&lt;a href=&quot;/jekyll/update/2018/04/07/lsi.html&quot;&gt;logarithmic Sobolev inequality&lt;/a&gt; a few posts back!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems&lt;/em&gt;
by S. Bubeck and N. Cesa-Bianchi. A digital copy can be found 
&lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Finite-time Analysis of the Multiarmed Bandit Problem&lt;/em&gt; by P. Auer, N. 
Cesa-Bianchi, and P. Fischer. A digital copy can be found &lt;a href=&quot;http://cesa-bianchi.di.unimi.it/Pubblicazioni/ml-02.pdf&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Prediction, Learning, and Games&lt;/em&gt; (a.k.a. “Perdition, Burning, and Flames”) 
by N. Cesa-Bianchi and G. Lugosi. Find a description of the book and its 
table of contents &lt;a href=&quot;http://cesa-bianchi.di.unimi.it/predbook/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;the-intermediate-steps&quot;&gt;The intermediate steps&lt;/h4&gt;

&lt;p&gt;We can interpret the relationship&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\E T_i(n) = \E \sum_{t=1}^n \ind{}\{I_t = i\} \le 
	u + \E \sum_{t=u+1}^n \ind{}\{I_t = i \textsf{ and inequality #3 is false}\}&lt;/script&gt;

&lt;p&gt;by observing that the indicator &lt;script type=&quot;math/tex&quot;&gt;\ind{}\{I_t = i\}&lt;/script&gt; and be written as
&lt;script type=&quot;math/tex&quot;&gt;\ind{}\{I_t = i \textsf{ and inequality #3 is false or true}\}&lt;/script&gt;. 
Inequality #3 is true when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(k) \le u = 
	\left\lceil \frac{\alpha \ln n}{\psi^*(\Delta_i / 2)} \right\rceil&lt;/script&gt;.
So, the bound follows by assuming that indicator is active at &lt;script type=&quot;math/tex&quot;&gt;k=1,\dots,u&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Because we allow either #1 or #2 to be true, the event&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\big\{I_t = i \textsf{ and inequality #3 is false}\big\} \subseteq
	\big\{\textsf{inequality #1 or #2 is true}\big\},&lt;/script&gt;

&lt;p&gt;meaning the probability of the second event is larger.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today we’re going to prove the upper bound that results from the upper confidence bound (UCB) strategy. The UCB strategy allowed us to bound the pseudo-regret by a term which is logarithmic in the number of rounds played. Generally speaking, “good” regret bounds for bandit problems are sublinear in the number of rounds played.</summary></entry><entry><title type="html">Bandits!</title><link href="http://localhost:4000/jekyll/update/2018/04/14/bandits.html" rel="alternate" type="text/html" title="Bandits!" /><published>2018-04-14T17:00:00-06:00</published><updated>2018-04-14T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/14/bandits</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/14/bandits.html">&lt;p&gt;Today we’re talking about bandits. Bandit problems, not dissimilar from Markov 
chains, are one of those simple models that apply to a wide variety of
problems. Indeed, many results of “sequential decision making” stem from
the study of bandit problems. Plus the name is cool, so that should provide
some motivation for wanting to study them. The name &lt;strong&gt;bandit&lt;/strong&gt; originates 
from the term &lt;strong&gt;one-armed bandit&lt;/strong&gt;, which was used to describe slot machines.&lt;/p&gt;

&lt;p&gt;In their &lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;survey on bandits&lt;/a&gt;, Bubeck and Cesa-Bianchi define 
a multi-armed bandit problem as “a sequential allocation problem defined by a 
set of actions.” The allocation problem is similar to a (repeated) game: at 
each point in time, the player chooses an action &lt;em&gt;i.e.&lt;/em&gt;, an arm, and receives 
a reward.&lt;/p&gt;

&lt;p&gt;The player’s goal is to maximize her cumulative reward, which naturally leads to
an &lt;strong&gt;exploitation vs. exploration&lt;/strong&gt; problem. The player needs to simultaneously 
exploit arms known to yield high rewards and explore other arms in the hopes 
of finding other high-yield rewards.&lt;/p&gt;

&lt;p&gt;In bandit problems, we assess a player’s performance by her &lt;strong&gt;regret&lt;/strong&gt;, which
compares her performance to (something like) the best-possible performance. 
After the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds of the game, the player’s regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_n = \max_{i=1,\dots,K} \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t},&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; is the number of bandit arms, &lt;script type=&quot;math/tex&quot;&gt;X_{i,t}&lt;/script&gt; is the reward of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at
time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; is the player’s (possibly randomly) chosen arm.&lt;/p&gt;

&lt;h3 id=&quot;stochastic-bandit-problems&quot;&gt;Stochastic bandit problems&lt;/h3&gt;

&lt;p&gt;In this post, we’re going to focus on &lt;strong&gt;stochastic bandit problems&lt;/strong&gt; as opposed
to &lt;strong&gt;adversarially bandit problems&lt;/strong&gt;. Here’s the set-up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There are &lt;script type=&quot;math/tex&quot;&gt;\{1,\dots,K\}&lt;/script&gt; arms.&lt;/li&gt;
  &lt;li&gt;Each arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; corresponds to an unknown probability distribution &lt;script type=&quot;math/tex&quot;&gt;p_i&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;At each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, the player selects an arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; (independently of 
previous choices) and receives a reward &lt;script type=&quot;math/tex&quot;&gt;X_{I_t,t} \sim p_{I_t}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll denote the mean of distribution &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;\mu_i&lt;/script&gt; and define&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu^\star = \max_{i=1,\dots,K} \mu_i \quad \textsf{and} \quad
	i^\star = \argmax_{i=1,\dots,K} \mu_i&lt;/script&gt;

&lt;p&gt;as optimal parameters. Instead of using the regret to assess our player’s performance,
we’ll use the &lt;strong&gt;pseudo-regret&lt;/strong&gt;, which is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\bar{R}_n &amp;= \max_{i=1,\dots,K} \E 
	\left[ \sum_{i=1}^n X_{i,t} - \sum_{i=1}^n X_{I_t,t} \right] \\
	&amp;= n \mu^\star - \E \sum_{t=1}^n \mu_{I_t}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;We know that &lt;script type=&quot;math/tex&quot;&gt;\bar{R}_n \le \E R_n&lt;/script&gt; because of Jensen’s inequality for convex 
functions. For our purposes, a more informative form of the pseudo-regret is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n = \sum_{i=1}^K \Delta_i \E T_i(n),&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\Delta_i = \mu^\star - \mu_i&lt;/script&gt; is the suboptimality of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and the
random variable &lt;script type=&quot;math/tex&quot;&gt;T_i(n) = \sum_{i=1}^n \ind{}\{I_t = i\}&lt;/script&gt; is the number of times 
arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is selected in the first &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; rounds.&lt;/p&gt;

&lt;p&gt;This alternative expression for the pseudo-regret sums over arms rather than rounds.
To see how we switched from arms to rounds, play around with random variables 
&lt;script type=&quot;math/tex&quot;&gt;T_i(n)&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;upper-confidence-bounds&quot;&gt;Upper confidence bounds&lt;/h3&gt;

&lt;p&gt;One approach for simultaneously performing &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;exploitation&lt;/strong&gt; is 
to use &lt;strong&gt;upper confidence bound&lt;/strong&gt; (UCB) strategies. UCB strategies produce upper
bounds (based on a confidence level) on the current estimate for each arm’s mean 
reward. The player selects the arm that is the best using the UCB-modified estimate.&lt;/p&gt;

&lt;p&gt;In the spirit of brevity, we’re going to gloss over a few important details 
(&lt;em&gt;e.g.&lt;/em&gt;, Legendre–Fenchel duals and Hoeffding’s lemma) but here’s the gist of 
the UCB set-up.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define &lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,n} = \frac{1}{n} \sum_{j=1}^n X_{i,j}&lt;/script&gt; as the sample
mean of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; after being played &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; times.&lt;/li&gt;
  &lt;li&gt;For a convex function &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; with convex conjugate &lt;script type=&quot;math/tex&quot;&gt;\psi^*&lt;/script&gt; and parameter 
&lt;script type=&quot;math/tex&quot;&gt;\lambda &gt; 0&lt;/script&gt;, the cumulant generating function of &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; is bounded by &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln \E e^{\lambda(X - \E X)} \le \psi(\lambda) \quad \textsf{and} \quad
\ln \E e^{\lambda(\E X - X)} \le \psi(\lambda).&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;By Markov’s inequality and the Cramér–Chernoff technique&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob \left( \mu_i - \widehat{\mu}_{i,n} \ge \varepsilon \right) \le
	e^{-n \psi^*(\varepsilon)}.&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Markov’s inequality means that, with probability &lt;script type=&quot;math/tex&quot;&gt;1 - \delta&lt;/script&gt;, we have an 
upper bound on the estimate of the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th arm:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mu_i &lt; \widehat{\mu}_{i,n} + (\psi^*)^{-1} 
	\left(\frac{1}{n} \ln \frac{1}{\delta} \right). %]]&gt;&lt;/script&gt;

&lt;p&gt;The UCB strategy is (very) simple; at each time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, select the arm &lt;script type=&quot;math/tex&quot;&gt;I_t&lt;/script&gt; by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I_t \in \argmax_{i=1,\dots,K} \left\{ \widehat{\mu}_{i,T_i(t-1)} + 
	(\psi^*)^{-1} \left( \frac{\alpha \ln t}{T_i(t-1)} \right) \right\}.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;The tradeoff.&lt;/strong&gt;
Let’s pick apart this term and see how it encourages exploration and exploitation.
We’re going to use &lt;script type=&quot;math/tex&quot;&gt;\psi(x) = x^2/8&lt;/script&gt; with convex conjugate 
&lt;script type=&quot;math/tex&quot;&gt;\psi^*(z) = 2z^2&lt;/script&gt;, so that &lt;script type=&quot;math/tex&quot;&gt;(\psi^*)^{-1}(z) = (x/2)^{1/2}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;When arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; has not been played many times before time $t$, &lt;em&gt;i.e.&lt;/em&gt;, when 
&lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; is small numerator of &lt;script type=&quot;math/tex&quot;&gt;\frac{\alpha \ln t}{T_i(t-1)}&lt;/script&gt; dominates 
and the UCB-adjusted estimate of arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is likely to relatively high, which
encourages arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; to be chosen. In other words, it encourages exploration.&lt;/p&gt;

&lt;p&gt;As arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is chosen more, &lt;script type=&quot;math/tex&quot;&gt;T_i(t-1)&lt;/script&gt; increases and the estimate
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; improves. If arm &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is the optimal arm, then the 
&lt;script type=&quot;math/tex&quot;&gt;\widehat{\mu}_{i,T_i(t-1)}&lt;/script&gt; term dominates the estimates for other arms and the
UCB-adjustment further encourages selection of this arm. This means that the 
algorithm exploits high-yielding arms.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Upper bound on pseudo-regret.&lt;/strong&gt;
If our player follows the UCB scheme specified above, then for &lt;script type=&quot;math/tex&quot;&gt;\alpha &gt; 2&lt;/script&gt;
her pseudo-regret is upperbounded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{R}_n \le \sum_{i: \Delta_i &gt; 0} \left( 
\frac{\alpha \Delta_i}{\psi^*(\Delta_i / 2)} \ln n + \frac{\alpha}{\alpha - 2} 
\right).&lt;/script&gt;

&lt;p&gt;We’re going to prove the bound in the next post.&lt;/p&gt;

&lt;h3 id=&quot;bandit-simulations&quot;&gt;Bandit simulations&lt;/h3&gt;

&lt;p&gt;Here’s an &lt;a href=&quot;https://github.com/jakeknigge/ucb-bandits/blob/master/bandits.R&quot;&gt;R script&lt;/a&gt; which uses the upper confidence bound algorithm.
For the plots below, there are &lt;script type=&quot;math/tex&quot;&gt;K = 3&lt;/script&gt; arms and &lt;script type=&quot;math/tex&quot;&gt;n = 1000&lt;/script&gt; rounds. The reward 
distributions are Bernoulli’s and the mean parameters the three arms are 0.46, 0.72, 
and 0.55.&lt;/p&gt;

&lt;p&gt;The first plot shows the evolution of each mean estimate as different rounds are
played.
&lt;img src=&quot;/assets/2018-04-14_bandit_arm_est.png&quot; alt=&quot;Bandit arm estimates&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next plot illustrates the exploration vs. exploitation trade-off. Even
though arm 2 yields the highest rewards, the algorithm occasionally plays 
arms 1 and 3 in later rounds.
&lt;img src=&quot;/assets/2018-04-14_bandit_arms_played.png&quot; alt=&quot;Bandit regret&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The final plot shows the player’s cumulative regret compared to the UCB-implied
upper bound on the regret; the lower bound is distribution-dependent and
asymptotic, which is why it exceeds the pseudo-regret until round 400ish.
&lt;img src=&quot;/assets/2018-04-14_bandit_regret.png&quot; alt=&quot;Bandit regret&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;… a proof of the upper confidence bound regret rate!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems&lt;/em&gt;
by S. Bubeck and N. Cesa-Bianchi. A digital copy can be found 
&lt;a href=&quot;http://sbubeck.com/SurveyBCB12.pdf&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Prediction, Learning, and Games&lt;/em&gt; (a.k.a. “Perdition, Burning, and Flames”) 
by N. Cesa-Bianchi and G. Lugosi. Find a description of the book and its 
table of contents &lt;a href=&quot;http://cesa-bianchi.di.unimi.it/predbook/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I would also recommend checking out Sébastien Bubeck’s blog 
&lt;a href=&quot;https://blogs.princeton.edu/imabandit&quot;&gt;“I’m a bandit”&lt;/a&gt; and, in particular, his bandit tutorials:
&lt;a href=&quot;https://blogs.princeton.edu/imabandit/2016/05/11/bandit-theory-part-i/&quot;&gt;part 1&lt;/a&gt; and &lt;a href=&quot;https://blogs.princeton.edu/imabandit/2016/05/13/bandit-theory-part-ii/&quot;&gt;part 2&lt;/a&gt;. Also check out his new YouTube
channel: https://www.youtube.com/user/sebastienbubeck/videos.&lt;/p&gt;</content><author><name></name></author><summary type="html">Today we’re talking about bandits. Bandit problems, not dissimilar from Markov chains, are one of those simple models that apply to a wide variety of problems. Indeed, many results of “sequential decision making” stem from the study of bandit problems. Plus the name is cool, so that should provide some motivation for wanting to study them. The name bandit originates from the term one-armed bandit, which was used to describe slot machines.</summary></entry><entry><title type="html">Logarithmic Sobolev inequalities</title><link href="http://localhost:4000/jekyll/update/2018/04/07/lsi.html" rel="alternate" type="text/html" title="Logarithmic Sobolev inequalities" /><published>2018-04-07T17:00:00-06:00</published><updated>2018-04-07T17:00:00-06:00</updated><id>http://localhost:4000/jekyll/update/2018/04/07/lsi</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/07/lsi.html">&lt;p&gt;As promised, this post will be about logarithmic Sobolev inequalities, which
are (exponential) concentration inequalities for functions defined on the
binary hypercube. In particular, we’ll review a specific case where we
get speedy concentration thanks to a variance-like bound on our function of
interest. Let’s concentrate some measure!&lt;/p&gt;

&lt;h3 id=&quot;starting-simple&quot;&gt;Starting simple&lt;/h3&gt;

&lt;p&gt;To get things going, we’ll look at a logarithmic Sobolev inequality for a 
function defined on the &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; dimensional binary hypercube&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f: \{-1,1\}^n \to \reals.&lt;/script&gt;

&lt;p&gt;Our random variables &lt;script type=&quot;math/tex&quot;&gt;X \in \{-1,1\}^n&lt;/script&gt; are Rademacher random variables, 
&lt;em&gt;i.e.&lt;/em&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
g_X(x) = 
\begin{cases}
+1, &amp; \textsf{with probability } 0.5 \\
-1, &amp; \textsf{with probability } 0.5.
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;We define &lt;script type=&quot;math/tex&quot;&gt;Z = f(X)&lt;/script&gt; as our real-valued random variable of interest. 
Logarithmic Sobolev inequalities compare to quantities related to &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;entropy functional&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(f) = \E \big[ f(X) \log f(X) \big] - 
				  \E f(X) \log \big( \E f(X) \big)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;Efron–Stein-like functional&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{E}(f) = \frac{1}{2} \E \left[ \sum_{i=1}^n \left( f(X) - 
	f \left( \tilde{X}^{(i)} \right) \right)^2 \right].&lt;/script&gt;

&lt;p&gt;The quantity &lt;script type=&quot;math/tex&quot;&gt;\tilde{X}^{(i)}&lt;/script&gt; is the vector &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; with its &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th
component drawn from an independent copy—this is the same idea as in the
Efron–Stein inequality. For our purposes, this implies that &lt;script type=&quot;math/tex&quot;&gt;X_i&lt;/script&gt; changes
sign.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;logarithmic Sobolev inequality&lt;/strong&gt;for this set up is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(f^2) \le 2 \mathcal{E}(f).&lt;/script&gt;

&lt;h3 id=&quot;concentration-inequality&quot;&gt;Concentration inequality&lt;/h3&gt;

&lt;p&gt;With our logarithmic Sobolev inequality pinned down, we’ll now prove
a concentration inequality for a function satisfying&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^n \left( f(x) - f \left( \tilde{x}^{(i)} \right) \right)^2 \le v&lt;/script&gt;

&lt;p&gt;for some &lt;script type=&quot;math/tex&quot;&gt;v &gt; 0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;x \in \{-1,1\}^n&lt;/script&gt;. In particular, we’ll show that
for all &lt;script type=&quot;math/tex&quot;&gt;t &gt; 0&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\prob(Z &gt; \E Z + t) \le e^{-2t^2/v}.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Technical detail—hint.&lt;/strong&gt;
The proof hinges on the following fact (which we’ll show in a later post
because it uses some nice ideas)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left( e^{z/2} - e^{y/2} \right)^2 \le \frac{(z-y)^2}{8}(e^{z} + e^{y})&lt;/script&gt;

&lt;p&gt;for &lt;script type=&quot;math/tex&quot;&gt;z \ge y&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;proof&quot;&gt;Proof&lt;/h3&gt;

&lt;p&gt;We’re going to follow the so-called &lt;strong&gt;Herbst argument&lt;/strong&gt; to prove the
concentration inequality. The key ingredient of Herbst’s argument is the use
of a &lt;strong&gt;differential inequality&lt;/strong&gt; on a function &lt;script type=&quot;math/tex&quot;&gt;g(x) = e^{\lambda f(x)/2}&lt;/script&gt;
with parameter &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Part 1: defining a differential inequality.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The entropy of &lt;script type=&quot;math/tex&quot;&gt;g^2&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(g^2) = \mathrm{ent}(e^{\lambda f}) 
	= \lambda \E \big[ e^{\lambda f(X)} f(X) \big] -  
	  \E e^{\lambda f(X)} \log \big( \E e^{\lambda f(X)} \big).&lt;/script&gt;

&lt;p&gt;Now, if we stare at this for a moment and let our &lt;em&gt;cumulant generating 
function&lt;/em&gt; neurons fire, then we see that if we let 
&lt;script type=&quot;math/tex&quot;&gt;F(\lambda) = \E e^{\lambda f(X)}&lt;/script&gt;, then we get a &lt;strong&gt;differential inequality&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(g^2) = \lambda F'(\lambda) - F(\lambda) \log F(\lambda).&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Part 2: putting the logarithmic Sobolev inequality to work.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The logarithmic Sobolev inequality states&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\mathrm{ent}(g^2) &amp;\le 2 \mathcal{E}(g) \\
&amp;\stackrel{\textsf{def}}{=} 
	\E \left[ \sum_{i=1}^n \left( e^{\lambda f(X) / 2} - 
		e^{\lambda f \left( \tilde{X}^{(i)} \right) / 2} \right)^2 \right] \\
&amp;\stackrel{\textsf{hint}}{\le} 
	\frac{1}{8} \sum_{i=1}^n \E \left[ 
	\lambda^2 \left( f(X) - f \left( \tilde{X}^{(i)} \right) \right)^2 
	\left( e^{\lambda f(X)} - e^{\lambda f \left( \tilde{X}^{(i)} \right)} \right)
	\right] \\
&amp;\le \frac{\lambda^2 v}{8} \E \left[ e^{\lambda f(X)} \right].
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Part 3: connecting the dots with some calculus.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Okay, cool; we’ve shown that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ent}(e^{\lambda f}) \le \frac{\lambda^2 v}{8} 
	\E \left[ e^{\lambda f(X)} \right]&lt;/script&gt;

&lt;p&gt;which we can rewrite as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda F'(\lambda) - F(\lambda) \log F(\lambda) \le 
	\frac{\lambda^2 v}{8} F(\lambda).&lt;/script&gt;

&lt;p&gt;Now, let’s write this guy in a slightly different form in the spirit of
the Herbst argument:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\lambda F'(\lambda) - F(\lambda) \log F(\lambda)}{\lambda^2 F(\lambda)} 
	= \frac{\lambda F'(\lambda) - \log F(\lambda)}{\lambda^2 F(\lambda)}
	\le \frac{v}{8}.&lt;/script&gt;

&lt;p&gt;The calculus part of brain might be screaming something like&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{d}{dz} \left( \frac{\log z}{z} \right) = \frac{1 - \log z}{z^2},&lt;/script&gt;

&lt;p&gt;which we translate to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{d}{dz} \left( \frac{\log F(\lambda)}{\lambda} \right) \le \frac{v}{8}.&lt;/script&gt;

&lt;p&gt;Invoking more calculus ideas, l’Hospital’s rule says&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim_{\lambda \to 0} \frac{\log F(\lambda)}{\lambda} 
	= \frac{F'(0)}{F(0)} = \E Z.&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Part 4: bounding via Cramér–Chernoff and Markov.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We’re almost there! Let’s assume that &lt;script type=&quot;math/tex&quot;&gt;\lambda &gt; 0&lt;/script&gt; and then integrate
the inequality between &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;. From l’Hospital’s rule, we get
that &lt;script type=&quot;math/tex&quot;&gt;\log F(\lambda) / \lambda \le \E Z + \lambda v / 8&lt;/script&gt;. Now, let’s undo
our &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;-in-the-denominator and our logarithmic term and write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(\lambda) \le e^{\lambda \E Z + \lambda^2 v / 8}.&lt;/script&gt;

&lt;p&gt;Finally, we can use the Cramér–Chernoff technique and Markov’s inequality to 
say that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\prob(Z &gt; \E Z + t) 
	&amp;\le \inf_{\lambda &gt; 0} F(\lambda)e^{-\lambda \E Z - \lambda t} \\
	&amp;\le \inf_{\lambda &gt; 0}  e^{\lambda^2 v / 8 - \lambda t} \\
	&amp;\le e^{-2t^2/v}.
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;(Note that &lt;script type=&quot;math/tex&quot;&gt;\lambda = 4t/v&lt;/script&gt; minimizes the upper bound.) Pat yourself on the 
back and give Mr. Herbst a (pretend) pat on the back too.&lt;/p&gt;

&lt;h3 id=&quot;next-up&quot;&gt;Next up&lt;/h3&gt;

&lt;p&gt;…bandits!&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;

&lt;p&gt;This post is based on material from Chapter 5 of (my new favorite book):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Concentration Inequalities: A Nonasymptotic Theory of Independence&lt;/em&gt; by 
S. Boucheron, G. Lugosi, and P. Masart.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">As promised, this post will be about logarithmic Sobolev inequalities, which are (exponential) concentration inequalities for functions defined on the binary hypercube. In particular, we’ll review a specific case where we get speedy concentration thanks to a variance-like bound on our function of interest. Let’s concentrate some measure!</summary></entry></feed>