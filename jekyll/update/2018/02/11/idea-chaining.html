<!DOCTYPE html>
<html>
	<head>
  	  <title>
  	  	Idea chaining
  	  </title>
	</head>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Idea chaining | Eggink Blog</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="Idea chaining" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this post, we’re going to talk about a concept that is useful in many areas… statistics, optimization, life-in-general… I call it idea chaining. My guess is that most people are already aware of this notion on an intuitive level. Systems thinkers would probably call it something like “problem decomposition”, mathematicians would think of lemmas… basically we take a problem, split it into smaller, easier-to-solve sub-problems, and then chain our results together to solve the original problem." />
<meta property="og:description" content="In this post, we’re going to talk about a concept that is useful in many areas… statistics, optimization, life-in-general… I call it idea chaining. My guess is that most people are already aware of this notion on an intuitive level. Systems thinkers would probably call it something like “problem decomposition”, mathematicians would think of lemmas… basically we take a problem, split it into smaller, easier-to-solve sub-problems, and then chain our results together to solve the original problem." />
<link rel="canonical" href="http://localhost:4000/jekyll/update/2018/02/11/idea-chaining.html" />
<meta property="og:url" content="http://localhost:4000/jekyll/update/2018/02/11/idea-chaining.html" />
<meta property="og:site_name" content="Eggink Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-02-11T20:40:00-07:00" />
<script type="application/ld+json">
{"description":"In this post, we’re going to talk about a concept that is useful in many areas… statistics, optimization, life-in-general… I call it idea chaining. My guess is that most people are already aware of this notion on an intuitive level. Systems thinkers would probably call it something like “problem decomposition”, mathematicians would think of lemmas… basically we take a problem, split it into smaller, easier-to-solve sub-problems, and then chain our results together to solve the original problem.","@type":"BlogPosting","url":"http://localhost:4000/jekyll/update/2018/02/11/idea-chaining.html","headline":"Idea chaining","dateModified":"2018-02-11T20:40:00-07:00","datePublished":"2018-02-11T20:40:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/jekyll/update/2018/02/11/idea-chaining.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="alternate" type="application/rss+xml" title="Eggink Blog" href="/feed.xml">
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" rel="author" href="/">Eggink Blog</a>

    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/about/">About</a>
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Idea chaining</h1>
    <p class="post-meta">Feb 11, 2018</p>
  </header>

  <article class="post-content">
    <p>In this post, we’re going to talk about a concept that is useful in many areas…
statistics, optimization, life-in-general… I call it <strong>idea chaining</strong>. My guess is that
most people are already aware of this notion on an intuitive level. Systems thinkers would
probably call it something like “problem decomposition”, mathematicians would think of
lemmas… basically we take a problem, split it into smaller, easier-to-solve
sub-problems, and then chain our results together to solve the original problem.</p>

<h3 id="a-convex-calculus-for-convexity-verification">A (convex) calculus for convexity verification</h3>

<p>In convex analysis and optimization, we’re often interested in whether or not a given
function is convex. There are a few ways to go about showing the “vexity” of a
particular function, such as using:</p>

<ul>
  <li>the definition of convexity;</li>
  <li>the restriction-to-a-line technique;</li>
  <li>first-order (<em>i.e.</em>, derivative) conditions;</li>
  <li>second-order conditions; or</li>
  <li>a convex calculus.</li>
</ul>

<p>The <strong>convex calculus</strong> approach is appealing because it gives us a toolbox to
(mindlessly) construct or decompose a function, using a set of basic functions and a few
rules that preserve convexity. In the context of convex optimization, this
<strong>constructive convex verification process</strong>
is part of an approach known as <strong>disciplined convex
programming</strong> (DCP). The DCP ideas arose from the work of Michael Grant and
Stephen Boyd in the mid-2000s. Hiriart-Urruty and Lemaréchal discuss the notion of a
convex calculus in their books from the 1990s.</p>

<p>Let’s put the ideas to work on an example that came up on the quiz page of the
<a href="http://dcp.stanford.edu/">DCP</a> website (which teaches the principles of disciplined convex programming).</p>

<p>Our function of interest is</p>

<script type="math/tex; mode=display">f(u,w,y,z) = \log \left( \exp \left\{ e^{\max(u, z)} \right\} +
						 \exp \left\{ g_{\mathrm{hub}}(w) \right\} +
						 \exp \left\{ y - 42 \right\}  \right),</script>

<p>where</p>

<script type="math/tex; mode=display">% <![CDATA[
g_{\mathrm{hub}}(w) =
\begin{cases}
	2|x| - 1, & |x| \ge 1 \\
	|x|^2, 	  & |x| < 1.
\end{cases} %]]></script>

<p>At first sight, this looks ugly because we have a concave function with <script type="math/tex">\log</script>, a couple
convex functions with <script type="math/tex">\max</script> and <script type="math/tex">\exp</script>, an affine function <script type="math/tex">y - 42</script>, and that Huber
function <script type="math/tex">g_{\mathrm{hub}}</script> (which is actually convex, but may not be recognized as
such). Moreover, we have four variables!</p>

<p>The DCP / convex calculus approach turns this problem into an easy verification process.
The non-obvious and key ingredient is the “log-sum-exp” function, also called the soft-max
function. For <script type="math/tex">x \in \reals^n</script>, the log-sum-exp function is</p>

<script type="math/tex; mode=display">h(x) = \log \left( \sum_{i = 1}^n \exp ( x_i ) \right).</script>

<p>This function is convex—if you’re suspicious, calculate its Hessian and
convince yourself. With this single fact, we’re nearly done because the functions
appearing within the exponentials are convex and affine. Then we use that log-sum-exp is
convex and we’re done.</p>

<p><strong>Tips and tricks.</strong> Here are the DCP rules we used:</p>

<ul>
  <li>an increasing convex function of a convex function is convex; and</li>
  <li>a sum of convex functions is convex.</li>
</ul>

<p>So, with two rules and a few basic functions we’ve show a rather complicated function to
be convex—no gradients, subgradients, or Hessians required. We reduced the problem
to a few simple subproblems (<em>e.g.</em>, verifying the convexity of
<script type="math/tex">e^{g_{\mathrm{hub}}(w)}</script> and the like) and then strung everything together using a
couple rules. Bam.</p>

<p>If you’re interested in seeing the “vexity” parse tree for this function, check out the
DCP site’s “<a href="http://dcp.stanford.edu/analyzer">Analyzer</a>” and type in
<em>log_sum_exp(exp(max(u, z)), huber(w) + y - 42)</em>. Do it!</p>

<h3 id="le-cams-inequality">Le Cam’s inequality</h3>

<p>Our next example of idea chaining stems from a problem from Tom Ferguson’s (excellent)
mathematical statistics book called <em>A Course in Large Sample Theory</em>. Problem 5 of
chapter 3 (“Convergence in Law”) walks us through Le Cam’s inequality.</p>

<p>Here’s the set up.</p>

<ul>
  <li>We have <script type="math/tex">n</script> independent Bernoulli random variables each with its own probability of
success, <script type="math/tex">p_i = \prob(X_i = 1)</script>. We’ll call these <script type="math/tex">X_1,\dots,X_n</script>.</li>
  <li>We define <script type="math/tex">S_n = \sum_{i=1}^n X_i</script>.</li>
  <li>We define <script type="math/tex">Z</script> as a Poisson random variable with parameter
<script type="math/tex">\lambda = \sum_{i=1}^n p_i</script>.</li>
</ul>

<p>We want to show that</p>

<script type="math/tex; mode=display">| \prob(S_n \in A) - \prob(Z \in A)| \le \sum_{i=1}^n p_i^2</script>

<p>for all sets <script type="math/tex">A</script>. In other words, we’re computing a bound on the error of using a
Poisson approximation.</p>

<p>We’ll solve this problem by solving three simpler sub-problems.</p>

<p>(1) First, we’ll show that</p>

<script type="math/tex; mode=display">| \prob(S_n \in A) - \prob(Z \in A)| \le \prob(S_n \neq Z).</script>

<p>(2) Then, we’ll show that</p>

<script type="math/tex; mode=display">\prob(S_n \neq Z) \le \sum_{i=1}^n \prob(X_i \neq Y_i).</script>

<p>(3) Finally, we’ll show that</p>

<script type="math/tex; mode=display">\prob(X_i \neq Y_i) \le \sum_{i=1}^n p_i^2.</script>

<p>To show (1), (2), and (3), we’re going to couple <script type="math/tex">S_n</script> and <script type="math/tex">Z</script> to the same underlying
probability space.</p>

<ul>
  <li>The variables <script type="math/tex">U_1,\dots,U_n</script> are uniformly distributed on <script type="math/tex">[0,1]</script>.</li>
  <li>We can define <script type="math/tex">X_i = \ind{}(U_i > 1 - p_i)</script> with <script type="math/tex">\E X_i = p_i</script>.</li>
  <li>We introduce <script type="math/tex">Y \sim \mathrm{Poisson}(p_i)</script> as</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
Y_i =
\begin{cases}
0, & U_i < e^{-p_i} \\
k, & F(k-1) < U_i < F(k),
\end{cases} %]]></script>

<p>where <script type="math/tex">F(k) = e^{-p_i} \sum_{j=0}^{k} p_i^j/j!</script> is the cumulative distribution function
for a Poisson random variable with parameter <script type="math/tex">p_i</script>.</p>

<p><strong>Proof of (1).</strong></p>

<p>Without loss of generality we can assume that <script type="math/tex">\prob(S_n \in A) \ge \prob(Z \in A)</script>.
This allows us to conclude that <script type="math/tex">\{S_n \in A\} \supseteq \{Z \in A\}</script>. Now, we isolate
the set where <script type="math/tex">\{S_n \neq Z\}</script> by noting that</p>

<script type="math/tex; mode=display">\prob(S_n \in A) - \prob(Z \in A) \le \prob(S_n \in A) - \prob(S_n \cap Z \in A)
	= \prob(S_n \neq Z).</script>

<p>One down, two to go.</p>

<p><strong>Proof of (2).</strong></p>

<p>First, let’s rewrite <script type="math/tex">\prob(S_n \neq Z)</script> as <script type="math/tex">\prob \left( \sum_i X_i \neq Z \right)</script>.
This implies that there’s at least one <script type="math/tex">X_i</script> not equal to <script type="math/tex">Y_i</script>. (The <em>at least</em>
phrase should be triggering the part of your brain associated with <em>unions</em>.)
So, we have that</p>

<script type="math/tex; mode=display">\prob \left( \bigcup_{i=1}^n \{X_i \neq Y_i\} \right) \le \sum_{i=1}^n \prob(X_i \neq Y_i)</script>

<p>by the subadditivity of probability.</p>

<p>Two down, one to go.</p>

<p><strong>Proof of (3).</strong></p>

<p>Using our definitions of <script type="math/tex">X_i</script> and <script type="math/tex">Y_i</script>, we can write</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\prob(X_i \neq Y_i) &= 1 - \prob(X_i = 0) - \prob(Y_i = 1) \\
	&= 1 - (1 - p_i) - p_i e^{-p_i} \\
	&= p_i - p_i e^{-p_i} \qquad \qquad \textsf{(because $(1-e^{-p_i}) \le p_i$)}\\
	&\le p_i^2.
\end{align*} %]]></script>

<p>Now, we sum both sides of the equation and we’ve got it.</p>

<p><strong>Bringing it all back home.</strong></p>

<p>Finally, chain the inequalities in (1), (2), and (3) together and we’ve proved Le Cam’s
inequality. Heck yeah!</p>

<h3 id="references">References</h3>

<p>This post draws on material from:</p>

<ul>
  <li>Stephen Boyd’s “<a href="https://web.stanford.edu/~boyd/papers/cvx_short_course.html">Convex Optimization Short Course</a>” notes;</li>
  <li><em>Fundamentals of Convex Analysis</em> by Hiriart-Urruty and Lemaréchal; and</li>
  <li><em>A Course in Large Sample Theory</em> by Thomas Ferguson.</li>
</ul>


  </article>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://jakeknigge-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

                           
<script type="text/javascript" 
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  
<script type="text/x-mathjax-config">

MathJax.Hub.Config({

    showProcessingMessages: false,
    messageStyle: "none",
	CommonHTML: { linebreaks: { automatic: true } },
	SVG: { linebreaks: { automatic: true } },
    "HTML-CSS": {
      linebreaks: { automatic: true},
      availableFonts: ["TeX", "Neo-Euler", "STIX"],
      preferredFont: "TeX",
      webFont: "TeX",
        matchFontHeight: true,
        scale: 100,
        styles: {
            ".MathJax_Display": {
                margin: "0.85em 0em"
            }
        }
    },
    MathMenu: {  
        showFontMenu: true
    },
    TeX: {
      TagIndent: "0.25em",
      extensions: ["AMSmath.js","AMSsymbols.js","cancel.js"], //cancel.js needed only for I_29
      equationNumbers: {
        autoNumber: "AMS", formatNumber: function (n) { return EqnumPrefix() + n }
      },
      MultLineWidth: "80%",
		Macros: {  
			mat: ["{\\overset \\leftrightarrow #1}",1],  
			bra: ["{\\langle #1 |}",1],  
			ket: ["{| #1 \\rangle}",1],  
			sprod: ["{\\left\\langle #1 | #2 \\right\\rangle}",2],  
			tr: "\\text{tr}",  
			ev: ["{\\left\\langle #1 \\right \\rangle}",1],  
			threej: ["{\\left(\\begin{array}{ccc} #1 & #3 & #5 \\\\ #2 & #4 & #6 \\end{array} \\right)}",6],  
			dbar: "đ",
			d: "\\mathrm{d}",
			i: "\\mathrm{i}",
			eps: "\\varepsilon",
			sla: ["\\displaystyle{\\not} #1",1],  
			spinvec: ["\\left( \\begin{array}{c} #1 \\\\ #2 \\end{array} \\right)",2],  
			spinmat: ["\\left( \\begin{array}{cc} #1 & #2 \\\\ #3 & #4 \\end{array} \\right)",4],  
			reals: "\\mathbf{R}",
			integers: "\\mathbf{Z}",
			naturals: "\\mathbf{N}",
			symm: "\\mathbf{S}",
			ones: "\\mathbf{1}",
			prox: "\\mathbf{prox}",
			dom: "\\mathop{\\mathbf{dom}}",
			dist: "\\mathop{\\mathbf{dist}}",
			argmin: "\\mathop{\\mathrm{argmin}}",
			argmax: "\\mathop{\\mathrm{argmax}}",
			epi: "\\mathop{\\mathbf{epi}}",
			E: "\\mathbf{E}",
			Var: "\\mathbf{Var}",
			Cov: "\\mathbf{Cov}",
			prob: "\\mathbf{P}",
			ind: ["{\\mathbf{I}_{#1}}", 1],
			tvec: ["{\\boldsymbol{#1}}",1],
			relint: "\\mathop{\\mathbf{relint}}",
		}
    }
});
</script>

</div>
      </div>
    </div>

    <footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Eggink Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">
            
              Eggink Blog
            
            </li>
            
            <li><a class="u-email" href="mailto:jake@knigge.us">jake@knigge.us</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
  
  
  
  <li><a href="https://github.com/jakeknigge"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">jakeknigge</span></a></li>
  
  
  
  <li><a href="https://www.twitter.com/JakeKnigge"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">JakeKnigge</span></a></li>
  
  
  
</ul>

      </div>

      <div class="footer-col footer-col-3">
        <p>Jake W. Knigge&#39;s blah, blah, blog... a place to discuss statistics, math, and  whatever else comes to mind.
</p>
      </div>
    </div>

  </div>

</footer>

    
  </body>

</html>